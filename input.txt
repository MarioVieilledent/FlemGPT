The English language, with its rich history and global reach, has evolved into one of the most widely spoken and written languages in the world. From its humble beginnings as a Germanic language spoken by a small group of tribes in what is now England, it has grown and adapted over centuries to become a lingua franca for people from diverse cultures and backgrounds.

English is known for its flexibility and versatility, with a vast vocabulary that draws from various sources. The core of the language consists of Old English, a Germanic tongue heavily influenced by Latin and French during the Middle Ages. This linguistic fusion resulted in a vast array of words with different origins and meanings, adding depth and nuance to the language.

One of the fascinating aspects of the English language is its extensive use of borrowed words. English has borrowed vocabulary from Latin, Greek, French, and many other languages, reflecting the cultural exchanges and historical events that shaped the language. These borrowed words often retain their original forms or undergo modifications to fit the English phonetic and grammatical structures.

English also exhibits a complex grammatical structure, although it has undergone simplification over time. It uses a subject-verb-object word order in most cases, but exceptions and variations abound, providing opportunities for linguistic analysis. The language features a wide range of tenses, verb conjugations, and grammatical nuances that require careful study and understanding.

In addition to its grammatical intricacies, English employs a broad range of idioms, expressions, and colloquialisms. These linguistic devices add color and character to the language but can also pose challenges for non-native speakers. Understanding the cultural context and usage of idiomatic expressions is crucial for comprehensive language analysis.

The significance of English extends beyond its linguistic features. As the language of science, technology, business, and diplomacy, it plays a vital role in global communication. English proficiency has become a sought-after skill, enabling individuals to access opportunities for education, employment, and cultural exchange on an international scale.

To analyze the English language effectively, researchers and language enthusiasts employ various statistical techniques. Corpus linguistics, a branch of linguistics that focuses on large collections of texts, provides valuable insights into the frequency, distribution, and usage patterns of words and phrases. By analyzing corpora, researchers can uncover language trends, stylistic preferences, and changes in vocabulary and grammar over time.

The advent of computational linguistics and natural language processing has revolutionized the field of English language analysis. Machine learning models can now process vast amounts of text data, extract meaningful information, and generate accurate statistical analyses. These advanced techniques enable researchers to delve deeper into the intricacies of English and explore its patterns and structures in unprecedented ways.

In conclusion, the English language is a multifaceted and dynamic linguistic system that continues to evolve and influence the world. Its diverse vocabulary, grammatical complexities, and cultural significance make it an intriguing subject for statistical analysis. By leveraging the power of computational linguistics and corpus analysis, we can uncover fascinating insights about English, enhance language learning, and further our understanding of this global means of communication.

Language is a remarkable tool that allows humans to communicate, connect, and share ideas across vast distances and diverse cultures. Throughout history, numerous languages have emerged and evolved, each with its own unique characteristics and rich cultural significance. In this text, we will explore some of the most widely known and spoken languages in the world.

One of the most prevalent languages globally is Mandarin Chinese. With over a billion native speakers, it holds the title of the most spoken language in the world. Mandarin is an official language in China, Taiwan, and Singapore. Its complex writing system, consisting of thousands of characters, adds to its cultural depth and historical importance.

Another influential language is Spanish, spoken by approximately 460 million people worldwide. It is the official language of Spain and most Latin American countries. Spanish boasts a rich literary tradition, with renowned authors like Miguel de Cervantes and Gabriel Garcia Marquez. Its passionate intonation and melodious rhythm make it a favorite among language learners.

English, with around 360 million native speakers, is the global lingua franca. As the official language of numerous countries, including the United States, the United Kingdom, Canada, and Australia, English serves as a bridge across cultures and industries. Its widespread usage in business, academia, and entertainment has contributed to its dominant position in the modern world.

Arabic, spoken by over 300 million people, is the language of the Quran and is widely used across the Middle East and North Africa. It is known for its elegant calligraphy and intricate grammatical structure. Arabic has left an indelible mark on various fields, including mathematics, science, and philosophy, through its significant contributions during the Islamic Golden Age.

Hindi, one of the official languages of India, boasts approximately 341 million speakers. It plays a crucial role in the vibrant Indian film industry, Bollywood, and is deeply intertwined with Indian culture and heritage. Hindi's Devanagari script adds to its distinctiveness, with its curvaceous and visually appealing characters.

Russian, with around 258 million speakers, is the largest native language in Europe. It spans across the vast landmass of Russia and holds significant influence in Eastern Europe and Central Asia. Russian is known for its rich literary traditions, showcased by literary giants like Leo Tolstoy and Fyodor Dostoevsky, and its complex grammar structure challenges language learners.

Finally, we cannot overlook the global impact of French. With approximately 220 million speakers, French is an official language in 29 countries, spread across Europe, Africa, the Americas, and the Caribbean. Renowned for its elegance and sophistication, French is synonymous with art, fashion, and culinary excellence. It continues to be a language of diplomacy and remains a popular choice for language enthusiasts worldwide.

These are just a few examples of the world's most known and spoken languages, each carrying its own unique cultural heritage and global significance. Languages not only allow us to communicate but also provide insights into the history, traditions, and perspectives of different societies, enriching our understanding of the world we inhabit.

The world is a fascinating tapestry of countries, each with its own distinct identity, culture, and geography. From sprawling nations to tiny island nations, the diversity of countries on our planet is truly awe-inspiring. In this text, we will embark on a journey to explore some of the remarkable countries that make up our global community.

Let's start with China, the most populous country on Earth. China is a land of ancient traditions and modern marvels, where vibrant cities like Beijing and Shanghai coexist with breathtaking natural landscapes like the Great Wall and the Yangtze River. Its rich history, exquisite cuisine, and diverse ethnicities contribute to its cultural tapestry.

Moving to India, we encounter a land of contrasts and diversity. India is a mosaic of cultures, languages, and religions. From the bustling streets of Delhi to the serene backwaters of Kerala, this subcontinent offers an array of experiences. India's architectural wonders like the Taj Mahal, its Bollywood film industry, and its spiritual practices, such as yoga and meditation, captivate the imagination.

Next, let's travel to the United States, a vast nation stretching from coast to coast. The United States is known for its cultural influence, technological innovation, and diverse landscapes. From the iconic skylines of New York City and Chicago to the awe-inspiring natural wonders of the Grand Canyon and Yellowstone National Park, the U.S. offers a multitude of experiences and opportunities.

In Africa, we find the vibrant nation of South Africa. Known as the "Rainbow Nation," South Africa is a land of breathtaking beauty and cultural diversity. From the iconic Table Mountain in Cape Town to the stunning wildlife of Kruger National Park, this country offers a unique blend of modernity and traditional heritage, reflected in its rich music, art, and literature.

Moving on to Brazil, we encounter a country of unmatched natural beauty and infectious energy. Brazil is home to the Amazon rainforest, the captivating city of Rio de Janeiro, and the world's largest Carnival celebration. With its samba rhythms, passion for football, and warm hospitality, Brazil embraces visitors with open arms, inviting them to experience its vibrant culture and pristine beaches.

Continuing our journey, we arrive in Australia, a land of stunning landscapes and unique wildlife. Australia's vast Outback, the Great Barrier Reef, and cosmopolitan cities like Sydney and Melbourne showcase the country's diverse offerings. Australia's laid-back lifestyle, love for outdoor adventures, and indigenous heritage create a distinct atmosphere that leaves a lasting impression on travelers.

Finally, let's explore the rich history and cultural heritage of Greece. Known as the cradle of Western civilization, Greece is adorned with ancient ruins, including the Acropolis and the Parthenon in Athens. Its picturesque islands, such as Santorini and Mykonos, with their whitewashed buildings and turquoise waters, have become sought-after destinations for travelers seeking beauty and tranquility.

These are just a few glimpses into the vast tapestry of countries that make up our world. Each country has its own story to tell, captivating us with its unique blend of history, culture, and natural wonders. By exploring these diverse nations, we gain a deeper appreciation for the remarkable planet we call home.

Cultures and history intertwine to form the rich tapestry of human existence. Across the globe, countless cultures have flourished, leaving behind a legacy that shapes our present and influences our future. In this text, we will delve into the captivating world of cultures and history, exploring the depth and diversity that define our human experience.

Let us begin our journey in ancient Egypt, a civilization that emerged along the Nile River over 5,000 years ago. The Egyptians left an indelible mark on history with their awe-inspiring pyramids, intricate hieroglyphic writing, and belief in an afterlife. Their advancements in architecture, medicine, and astronomy showcased their remarkable ingenuity and enduring legacy.

Traveling to ancient Greece, we encounter the birthplace of democracy, philosophy, and the arts. The Greeks' intellectual and artistic achievements, from the works of Homer and Plato to the architectural marvels of the Parthenon, continue to inspire and shape our modern world. Their Olympic Games, held every four years, serve as a testament to their enduring cultural influence.

Venturing eastward, we discover the rich heritage of China. With a history spanning thousands of years, China boasts an array of dynasties, remarkable inventions, and profound philosophical traditions. From the Great Wall to the Terracotta Army, the Chinese civilization showcases its cultural depth and enduring traditions, such as calligraphy, martial arts, and the philosophies of Confucianism and Taoism.

In the Americas, the Mayan civilization flourished, leaving behind magnificent ruins that bear witness to their advanced understanding of astronomy and mathematics. The Maya's intricate calendar system and awe-inspiring temples, such as Chichen Itza and Tikal, offer glimpses into their profound spiritual beliefs and architectural brilliance.

The Islamic Golden Age, spanning from the 8th to the 14th centuries, witnessed an extraordinary flourishing of art, science, and literature across the Islamic world. Scholars and polymaths such as Avicenna, Al-Khwarizmi, and Ibn Rushd made groundbreaking contributions in various fields, while Islamic architecture, with its intricate geometric patterns and majestic mosques like the Alhambra and the Blue Mosque, left an indelible mark on the world.

Turning to Africa, we encounter the diverse cultures that have shaped the continent's history. From the kingdoms of ancient Mali and Ghana to the Swahili city-states along the East African coast, Africa's cultural heritage is vast and varied. The artistry of African masks, the rhythmic beats of traditional music, and the vibrant traditions of storytelling and oral history showcase the continent's rich cultural fabric.

The Renaissance in Europe marked a period of intellectual and artistic rebirth, fueling groundbreaking discoveries, artistic masterpieces, and new ways of thinking. Visionaries like Leonardo da Vinci, Michelangelo, and Galileo Galilei pushed the boundaries of knowledge and creativity, leaving an indelible imprint on European history and culture.

These glimpses into various cultures and historical periods only scratch the surface of the immense wealth of human heritage. Each culture and historical epoch offers a unique perspective, revealing the extraordinary achievements, struggles, and triumphs of our ancestors. By embracing and appreciating the diversity of cultures and delving into the lessons of history, we gain a deeper understanding of our shared humanity and the collective journey that has brought us to the present day.

Religions have played a significant role in shaping the beliefs, values, and practices of communities throughout history. From the ancient civilizations to the present day, different religions have emerged and spread across various cultures and geographic regions, leaving a profound impact on societies. In this text, we will explore the diverse world of religions, their cultural contexts, and the geographic places they have influenced.

One of the earliest known religions is ancient Egyptian religion, which thrived along the banks of the Nile River. Egyptians worshipped a pantheon of gods and goddesses, including Ra, Osiris, and Isis. Their religious beliefs were intertwined with their agricultural practices and their profound reverence for life and the afterlife.

In the Indian subcontinent, Hinduism, one of the world's oldest religions, emerged. Hinduism is a complex system of beliefs and practices that encompasses a wide range of traditions. It embraces concepts such as karma, dharma, and moksha, and venerates deities like Brahma, Vishnu, Shiva, and Devi. The sacred texts of the Vedas and the Upanishads serve as foundational scriptures for Hindu philosophy.

Buddhism, founded by Siddhartha Gautama in ancient India, spread across Asia, leaving an indelible mark on cultures and societies. Buddhism emphasizes the Four Noble Truths and the Eightfold Path as a means to attain enlightenment and liberation from suffering. It has influenced the art, architecture, and moral codes of countries like India, China, Japan, and Thailand.

Judaism, one of the world's oldest monotheistic religions, originated in ancient Israel. It is characterized by the belief in a covenant between God and the Jewish people, as expressed in the Hebrew Bible (Tanakh) and the Talmud. Judaism has shaped the cultural identity of Jewish communities around the world and has influenced the development of Christianity and Islam.

Christianity emerged from the teachings of Jesus Christ in the 1st century CE and spread across Europe, becoming one of the world's largest religions. Its central beliefs focus on the life, death, and resurrection of Jesus Christ, as recorded in the New Testament. Christianity has diverse denominations, each with its own traditions and interpretations, and has profoundly influenced art, music, literature, and ethics throughout history.

Islam, founded by the Prophet Muhammad in the 7th century CE, emerged in the Arabian Peninsula and quickly spread across the Middle East, North Africa, and beyond. The Qur'an is the central religious text of Islam, and the Five Pillars of Islam serve as core principles and practices. Islamic civilization has made significant contributions in science, mathematics, architecture, and philosophy, and has influenced the cultural landscapes of countries such as Saudi Arabia, Egypt, Iran, and Indonesia.

Other major religions include Sikhism, Jainism, Taoism, and Shintoism, each with their own unique beliefs and cultural expressions. They have shaped the identities and worldviews of communities in regions like South Asia, East Asia, and Japan, respectively.

Religions have not only influenced cultures but have also shaped the geographic places they originated from. Sacred sites and pilgrimage destinations, such as Mecca, Jerusalem, Varanasi, and the Vatican City, hold immense religious and cultural significance, attracting millions of worshippers and visitors every year.

Through their teachings, rituals, and traditions, religions have provided a framework for understanding the world, cultivating spirituality, and fostering moral values. They have shaped the identities and worldviews of individuals and communities, leaving a lasting impact on cultures and the geographic places they have touched.

A country is a distinct political and geographic entity, typically characterized by defined borders, a government, and a sovereign authority. It is an independent nation or state that exercises control over a specific territory, including its land, resources, and population. Countries often have their own laws, institutions, and systems of governance.

Language refers to a system of communication used by a particular group or community. It involves the use of structured sounds, words, and grammar to convey meaning and facilitate understanding between individuals. Languages can be spoken, written, or signed, and they serve as a primary means of expression, social interaction, and cultural transmission.

Culture encompasses the beliefs, values, customs, traditions, art, literature, music, and social behaviors shared by a particular group of people. It encompasses the collective knowledge, practices, and symbols that shape the way of life and identity of a community. Culture is learned and passed down from one generation to another, and it plays a crucial role in shaping individuals' behaviors, attitudes, and worldviews.

The term "people" refers to individuals who make up a community, society, or nation. It refers to human beings as a collective entity, highlighting their shared characteristics, experiences, and relationships. People are characterized by their capacity for rational thought, emotions, and social interactions. The term "people" is often used to describe a specific population or ethnic group.

Civilization refers to an advanced stage of human social development characterized by complex political, economic, technological, and cultural systems. It denotes a level of societal organization beyond basic survival needs, marked by the establishment of cities, the development of written language, the specialization of labor, and advancements in art, science, and governance. Civilizations often exhibit distinctive achievements in areas such as architecture, literature, philosophy, and governance.

History is the study of past events, particularly those pertaining to human societies. It involves the examination, interpretation, and analysis of records, artifacts, and narratives from the past to understand how societies have evolved over time. History encompasses the study of political, social, economic, cultural, and technological developments, providing insights into the causes and consequences of human actions and their impact on the present.

Religion refers to a system of beliefs, practices, and moral values that revolve around the worship of a higher power or spiritual entities. It encompasses rituals, prayers, ceremonies, and doctrines that guide individuals' faith and understanding of the universe. Religions often involve moral codes, teachings about the nature of existence, and explanations of the human purpose and destiny. They play a significant role in shaping individuals' worldviews, ethical frameworks, and cultural identities.

Democracy is a system of government in which power is vested in the people, who exercise it either directly or through elected representatives. It is characterized by principles of political equality, popular participation, and the protection of individual rights and freedoms. In a democratic society, decisions are made through fair and transparent processes, and there are mechanisms to ensure accountability and respect for the rule of law.

Justice refers to the fair and impartial treatment of individuals and the upholding of what is right and equitable. It involves the administration of laws and the protection of rights, ensuring that all people are treated fairly and without discrimination. Justice encompasses notions of fairness, integrity, and the resolution of conflicts according to established legal principles.

Equality refers to the state of being equal in rights, opportunities, and status. It involves the absence of discrimination based on characteristics such as race, gender, ethnicity, religion, or social background. Equality promotes the idea that all individuals should have the same access to resources, opportunities, and benefits within a society, fostering inclusivity and social justice.

Freedom is the ability to act, speak, or think without undue restraint or coercion. It encompasses individual liberties, such as freedom of expression, assembly, religion, and movement. Freedom is a fundamental human right that allows individuals to pursue their interests, make choices, and participate in public life without unwarranted interference.

Human rights are inherent rights and freedoms to which all individuals are entitled by virtue of their humanity. They are universal, indivisible, and inalienable, encompassing civil, political, economic, social, and cultural rights. Human rights include the right to life, liberty, equality, and dignity, as well as the right to education, healthcare, and a fair standard of living. Upholding and protecting human rights is a core aspect of promoting justice and ensuring the well-being of individuals and communities.

Sustainability refers to the responsible and balanced use of resources to meet the needs of the present generation without compromising the ability of future generations to meet their own needs. It involves considering the environmental, social, and economic impacts of actions and policies, with the aim of fostering long-term well-being and preserving the natural environment. Sustainable practices strive to address current challenges while promoting the resilience and flourishing of societies and ecosystems for the future.

Globalization is the process of increasing interconnectedness and integration among nations, societies, and economies on a global scale. It involves the exchange of goods, services, information, and ideas across borders, facilitated by advances in technology, transportation, and communication. Globalization has profound effects on economies, cultures, politics, and social systems, leading to increased interdependence and the emergence of a global community.


Life and nature are intricately intertwined, forming a tapestry of beauty, diversity, and interconnectedness. From the majestic mountains to the delicate blossoms, the boundless oceans to the lush forests, the world around us is a symphony of awe-inspiring wonders. In this text, we will delve into the profound relationship between life and nature, exploring their intricate dynamics and the significance they hold for our existence.

Nature, with its breathtaking landscapes and intricate ecosystems, provides the nurturing embrace that sustains all life on Earth. It is a source of inspiration, solace, and wonder, inviting us to explore its mysteries and appreciate its intricate balance. The lush greenery of forests, with their towering trees and delicate undergrowth, offers a sanctuary for countless species, providing oxygen, shelter, and sustenance. The shimmering rivers and glistening lakes quench the thirst of not only wildlife but also our own souls, reminding us of the importance of water for our survival and the vitality it brings to the Earth.

Within nature's embrace, life thrives in all its remarkable forms. From the smallest microorganisms to the grandeur of the animal kingdom, every living being plays a unique role in the intricate web of life. The buzzing of bees, diligently pollinating flowers, ensures the continuation of plant species and the production of nourishing fruits and seeds. The graceful flight of birds, their colorful plumage painting the skies, adds melody and vibrancy to our surroundings. The gentle rustle of leaves, carried by the wind, whispers tales of resilience and growth.

Nature also teaches us valuable lessons about the cycle of life. The changing seasons, from the vibrant blooms of spring to the serene blanket of snow in winter, remind us of the impermanence and constant renewal of existence. Just as a seed buried in the soil germinates and transforms into a towering tree, we, too, experience growth, transformation, and the passage of time.

Yet, amidst the awe-inspiring beauty of nature, we must also acknowledge the fragility of our ecosystems and the impact of human actions. Climate change, deforestation, pollution, and the loss of biodiversity pose significant threats to the delicate balance of life on our planet. It is crucial that we recognize our responsibility to protect and preserve nature, for it sustains not only our physical well-being but also our emotional and spiritual connection to the world.

By immersing ourselves in nature, we find solace, inspiration, and a profound sense of belonging. The verdant forests invite us to wander and contemplate, the crashing waves embrace us in their rhythmic embrace, and the starlit skies fill us with a sense of awe and wonder. In the presence of nature's grandeur, we are reminded of our place in the intricate tapestry of life.

As we navigate the complexities of existence, let us cherish and respect the precious bond between life and nature. Let us strive to be stewards of the Earth, nurturing and protecting the diversity of life that thrives within its embrace. For it is in the harmony between life and nature that we discover our true interconnectedness and the profound beauty that surrounds us every day.

Science and technology have revolutionized the way we live, work, and interact with the world around us. From groundbreaking discoveries to innovative inventions, the realms of science and technology have propelled humanity forward, opening up new frontiers and expanding our understanding of the universe. In this text, we will explore the fascinating world of science and technology, its impact on society, and the remarkable possibilities it holds for the future.

Science, at its core, is the pursuit of knowledge through systematic observation, experimentation, and analysis. It encompasses various disciplines such as physics, chemistry, biology, astronomy, and more. Scientists strive to uncover the fundamental principles that govern the natural world, unraveling its mysteries and pushing the boundaries of human understanding. Through meticulous research and the scientific method, they uncover new truths, challenge existing theories, and contribute to the collective knowledge of humanity.

Technology, on the other hand, represents the practical application of scientific knowledge for practical purposes. It involves the development of tools, machines, systems, and processes that enhance our capabilities and improve our lives. From the invention of the wheel to the advent of the internet, technology has shaped civilizations, enabling advancements in communication, transportation, medicine, agriculture, and countless other fields.

The intertwining of science and technology has led to remarkable advancements that have transformed every aspect of our lives. The field of medicine, for instance, has witnessed extraordinary breakthroughs, leading to improved diagnostics, life-saving treatments, and enhanced quality of life. From vaccines and antibiotics to medical imaging and regenerative therapies, science and technology have revolutionized healthcare, enabling us to combat diseases and extend human lifespan.

In the realm of communication and connectivity, technology has bridged the gaps between people and cultures. The advent of the internet and digital platforms has transformed the way we communicate, share information, and conduct business. It has created a global network of interconnectedness, fostering collaboration, innovation, and cultural exchange on an unprecedented scale.

Technological advancements have also revolutionized transportation, making the world more accessible and interconnected. From automobiles and airplanes to high-speed trains and space exploration, science and technology have propelled us beyond the confines of our immediate surroundings, allowing us to explore new frontiers and expand our horizons.

In the realm of artificial intelligence and robotics, science and technology are reshaping industries and pushing the boundaries of what is possible. With machine learning, data analytics, and automation, we are witnessing the rise of intelligent systems that can analyze vast amounts of information, assist in decision-making processes, and perform complex tasks with precision and efficiency.

However, with the remarkable progress in science and technology comes the need for responsible and ethical considerations. As we embrace the potential of new discoveries and inventions, it is essential to ensure their safe and ethical implementation. Discussions around data privacy, cybersecurity, and the ethical implications of emerging technologies are crucial to shape a future that aligns with our shared values and respects human rights.

In conclusion, science and technology have ushered in a new era of possibilities, transforming our lives and shaping the world we live in. From healthcare to communication, transportation to exploration, their impact is evident in every facet of our existence. As we continue to explore and push the boundaries of knowledge, it is important to foster a symbiotic relationship between scientific progress, technological innovation, and the well-being of humanity and the planet. By harnessing the power of science and technology responsibly, we can create a future that is filled with unprecedented opportunities, sustainable solutions, and the betterment of humankind.

Art, in its myriad forms, has been an integral part of human expression and creativity throughout history. From ancient cave paintings to modern installations, art has the power to inspire, provoke thought, evoke emotions, and shape cultural narratives. In this text, we will delve into the captivating world of art, exploring its diverse manifestations, its impact on society, and the profound ways it enriches our lives.

Art encompasses a vast spectrum of mediums, including painting, sculpture, architecture, literature, music, dance, theater, film, and more. It serves as a means of communication, allowing individuals to express their unique perspectives, emotions, and ideas. Through the creative process, artists channel their inner worlds and external experiences into tangible forms, inviting audiences to engage, interpret, and connect with their work.

Visual art, such as painting and sculpture, presents a visual language that transcends cultural and linguistic barriers. From the vivid colors and brushstrokes of a painting to the intricate details and textures of a sculpture, visual art stimulates our senses and invites us to contemplate and interpret its meaning. It reflects the artist's perspective, experiences, and observations, offering a glimpse into different cultures, historical periods, and individual imaginations.

Literature, another powerful form of artistic expression, transports us to different realms, introduces us to compelling characters, and explores profound themes. Through the written word, authors weave narratives, craft poetry, and delve into the depths of human experiences. Literature not only entertains but also challenges our perceptions, expands our horizons, and nurtures our empathy and understanding.

Music, with its enchanting melodies, harmonies, and rhythms, has the ability to move us on an emotional and visceral level. Whether through classical symphonies, energetic rock anthems, soulful jazz tunes, or meditative chants, music has the power to evoke a wide range of emotions and create shared experiences. It transcends cultural boundaries, serving as a universal language that resonates with people from all walks of life.

Performing arts, including theater, dance, and film, bring stories to life through physicality, movement, and storytelling. They captivate audiences, transporting them into different worlds, challenging their perspectives, and igniting their imaginations. Performances create a unique fusion of visual, auditory, and kinesthetic elements, leaving a lasting impact on both performers and spectators.

Art, beyond its aesthetic value, plays a significant role in shaping cultures, identities, and societal dialogues. It reflects the values, beliefs, and aspirations of a society, acting as a mirror that allows us to introspect and question the world we inhabit. Art can challenge social norms, provoke critical thinking, raise awareness about important issues, and promote social change.

Moreover, art has the ability to provide solace, healing, and a sense of connection. It serves as a source of inspiration and respite, offering a space for introspection, self-expression, and catharsis. Art therapy has been recognized as a powerful tool for emotional and psychological well-being, helping individuals explore their inner worlds and find meaning and purpose in their lives.

In conclusion, art is a vibrant and essential part of our human experience. It has the power to ignite our imaginations, transcend boundaries, and shape our understanding of the world. Whether as creators or appreciators, art invites us to engage with our senses, emotions, and intellects. It invites us to explore, reflect, and celebrate the rich tapestry of human expression. Through art, we find inspiration, connection, and the beauty that resonates within us all.

A programming language is a system of notation for writing computer programs. Most programming languages are text-based formal languages, but they may also be graphical. They are a kind of computer language.
The description of a programming language is usually split into the two components of syntax (form) and semantics (meaning), which are usually defined by a formal language. Some languages are defined by a specification document (for example, the C programming language is specified by an ISO Standard) while other languages (such as Perl) have a dominant implementation that is treated as a reference. Some languages have both, with the basic language defined by a standard and extensions taken from the dominant implementation being common.
Programming language theory is the subfield of computer science that studies the design, implementation, analysis, characterization, and classification of programming languages.
There are many considerations when defining what constitutes a programming language.

Computer languages vs programming languages
The term computer language is sometimes used interchangeably with programming language. However, the usage of both terms varies among authors, including the exact scope of each. One usage describes programming languages as a subset of computer languages. Similarly, languages used in computing that have a different goal than expressing computer programs are generically designated computer languages. For instance, markup languages are sometimes referred to as computer languages to emphasize that they are not meant to be used for programming. One way of classifying computer languages is by the computations they are capable of expressing, as described by the theory of computation. The majority of practical programming languages are Turing complete, and all Turing complete languages can implement the same set of algorithms. ANSI/ISO SQL-92 and Charity are examples of languages that are not Turing complete, yet are often called programming languages. However, some authors restrict the term "programming language" to Turing complete languages.

Another usage regards programming languages as theoretical constructs for programming abstract machines and computer languages as the subset thereof that runs on physical computers, which have finite hardware resources. John C. Reynolds emphasizes that formal specification languages are just as much programming languages as are the languages intended for execution. He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats.

Domain and target
In most practical contexts, a programming language involves a computer; consequently, programming languages are usually defined and studied this way. Programming languages differ from natural languages in that natural languages are only used for interaction between people, while programming languages also allow humans to communicate instructions to machines.

The domain of the language is also worth consideration. Markup languages like XML, HTML, or troff, which define structured data, are not usually considered programming languages. Programming languages may, however, share the syntax with markup languages if a computational semantics is defined. XSLT, for example, is a Turing complete language entirely using XML syntax. Moreover, LaTeX, which is mostly used for structuring documents, also contains a Turing complete subset.

Abstractions
Programming languages usually contain abstractions for defining and manipulating data structures or controlling the flow of execution. The practical necessity that a programming language support adequate abstractions is expressed by the abstraction principle. This principle is sometimes formulated as a recommendation to the programmer to make proper use of such abstractions.
Early developments
Very early computers, such as Colossus, were programmed without the help of a stored program, by modifying their circuitry or setting banks of physical controls.

Slightly later, programs could be written in machine language, where the programmer writes each instruction in a numeric form the hardware can execute directly. For example, the instruction to add the value in two memory locations might consist of 3 numbers: an "opcode" that selects the "add" operation, and two memory locations. The programs, in decimal or binary form, were read in from punched cards, paper tape, magnetic tape or toggled in on switches on the front panel of the computer. Machine languages were later termed first-generation programming languages (1GL).

The next step was the development of the so-called second-generation programming languages (2GL) or assembly languages, which were still closely tied to the instruction set architecture of the specific computer. These served to make the program much more human-readable and relieved the programmer of tedious and error-prone address calculations.

The first high-level programming languages, or third-generation programming languages (3GL), were written in the 1950s. An early high-level programming language to be designed for a computer was Plankalkül, developed for the German Z3 by Konrad Zuse between 1943 and 1945. However, it was not implemented until 1998 and 2000.

John Mauchly's Short Code, proposed in 1949, was one of the first high-level languages ever developed for an electronic computer. Unlike machine code, Short Code statements represented mathematical expressions in an understandable form. However, the program had to be translated into machine code every time it ran, making the process much slower than running the equivalent machine code.

At the University of Manchester, Alick Glennie developed Autocode in the early 1950s. As a programming language, it used a compiler to automatically convert the language into machine code. The first code and compiler was developed in 1952 for the Mark 1 computer at the University of Manchester and is considered to be the first compiled high-level programming language.

The second auto code was developed for the Mark 1 by R. A. Brooker in 1954 and was called the "Mark 1 Autocode". Brooker also developed an auto code for the Ferranti Mercury in the 1950s in conjunction with the University of Manchester. The version for the EDSAC 2 was devised by D. F. Hartley of University of Cambridge Mathematical Laboratory in 1961. Known as EDSAC 2 Autocode, it was a straight development from Mercury Autocode adapted for local circumstances and was noted for its object code optimization and source-language diagnostics which were advanced for the time. A contemporary but separate thread of development, Atlas Autocode was developed for the University of Manchester Atlas 1 machine.

In 1954, FORTRAN was invented at IBM by John Backus. It was the first widely used high-level general-purpose programming language to have a functional implementation, as opposed to just a design on paper. It is still a popular language for high-performance computing and is used for programs that benchmark and rank the world's fastest supercomputers.

Another early programming language was devised by Grace Hopper in the US, called FLOW-MATIC. It was developed for the UNIVAC I at Remington Rand during the period from 1955 until 1959. Hopper found that business data processing customers were uncomfortable with mathematical notation, and in early 1955, she and her team wrote a specification for an English programming language and implemented a prototype. The FLOW-MATIC compiler became publicly available in early 1958 and was substantially complete in 1959. FLOW-MATIC was a major influence in the design of COBOL, since only it and its direct descendant AIMACO were in actual use at the time.

Refinement
The increased use of high-level languages introduced a requirement for low-level programming languages or system programming languages. These languages, to varying degrees, provide facilities between assembly languages and high-level languages. They can be used to perform tasks that require direct access to hardware facilities but still provide higher-level control structures and error-checking.

The period from the 1960s to the late 1970s brought the development of the major language paradigms now in use:

APL introduced array programming and influenced functional programming.
ALGOL refined both structured procedural programming and the discipline of language specification; the "Revised Report on the Algorithmic Language ALGOL 60" became a model for how later language specifications were written.
Lisp, implemented in 1958, was the first dynamically-typed functional programming language.
In the 1960s, Simula was the first language designed to support object-oriented programming; in the mid-1970s, Smalltalk followed with the first "purely" object-oriented language.
C was developed between 1969 and 1973 as a system programming language for the Unix operating system and remains popular.
Prolog, designed in 1972, was the first logic programming language.
In 1978, ML built a polymorphic type system on top of Lisp, pioneering statically-typed functional programming languages.
Each of these languages spawned descendants, and most modern programming languages count at least one of them in their ancestry.

The 1960s and 1970s also saw considerable debate over the merits of structured programming, and whether programming languages should be designed to support it. Edsger Dijkstra, in a famous 1968 letter published in the Communications of the ACM, argued that Goto statements should be eliminated from all "higher-level" programming languages.
Consolidation and growth

The 1980s were years of relative consolidation. C++ combined object-oriented and systems programming. The United States government standardized Ada, a systems programming language derived from Pascal and intended for use by defense contractors. In Japan and elsewhere, vast sums were spent investigating the so-called "fifth-generation" languages that incorporated logic programming constructs. The functional languages community moved to standardize ML and Lisp. Rather than inventing new paradigms, all of these movements elaborated upon the ideas invented in the previous decades.

One important trend in language design for programming large-scale systems during the 1980s was an increased focus on the use of modules or large-scale organizational units of code. Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs.

The rapid growth of the Internet in the mid-1990s created opportunities for new languages. Perl, originally a Unix scripting tool first released in 1987, became common in dynamic websites. Java came to be used for server-side programming, and bytecode virtual machines became popular again in commercial settings with their promise of "Write once, run anywhere" (UCSD Pascal had been popular for a time in the early 1980s). These developments were not fundamentally novel; rather, they were refinements of many existing languages and paradigms (although their syntax was often based on the C family of programming languages).

Programming language evolution continues, in both industry and research. Current directions include security and reliability verification, new kinds of modularity (mixins, delegates, aspects), and database integration such as Microsoft's LINQ.

Fourth-generation programming languages (4GL) are computer programming languages that aim to provide a higher level of abstraction of the internal computer hardware details than 3GLs. Fifth-generation programming languages (5GL) are programming languages based on solving problems using constraints given to the program, rather than using an algorithm written by a programmer.
Elements
All programming languages have some primitive building blocks for the description of data and the processes or transformations applied to them (like the addition of two numbers or the selection of an item from a collection). These primitives are defined by syntactic and semantic rules which describe their structure and meaning respectively.

Syntax
Main article: Syntax (programming languages)

A programming language's surface form is known as its syntax. Most programming languages are purely textual; they use sequences of text including words, numbers, and punctuation, much like written natural languages. On the other hand, some programming languages are more graphical in nature, using visual relationships between symbols to specify a program.

The syntax of a language describes the possible combinations of symbols that form a syntactically correct program. The meaning given to a combination of symbols is handled by semantics (either formal or hard-coded in a reference implementation). Since most languages are textual, this article discusses textual syntax.

The programming language syntax is usually defined using a combination of regular expressions (for lexical structure) and Backus–Naur form (for grammatical structure). Below is a simple grammar, based on Lisp:

expression ::= atom | list
atom       ::= number | symbol
number     ::= ?['0'-'9']+
symbol     ::= ['A'-'Z''a'-'z'].*
list       ::= '(' expression* ')'
This grammar specifies the following:

an expression is either an atom or a list;
an atom is either a number or a symbol;
a number is an unbroken sequence of one or more decimal digits, optionally preceded by a plus or minus sign;
a symbol is a letter followed by zero or more of any characters (excluding whitespace); and
a list is a matched pair of parentheses, with zero or more expressions inside it.
The following are examples of well-formed token sequences in this grammar: 12345, () and (a b c232 (1)).

Not all syntactically correct programs are semantically correct. Many syntactically correct programs are nonetheless ill-formed, per the language's rules; and may (depending on the language specification and the soundness of the implementation) result in an error on translation or execution. In some cases, such programs may exhibit undefined behavior. Even when a program is well-defined within a language, it may still have a meaning that is not intended by the person who wrote it.

Using natural language as an example, it may not be possible to assign a meaning to a grammatically correct sentence or the sentence may be false:

"Colorless green ideas sleep furiously." is grammatically well-formed but has no generally accepted meaning.
"John is a married bachelor." is grammatically well-formed but expresses a meaning that cannot be true.
The following C language fragment is syntactically correct, but performs operations that are not semantically defined (the operation *p >> 4 has no meaning for a value having a complex type and p->im is not defined because the value of p is the null pointer):

complex *p = NULL;
complex abs_p = sqrt(*p >> 4 + p->im);
If the type declaration on the first line were omitted, the program would trigger an error on the undefined variable p during compilation. However, the program would still be syntactically correct since type declarations provide only semantic information.

The grammar needed to specify a programming language can be classified by its position in the Chomsky hierarchy. The syntax of most programming languages can be specified using a Type-2 grammar, i.e., they are context-free grammars. Some languages, including Perl and Lisp, contain constructs that allow execution during the parsing phase. Languages that have constructs that allow the programmer to alter the behavior of the parser make syntax analysis an undecidable problem, and generally blur the distinction between parsing and execution. In contrast to Lisp's macro system and Perl's BEGIN blocks, which may contain general computations, C macros are merely string replacements and do not require code execution.

Semantics
The term semantics refers to the meaning of languages, as opposed to their form (syntax).

Static semantics
A static semantics defines restrictions on the structure of valid texts that are hard or impossible to express in standard syntactic formalisms.[failed verification] For compiled languages, static semantics essentially include those semantic rules that can be checked at compile time. Examples include checking that every identifier is declared before it is used (in languages that require such declarations) or that the labels on the arms of a case statement are distinct. Many important restrictions of this type, like checking that identifiers are used in the appropriate context (e.g. not adding an integer to a function name), or that subroutine calls have the appropriate number and type of arguments, can be enforced by defining them as rules in a logic called a type system. Other forms of static analyses like data flow analysis may also be part of static semantics. Newer programming languages like Java and C# have definite assignment analysis, a form of data flow analysis, as part of their static semantics.

Dynamic semantics
Main article: Semantics of programming languages
Once data has been specified, the machine must be instructed to perform operations on the data. For example, the semantics may define the strategy by which expressions are evaluated to values, or the manner in which control structures conditionally execute statements. The dynamic semantics (also known as execution semantics) of a language defines how and when the various constructs of a language should produce a program behavior. There are many ways of defining execution semantics. Natural language is often used to specify the execution semantics of languages commonly used in practice. A significant amount of academic research went into formal semantics of programming languages, which allows execution semantics to be specified in a formal manner. Results from this field of research have seen limited application to programming language design and implementation outside academia.

Type system
Main articles: Data type, Type system, and Type safety
A type system defines how a programming language classifies values and expressions into types, how it can manipulate those types and how they interact. The goal of a type system is to verify and usually enforce a certain level of correctness in programs written in that language by detecting certain incorrect operations. Any decidable type system involves a trade-off: while it rejects many incorrect programs, it can also prohibit some correct, albeit unusual programs. In order to bypass this downside, a number of languages have type loopholes, usually unchecked casts that may be used by the programmer to explicitly allow a normally disallowed operation between different types. In most typed languages, the type system is used only to type check programs, but a number of languages, usually functional ones, infer types, relieving the programmer from the need to write type annotations. The formal design and study of type systems is known as type theory.

Typed versus untyped languages
A language is typed if the specification of every operation defines types of data to which the operation is applicable. For example, the data represented by "this text between the quotes" is a string, and in many programming languages dividing a number by a string has no meaning and will not be executed. The invalid operation may be detected when the program is compiled ("static" type checking) and will be rejected by the compiler with a compilation error message, or it may be detected while the program is running ("dynamic" type checking), resulting in a run-time exception. Many languages allow a function called an exception handler to handle this exception and, for example, always return "-1" as the result.

A special case of typed languages is the single-typed languages. These are often scripting or markup languages, such as REXX or SGML, and have only one data type[dubious – discuss]–—most commonly character strings which are used for both symbolic and numeric data.

In contrast, an untyped language, such as most assembly languages, allows any operation to be performed on any data, generally sequences of bits of various lengths. High-level untyped languages include BCPL, Tcl, and some varieties of Forth.

In practice, while few languages are considered typed from the type theory (verifying or rejecting all operations), most modern languages offer a degree of typing. Many production languages provide means to bypass or subvert the type system, trading type safety for finer control over the program's execution (see casting).

Static vis-à-vis dynamic typing
In static typing, all expressions have their types determined prior to when the program is executed, typically at compile-time. For example, 1 and (2+2) are integer expressions; they cannot be passed to a function that expects a string or stored in a variable that is defined to hold dates.

Statically-typed languages can be either manifestly typed or type-inferred. In the first case, the programmer must explicitly write types at certain textual positions (for example, at variable declarations). In the second case, the compiler infers the types of expressions and declarations based on context. Most mainstream statically-typed languages, such as C++, C# and Java, are manifestly typed. Complete type inference has traditionally been associated with functional languages such as Haskell and ML. However, many manifestly-typed languages support partial type inference; for example, C++, Java, and C# all infer types in certain limited cases. Additionally, some programming languages allow for some types to be automatically converted to other types; for example, an int can be used where the program expects a float.

Dynamic typing, also called latent typing, determines the type-safety of operations at run time; in other words, types are associated with run-time values rather than textual expressions. As with type-inferred languages, dynamically-typed languages do not require the programmer to write explicit type annotations on expressions. Among other things, this may permit a single variable to refer to values of different types at different points in the program execution. However, type errors cannot be automatically detected until a piece of code is actually executed, potentially making debugging more difficult. Lisp, Smalltalk, Perl, Python, JavaScript, and Ruby are all examples of dynamically-typed languages.

Weak and strong typing
Weak typing allows a value of one type to be treated as another, for example treating a string as a number. This can occasionally be useful, but it can also allow some kinds of program faults to go undetected at compile time and even at run time.

Strong typing prevents these program faults. An attempt to perform an operation on the wrong type of value raises an error. Strongly-typed languages are often termed type-safe or safe.

An alternative definition for "weakly typed" refers to languages, such as Perl and JavaScript, which permit a large number of implicit type conversions. In JavaScript, for example, the expression 2 * x implicitly converts x to a number, and this conversion succeeds even if x is null, undefined, an Array, or a string of letters. Such implicit conversions are often useful, but they can mask programming errors. Strong and static are now generally considered orthogonal concepts, but usage in the literature differs. Some use the term strongly typed to mean strongly, statically typed, or, even more confusingly, to mean simply statically typed. Thus C has been called both strongly typed and weakly, statically typed.

It may seem odd to some professional programmers that C could be "weakly, statically typed". However, the use of the generic pointer, the void* pointer, does allow casting pointers to other pointers without needing to do an explicit cast. This is extremely similar to somehow casting an array of bytes to any kind of datatype in C without using an explicit cast, such as (int) or (char).

Standard library and run-time system
Main article: Standard library
Most programming languages have an associated core library (sometimes known as the "standard library", especially if it is included as part of the published language standard), which is conventionally made available by all implementations of the language. Core libraries typically include definitions for commonly used algorithms, data structures, and mechanisms for input and output.

The line between a language and its core library differs from language to language. In some cases, the language designers may treat the library as a separate entity from the language. However, a language's core library is often treated as part of the language by its users, and some language specifications even require that this library be made available in all implementations. Indeed, some languages are designed so that the meanings of certain syntactic constructs cannot even be described without referring to the core library. For example, in Java, a string literal is defined as an instance of the java.lang.String class; similarly, in Smalltalk, an anonymous function expression (a "block") constructs an instance of the library's BlockContext class. Conversely, Scheme contains multiple coherent subsets that suffice to construct the rest of the language as library macros, and so the language designers do not even bother to say which portions of the language must be implemented as language constructs, and which must be implemented as parts of a library.

Design and implementation
Main article: Programming language design and implementation
Programming languages share properties with natural languages related to their purpose as vehicles for communication, having a syntactic form separate from its semantics, and showing language families of related languages branching one from another. But as artificial constructs, they also differ in fundamental ways from languages that have evolved through usage. A significant difference is that a programming language can be fully described and studied in its entirety since it has a precise and finite definition. By contrast, natural languages have changing meanings given by their users in different communities. While constructed languages are also artificial languages designed from the ground up with a specific purpose, they lack the precise and complete semantic definition that a programming language has.

Many programming languages have been designed from scratch, altered to meet new needs, and combined with other languages. Many have eventually fallen into disuse. Although there have been attempts to design one "universal" programming language that serves all purposes, all of them have failed to be generally accepted as filling this role. The need for diverse programming languages arises from the diversity of contexts in which languages are used:

Programs range from tiny scripts written by individual hobbyists to huge systems written by hundreds of programmers.
Programmers range in expertise from novices who need simplicity above all else to experts who may be comfortable with considerable complexity.
Programs must balance speed, size, and simplicity on systems ranging from microcontrollers to supercomputers.
Programs may be written once and not change for generations, or they may undergo continual modification.
Programmers may simply differ in their tastes: they may be accustomed to discussing problems and expressing them in a particular language.
One common trend in the development of programming languages has been to add more ability to solve problems using a higher level of abstraction. The earliest programming languages were tied very closely to the underlying hardware of the computer. As new programming languages have developed, features have been added that let programmers express ideas that are more remote from simple translation into underlying hardware instructions. Because programmers are less tied to the complexity of the computer, their programs can do more computing with less effort from the programmer. This lets them write more functionality per time unit.

Natural-language programming has been proposed as a way to eliminate the need for a specialized language for programming. However, this goal remains distant and its benefits are open to debate. Edsger W. Dijkstra took the position that the use of a formal language is essential to prevent the introduction of meaningless constructs, and dismissed natural-language programming as "foolish". Alan Perlis was similarly dismissive of the idea. Hybrid approaches have been taken in Structured English and SQL.

A language's designers and users must construct a number of artifacts that govern and enable the practice of programming. The most important of these artifacts are the language specification and implementation.

Specification
Main article: Programming language specification
The specification of a programming language is an artifact that the language users and the implementors can use to agree upon whether a piece of source code is a valid program in that language, and if so what its behavior shall be.

A programming language specification can take several forms, including the following:

An explicit definition of the syntax, static semantics, and execution semantics of the language. While syntax is commonly specified using a formal grammar, semantic definitions may be written in natural language (e.g., as in the C language), or a formal semantics (e.g., as in Standard ML and Scheme specifications).
A description of the behavior of a translator for the language (e.g., the C++ and Fortran specifications). The syntax and semantics of the language have to be inferred from this description, which may be written in natural or formal language.
A reference or model implementation, sometimes written in the language being specified (e.g., Prolog or ANSI REXX). The syntax and semantics of the language are explicit in the behavior of the reference implementation.
Implementation
Main article: Programming language implementation
An implementation of a programming language provides a way to write programs in that language and execute them on one or more configurations of hardware and software. There are, broadly, two approaches to programming language implementation: compilation and interpretation. It is generally possible to implement a language using either technique.

The output of a compiler may be executed by hardware or a program called an interpreter. In some implementations that make use of the interpreter approach, there is no distinct boundary between compiling and interpreting. For instance, some implementations of BASIC compile and then execute the source one line at a time.

Programs that are executed directly on the hardware usually run much faster than those that are interpreted in software.[better source needed]

One technique for improving the performance of interpreted programs is just-in-time compilation. Here the virtual machine, just before execution, translates the blocks of bytecode which are going to be used to machine code, for direct execution on the hardware.

Proprietary languages
Although most of the most commonly used programming languages have fully open specifications and implementations, many programming languages exist only as proprietary programming languages with the implementation available only from a single vendor, which may claim that such a proprietary language is their intellectual property. Proprietary programming languages are commonly domain-specific languages or internal scripting languages for a single product; some proprietary languages are used only internally within a vendor, while others are available to external users.

Some programming languages exist on the border between proprietary and open; for example, Oracle Corporation asserts proprietary rights to some aspects of the Java programming language, and Microsoft's C# programming language, which has open implementations of most parts of the system, also has Common Language Runtime (CLR) as a closed environment.

Many proprietary languages are widely used, in spite of their proprietary nature; examples include MATLAB, VBScript, and Wolfram Language. Some languages may make the transition from closed to open; for example, Erlang was originally Ericsson's internal programming language.

Use
Thousands of different programming languages have been created, mainly in the computing field. Individual software projects commonly use five programming languages or more.

Programming languages differ from most other forms of human expression in that they require a greater degree of precision and completeness. When using a natural language to communicate with other people, human authors and speakers can be ambiguous and make small errors, and still expect their intent to be understood. However, figuratively speaking, computers "do exactly what they are told to do", and cannot "understand" what code the programmer intended to write. The combination of the language definition, a program, and the program's inputs must fully specify the external behavior that occurs when the program is executed, within the domain of control of that program. On the other hand, ideas about an algorithm can be communicated to humans without the precision required for execution by using pseudocode, which interleaves natural language with code written in a programming language.

A programming language provides a structured mechanism for defining pieces of data, and the operations or transformations that may be carried out automatically on that data. A programmer uses the abstractions present in the language to represent the concepts involved in a computation. These concepts are represented as a collection of the simplest elements available (called primitives). Programming is the process by which programmers combine these primitives to compose new programs, or adapt existing ones to new uses or a changing environment.

Programs for a computer might be executed in a batch process without human interaction, or a user might type commands in an interactive session of an interpreter. In this case the "commands" are simply programs, whose execution is chained together. When a language can run its commands through an interpreter (such as a Unix shell or other command-line interface), without compiling, it is called a scripting language.

Measuring language usage
Main article: Measuring programming language popularity
Determining which is the most widely used programming language is difficult since the definition of usage varies by context. One language may occupy the greater number of programmer hours, a different one has more lines of code, and a third may consume the most CPU time. Some languages are very popular for particular kinds of applications. For example, COBOL is still strong in the corporate data center, often on large mainframes; Fortran in scientific and engineering applications; Ada in aerospace, transportation, military, real-time, and embedded applications; and C in embedded applications and operating systems. Other languages are regularly used to write many different kinds of applications.

Various methods of measuring language popularity, each subject to a different bias over what is measured, have been proposed:

counting the number of job advertisements that mention the language
the number of books sold that teach or describe the language
estimates of the number of existing lines of code written in the language – which may underestimate languages not often found in public searches
counts of language references (i.e., to the name of the language) found using a web search engine.
Combining and averaging information from various internet sites, stackify.com reported the ten most popular programming languages (in descending order by overall popularity): Java, C, C++, Python, C#, JavaScript, VB .NET, R, PHP, and MATLAB.

Dialects, flavors and implementations
A dialect of a programming language or a data exchange language is a (relatively small) variation or extension of the language that does not change its intrinsic nature. With languages such as Scheme and Forth, standards may be considered insufficient, inadequate, or illegitimate by implementors, so often they will deviate from the standard, making a new dialect. In other cases, a dialect is created for use in a domain-specific language, often a subset. In the Lisp world, most languages that use basic S-expression syntax and Lisp-like semantics are considered Lisp dialects, although they vary wildly, as do, say, Racket and Clojure. As it is common for one language to have several dialects, it can become quite difficult for an inexperienced programmer to find the right documentation. The BASIC programming language has many dialects.

Taxonomies
Further information: Categorical list of programming languages
There is no overarching classification scheme for programming languages. A given programming language does not usually have a single ancestor language. Languages commonly arise by combining the elements of several predecessor languages with new ideas in circulation at the time. Ideas that originate in one language will diffuse throughout a family of related languages, and then leap suddenly across familial gaps to appear in an entirely different family.

The task is further complicated by the fact that languages can be classified along multiple axes. For example, Java is both an object-oriented language (because it encourages object-oriented organization) and a concurrent language (because it contains built-in constructs for running multiple threads in parallel). Python is an object-oriented scripting language.

In broad strokes, programming languages are classified by programming paradigm and intended domain of use, with general-purpose programming languages distinguished from domain-specific programming languages. Traditionally, programming languages have been regarded as describing computation in terms of imperative sentences, i.e. issuing commands. These are generally called imperative programming languages. A great deal of research in programming languages has been aimed at blurring the distinction between a program as a set of instructions and a program as an assertion about the desired answer, which is the main feature of declarative programming. More refined paradigms include procedural programming, object-oriented programming, functional programming, and logic programming; some languages are hybrids of paradigms or multi-paradigmatic. An assembly language is not so much a paradigm as a direct model of an underlying machine architecture. By purpose, programming languages might be considered general purpose, system programming languages, scripting languages, domain-specific languages, or concurrent/distributed languages (or a combination of these). Some general purpose languages were designed largely with educational goals.

A programming language may also be classified by factors unrelated to the programming paradigm. For instance, most programming languages use English language keywords, while a minority do not. Other languages may be classified as being deliberately esoteric or not.

omputer science is the study of computation, information, and automation. Computer science spans theoretical disciplines (such as algorithms, theory of computation, and information theory) to applied disciplines (including the design and implementation of hardware and software). Though more often considered an academic discipline, computer science is closely related to computer programming.

Algorithms and data structures are central to computer science. The theory of computation concerns abstract models of computation and general classes of problems that can be solved using them. The fields of cryptography and computer security involve studying the means for secure communication and for preventing security vulnerabilities. Computer graphics and computational geometry address the generation of images. Programming language theory considers different ways to describe computational processes, and database theory concerns the management of repositories of data. Human–computer interaction investigates the interfaces through which humans and computers interact, and software engineering focuses on the design and principles behind developing software. Areas such as operating systems, networks and embedded systems investigate the principles and design behind complex systems. Computer architecture describes the construction of computer components and computer-operated equipment. Artificial intelligence and machine learning aim to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. Within artificial intelligence, computer vision aims to understand and process image and video data, while natural language processing aims to understand and process textual and linguistic data.

The fundamental concern of computer science is determining what can and cannot be automated. The Turing Award is generally recognized as the highest distinction in computer science.

The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.

Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623. In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner. Leibniz may be considered the first computer scientist and information theorist, because of various reasons, including the fact that he documented the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry[note 1] when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine. He started developing this machine in 1834, and "in less than two years, he had sketched out many of the salient features of the modern computer". "A crucial step was the adoption of a punched card system derived from the Jacquard loom" making it infinitely programmable.[note 2] In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer. Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published the 2nd of the only two designs for mechanical analytical engines in history. In 1937, one hundred years after Babbage's impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage's Analytical Engine, which itself used cards and a central computing unit. When the machine was finished, some hailed it as "Babbage's dream come true".

During the 1940s, with the development of new and more powerful computing machines such as the Atanasoff–Berry computer and ENIAC, the term computer came to refer to the machines rather than their human predecessors. As it became clear that computers could be used for more than just mathematical calculations, the field of computer science broadened to study computation in general. In 1945, IBM founded the Watson Scientific Computing Laboratory at Columbia University in New York City. The renovated fraternity house on Manhattan's West Side was IBM's first laboratory devoted to pure science. The lab is the forerunner of IBM's Research Division, which today operates research facilities around the world. Ultimately, the close relationship between IBM and Columbia University was instrumental in the emergence of a new scientific discipline, with Columbia offering one of the first academic-credit courses in computer science in 1946. Computer science began to be established as a distinct academic discipline in the 1950s and early 1960s. The world's first computer science degree program, the Cambridge Diploma in Computer Science, began at the University of Cambridge Computer Laboratory in 1953. The first computer science department in the United States was formed at Purdue University in 1962. Since practical computers became available, many applications of computing have become distinct areas of study in their own rights.

Although first proposed in 1956, the term "computer science" appears in a 1959 article in Communications of the ACM, in which Louis Fein argues for the creation of a Graduate School in Computer Sciences analogous to the creation of Harvard Business School in 1921. Louis justifies the name by arguing that, like management science, the subject is applied and interdisciplinary in nature, while having the characteristics typical of an academic discipline. His efforts, and those of others such as numerical analyst George Forsythe, were rewarded: universities went on to create such departments, starting with Purdue in 1962. Despite its name, a significant amount of computer science does not involve the study of computers themselves. Because of this, several alternative names have been proposed. Certain departments of major universities prefer the term computing science, to emphasize precisely that difference. Danish scientist Peter Naur suggested the term datalogy, to reflect the fact that the scientific discipline revolves around data and data treatment, while not necessarily involving computers. The first scientific institution to use the term was the Department of Datalogy at the University of Copenhagen, founded in 1969, with Peter Naur being the first professor in datalogy. The term is used mainly in the Scandinavian countries. An alternative term, also proposed by Naur, is data science; this is now used for a multi-disciplinary field of data analysis, including statistics and databases.

In the early days of computing, a number of terms for the practitioners of the field of computing were suggested in the Communications of the ACM—turingineer, turologist, flow-charts-man, applied meta-mathematician, and applied epistemologist. Three months later in the same journal, comptologist was suggested, followed next year by hypologist. The term computics has also been suggested. In Europe, terms derived from contracted translations of the expression "automatic information" (e.g. "informazione automatica" in Italian) or "information and mathematics" are often used, e.g. informatique (French), Informatik (German), informatica (Italian, Dutch), informática (Spanish, Portuguese), informatika (Slavic languages and Hungarian) or pliroforiki (πληροφορική, which means informatics) in Greek. Similar words have also been adopted in the UK (as in the School of Informatics, University of Edinburgh). "In the U.S., however, informatics is linked with applied computing, or computing in the context of another domain."

A folkloric quotation, often attributed to—but almost certainly not first formulated by—Edsger Dijkstra, states that "computer science is no more about computers than astronomy is about telescopes."[note 3] The design and deployment of computers and computer systems is generally considered the province of disciplines other than computer science. For example, the study of computer hardware is usually considered part of computer engineering, while the study of commercial computer systems and their deployment is often called information technology or information systems. However, there has been exchange of ideas between the various computer-related disciplines. Computer science research also often intersects other disciplines, such as cognitive science, linguistics, mathematics, physics, biology, Earth science, statistics, philosophy, and logic.

Computer science is considered by some to have a much closer relationship with mathematics than many scientific disciplines, with some observers saying that computing is a mathematical science. Early computer science was strongly influenced by the work of mathematicians such as Kurt Gödel, Alan Turing, John von Neumann, Rózsa Péter and Alonzo Church and there continues to be a useful interchange of ideas between the two fields in areas such as mathematical logic, category theory, domain theory, and algebra.

The relationship between Computer Science and Software Engineering is a contentious issue, which is further muddied by disputes over what the term "Software Engineering" means, and how computer science is defined. David Parnas, taking a cue from the relationship between other engineering and science disciplines, has claimed that the principal focus of computer science is studying the properties of computation in general, while the principal focus of software engineering is the design of specific computations to achieve practical goals, making the two separate but complementary disciplines.

The academic, political, and funding aspects of computer science tend to depend on whether a department is formed with a mathematical emphasis or with an engineering emphasis. Computer science departments with a mathematics emphasis and with a numerical orientation consider alignment with computational science. Both types of departments tend to make efforts to bridge the field educationally if not across all research.

Despite the word "science" in its name, there is debate over whether or not computer science is a discipline of science, mathematics, or engineering. Allen Newell and Herbert A. Simon argued in 1975,
Computer science is an empirical discipline. We would have called it an experimental science, but like astronomy, economics, and geology, some of its unique forms of observation and experience do not fit a narrow stereotype of the experimental method. Nonetheless, they are experiments. Each new machine that is built is an experiment. Actually constructing the machine poses a question to nature; and we listen for the answer by observing the machine in operation and analyzing it by all analytical and measurement means available.

It has since been argued that computer science can be classified as an empirical science since it makes use of empirical testing to evaluate the correctness of programs, but a problem remains in defining the laws and theorems of computer science (if any exist) and defining the nature of experiments in computer science. Proponents of classifying computer science as an engineering discipline argue that the reliability of computational systems is investigated in the same way as bridges in civil engineering and airplanes in aerospace engineering. They also argue that while empirical sciences observe what presently exists, computer science observes what is possible to exist and while scientists discover laws from observation, no proper laws have been found in computer science and it is instead concerned with creating phenomena.

Proponents of classifying computer science as a mathematical discipline argue that computer programs are physical realizations of mathematical entities and programs can be deductively reasoned through mathematical formal methods. Computer scientists Edsger W. Dijkstra and Tony Hoare regard instructions for computer programs as mathematical sentences and interpret formal semantics for programming languages as mathematical axiomatic systems.

A number of computer scientists have argued for the distinction of three separate paradigms in computer science. Peter Wegner argued that those paradigms are science, technology, and mathematics. Peter Denning's working group argued that they are theory, abstraction (modeling), and design. Amnon H. Eden described them as the "rationalist paradigm" (which treats computer science as a branch of mathematics, which is prevalent in theoretical computer science, and mainly employs deductive reasoning), the "technocratic paradigm" (which might be found in engineering approaches, most prominently in software engineering), and the "scientific paradigm" (which approaches computer-related artifacts from the empirical perspective of natural sciences, identifiable in some branches of artificial intelligence). Computer science focuses on methods involved in design, specification, programming, verification, implementation and testing of human-made computing systems.

As a discipline, computer science spans a range of topics from theoretical studies of algorithms and the limits of computation to the practical issues of implementing computing systems in hardware and software. CSAB, formerly called Computing Sciences Accreditation Board—which is made up of representatives of the Association for Computing Machinery (ACM), and the IEEE Computer Society (IEEE CS)—identifies four areas that it considers crucial to the discipline of computer science: theory of computation, algorithms and data structures, programming methodology and languages, and computer elements and architecture. In addition to these four areas, CSAB also identifies fields such as software engineering, artificial intelligence, computer networking and communication, database systems, parallel computation, distributed computation, human–computer interaction, computer graphics, operating systems, and numerical and symbolic computation as being important areas of computer science.

Theoretical Computer Science is mathematical and abstract in spirit, but it derives its motivation from the practical and everyday computation. Its aim is to understand the nature of computation and, as a consequence of this understanding, provide more efficient methodologies.

According to Peter Denning, the fundamental question underlying computer science is, "What can be automated?" Theory of computation is focused on answering fundamental questions about what can be computed and what amount of resources are required to perform those computations. In an effort to answer the first question, computability theory examines which computational problems are solvable on various theoretical models of computation. The second question is addressed by computational complexity theory, which studies the time and space costs associated with different approaches to solving a multitude of computational problems.

The famous P = NP? problem, one of the Millennium Prize Problems, is an open problem in the theory of computation.

Information theory, closely related to probability and statistics, is related to the quantification of information. This was developed by Claude Shannon to find fundamental limits on signal processing operations such as compressing data and on reliably storing and communicating data. Coding theory is the study of the properties of codes (systems for converting information from one form to another) and their fitness for a specific application. Codes are used for data compression, cryptography, error detection and correction, and more recently also for network coding. Codes are studied for the purpose of designing efficient and reliable data transmission methods. 

Programming language theory is a branch of computer science that deals with the design, implementation, analysis, characterization, and classification of programming languages and their individual features. It falls within the discipline of computer science, both depending on and affecting mathematics, software engineering, and linguistics. It is an active research area, with numerous dedicated academic journals.

Formal methods are a particular kind of mathematically based technique for the specification, development and verification of software and hardware systems. The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design. They form an important theoretical underpinning for software engineering, especially where safety or security is involved. Formal methods are a useful adjunct to software testing since they help avoid errors and can also give a framework for testing. For industrial use, tool support is required. However, the high cost of using formal methods means that they are usually only used in the development of high-integrity and life-critical systems, where safety or security is of utmost importance. Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification.

Computer graphics is the study of digital visual contents and involves the synthesis and manipulation of image data. The study is connected to many other fields in computer science, including computer vision, image processing, and computational geometry, and is heavily applied in the fields of special effects and video games.

Scientific computing (or computational science) is the field of study concerned with constructing mathematical models and quantitative analysis techniques and using computers to analyze and solve scientific problems. A major usage of scientific computing is simulation of various processes, including computational fluid dynamics, physical, electrical, and electronic systems and circuits, as well as societies and social situations (notably war games) along with their habitats, among many others. Modern computers enable optimization of such designs as complete aircraft. Notable in electrical and electronic circuit design are SPICE, as well as software for physical realization of new (or modified) designs. The latter includes essential design software for integrated circuits.

Social computing and human–computer interaction
Main articles: Social computing and Human–computer interaction
Social computing is an area that is concerned with the intersection of social behavior and computational systems. Human–computer interaction research develops theories, principles, and guidelines for user interface designers.

Software engineering
Main article: Software engineering
See also: Computer programming
Software engineering is the study of designing, implementing, and modifying the software in order to ensure it is of high quality, affordable, maintainable, and fast to build. It is a systematic approach to software design, involving the application of engineering practices to software. Software engineering deals with the organizing and analyzing of software—it does not just deal with the creation or manufacture of new software, but its internal arrangement and maintenance. For example software testing, systems engineering, technical debt and software development processes.

Artificial intelligence
Main articles: Artificial intelligence and Bio-inspired computing
Artificial intelligence (AI) aims to or is required to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, learning, and communication found in humans and animals. From its origins in cybernetics and in the Dartmouth Conference (1956), artificial intelligence research has been necessarily cross-disciplinary, drawing on areas of expertise such as applied mathematics, symbolic logic, semiotics, electrical engineering, philosophy of mind, neurophysiology, and social intelligence. AI is associated in the popular mind with robotic development, but the main field of practical application has been as an embedded component in areas of software development, which require computational understanding. The starting point in the late 1940s was Alan Turing's question "Can computers think?", and the question remains effectively unanswered, although the Turing test is still used to assess computer output on the scale of human intelligence. But the automation of evaluative and predictive tasks has been increasingly successful as a substitute for human monitoring and intervention in domains of computer application involving complex real-world data.

Computer systems
Computer architecture and organization
Main articles: Computer architecture, Computer organisation, and Computer engineering
Computer architecture, or digital computer organization, is the conceptual design and fundamental operational structure of a computer system. It focuses largely on the way by which the central processing unit performs internally and accesses addresses in memory. Computer engineers study computational logic and design of computer hardware, from individual processor components, microcontrollers, personal computers to supercomputers and embedded systems. The term "architecture" in computer literature can be traced to the work of Lyle R. Johnson and Frederick P. Brooks, Jr., members of the Machine Organization department in IBM's main research center in 1959.

Concurrent, parallel and distributed computing
Main articles: Concurrency (computer science) and Distributed computing
Concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. A number of mathematical models have been developed for general concurrent computation including Petri nets, process calculi and the Parallel Random Access Machine model. When multiple computers are connected in a network while using concurrency, this is known as a distributed system. Computers within that distributed system have their own private memory, and information can be exchanged to achieve common goals.

Computer networks
Main article: Computer network
This branch of computer science aims to manage networks between computers worldwide.

Computer security and cryptography
Main articles: Computer security and Cryptography
Computer security is a branch of computer technology with the objective of protecting information from unauthorized access, disruption, or modification while maintaining the accessibility and usability of the system for its intended users.

Historical cryptography is the art of writing and deciphering secret messages. Modern cryptography is the scientific study of problems relating to distributed computations that can be attacked. Technologies studied in modern cryptography include symmetric and asymmetric encryption, digital signatures, cryptographic hash functions, key-agreement protocols, blockchain, zero-knowledge proofs, and garbled circuits.

Databases and data mining
Main articles: Database and Data mining
A database is intended to organize, store, and retrieve large amounts of data easily. Digital databases are managed using database management systems to store, create, maintain, and search data, through database models and query languages. Data mining is a process of discovering patterns in large data sets.

Discoveries
The philosopher of computing Bill Rapaport noted three Great Insights of Computer Science:

Gottfried Wilhelm Leibniz's, George Boole's, Alan Turing's, Claude Shannon's, and Samuel Morse's insight: there are only two objects that a computer has to deal with in order to represent "anything".[note 4]
All the information about any computable problem can be represented using only 0 and 1 (or any other bistable pair that can flip-flop between two easily distinguishable states, such as "on/off", "magnetized/de-magnetized", "high-voltage/low-voltage", etc.).
See also: Digital physics
Alan Turing's insight: there are only five actions that a computer has to perform in order to do "anything".
Every algorithm can be expressed in a language for a computer consisting of only five basic instructions:
move left one location;
move right one location;
read symbol at current location;
print 0 at current location;
print 1 at current location.
See also: Turing machine
Corrado Böhm and Giuseppe Jacopini's insight: there are only three ways of combining these actions (into more complex ones) that are needed in order for a computer to do "anything".
Only three rules are needed to combine any set of basic instructions into more complex ones:
sequence: first do this, then do that;
selection: IF such-and-such is the case, THEN do this, ELSE do that;
repetition: WHILE such-and-such is the case, DO this.
Note that the three rules of Boehm's and Jacopini's insight can be further simplified with the use of goto (which means it is more elementary than structured programming).
See also: Structured program theorem
Programming paradigms
Main article: Programming paradigm
Programming languages can be used to accomplish different tasks in different ways. Common programming paradigms include:

Functional programming, a style of building the structure and elements of computer programs that treats computation as the evaluation of mathematical functions and avoids state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations instead of statements.
Imperative programming, a programming paradigm that uses statements that change a program's state. In much the same way that the imperative mood in natural languages expresses commands, an imperative program consists of commands for the computer to perform. Imperative programming focuses on describing how a program operates.
Object-oriented programming, a programming paradigm based on the concept of "objects", which may contain data, in the form of fields, often known as attributes; and code, in the form of procedures, often known as methods. A feature of objects is that an object's procedures can access and often modify the data fields of the object with which they are associated. Thus object-oriented computer programs are made out of objects that interact with one another.
Service-oriented programming, a programming paradigm that uses "services" as the unit of computer work, to design and implement integrated business applications and mission critical software programs
Many languages offer support for multiple paradigms, making the distinction more a matter of style than of technical capabilities.

Research
Further information: List of computer science conferences and Category:Computer science journals
Conferences are important events for computer science research. During these conferences, researchers from the public and private sectors present their recent work and meet. Unlike in most other academic fields, in computer science, the prestige of conference papers is greater than that of journal publications. One proposed explanation for this is the quick development of this relatively new field requires rapid review and distribution of results, a task better handled by conferences than by journals.

Education
Main article: Computer science education
Computer Science, known by its near synonyms, Computing, Computer Studies, has been taught in UK schools since the days of batch processing, mark sensitive cards and paper tape but usually to a select few students. In 1981, the BBC produced a micro-computer and classroom network and Computer Studies became common for GCE O level students (11–16-year-old), and Computer Science to A level students. Its importance was recognised, and it became a compulsory part of the National Curriculum, for Key Stage 3 & 4. In September 2014 it became an entitlement for all pupils over the age of 4.

In the US, with 14,000 school districts deciding the curriculum, provision was fractured. According to a 2010 report by the Association for Computing Machinery (ACM) and Computer Science Teachers Association (CSTA), only 14 out of 50 states have adopted significant education standards for high school computer science. According to a 2021 report, only 51% of high schools in the US offer computer science.

Israel, New Zealand, and South Korea have included computer science in their national secondary education curricula, and several others are following.

Ancient algorithms
Since antiquity, step-by-step procedures for solving mathematical problems have been attested. This includes Babylonian mathematics (around 2500 BC), Egyptian mathematics (around 1550 BC), Indian mathematics (around 800 BC and later; e.g. Shulba Sutras, Kerala School, and Brāhmasphuṭasiddhānta), Greek mathematics (around 240 BC, e.g. sieve of Eratosthenes and Euclidean algorithm), and Arabic mathematics (9th century, e.g. cryptographic algorithms for code-breaking based on frequency analysis).

Al-khwarizmi and the term algorithm
Around 825, Muhammad ibn Musa al-Khwarizmi wrote kitāb al-ḥisāb al-hindī ("Book of Indian computation") and kitab al-jam' wa'l-tafriq al-ḥisāb al-hindī ("Addition and subtraction in Indian arithmetic"). Both of these texts are lost in the original Arabic at this time. (However, his other book on algebra remains.)

In the early 12th century, Latin translations of said al-Khwarizmi texts involving the Hindu–Arabic numeral system and arithmetic appeared: Liber Alghoarismi de practica arismetrice (attributed to John of Seville) and Liber Algorismi de numero Indorum (attributed to Adelard of Bath). Hereby, alghoarismi or algorismi is the Latinization of Al-Khwarizmi's name; the text starts with the phrase Dixit Algorismi ("Thus spoke Al-Khwarizmi").

In 1240, Alexander of Villedieu writes a Latin text titled Carmen de Algorismo. It begins with:

Haec algorismus ars praesens dicitur, in qua / Talibus Indorum fruimur bis quinque figuris.

which translates to:

Algorism is the art by which at present we use those Indian figures, which number two times five.

The poem is a few hundred lines long and summarizes the art of calculating with the new styled Indian dice (Tali Indorum), or Hindu numerals.

English evolution of the word
Around 1230, the English word algorism is attested and then by Chaucer in 1391. English adopted the French term.

In the 15th century, under the influence of the Greek word ἀριθμός (arithmos, "number"; cf. "arithmetic"), the Latin word was altered to algorithmus.

In 1656, in the English dictionary Glossographia, it says:

Algorism ([Latin] algorismus) the Art or use of Cyphers, or of numbering by Cyphers; skill in accounting.

Augrime ([Latin] algorithmus) skil in accounting or numbring.

In 1658, in the first edition of The New World of English Words, it says:

Algorithme, (a word compounded of Arabick and Spanish,) the art of reckoning by Cyphers.

In 1706, in the sixth edition of The New World of English Words, it says:

Algorithm, the Art of computing or reckoning by numbers, which contains the five principle Rules of Arithmetick, viz. Numeration, Addition, Subtraction, Multiplication and Division; to which may be added Extraction of Roots: It is also call'd Logistica Numeralis.

Algorism, the practical Operation in the several Parts of Specious Arithmetick or Algebra; sometimes it is taken for the Practice of Common Arithmetick by the ten Numeral Figures.

In 1751, in the Young Algebraist's Companion, Daniel Fenning contrasts the terms algorism and algorithm as follows:

Algorithm signifies the first Principles, and Algorism the practical Part, or knowing how to put the Algorithm in Practice.

Since at least 1811, the term algorithm is attested to mean a "step-by-step procedure" in English.

In 1842, in the Dictionary of Science, Literature and Art, it says:

ALGORITHM, signifies the art of computing in reference to some particular subject, or in some particular way; as the algorithm of numbers; the algorithm of the differential calculus.

Machine usage
In 1928, a partial formalization of the modern concept of algorithm began with attempts to solve the Entscheidungsproblem (decision problem) posed by David Hilbert. Later formalizations were framed as attempts to define "effective calculability" or "effective method". Those formalizations included the Gödel–Herbrand–Kleene recursive functions of 1930, 1934 and 1935, Alonzo Church's lambda calculus of 1936, Emil Post's Formulation 1 of 1936, and Alan Turing's Turing machines of 1936–37 and 1939.

Informal definition
For a detailed presentation of the various points of view on the definition of "algorithm", see Algorithm characterizations.
An informal definition could be "a set of rules that precisely defines a sequence of operations",[need quotation to verify] which would include all computer programs (including programs that do not perform numeric calculations), and (for example) any prescribed bureaucratic procedure or cook-book recipe.

In general, a program is only an algorithm if it stops eventually—even though infinite loops may sometimes prove desirable.

A prototypical example of an algorithm is the Euclidean algorithm, which is used to determine the maximum common divisor of two integers; an example (there are others) is described by the flowchart above and as an example in a later section.

Boolos, Jeffrey & 1974, 1999 offer an informal meaning of the word "algorithm" in the following quotation:

No human being can write fast enough, or long enough, or small enough† ( †"smaller and smaller without limit ... you'd be trying to write on molecules, on atoms, on electrons") to list all members of an enumerably infinite set by writing out their names, one after another, in some notation. But humans can do something equally useful, in the case of certain enumerably infinite sets: They can give explicit instructions for determining the nth member of the set, for arbitrary finite n. Such instructions are to be given quite explicitly, in a form in which they could be followed by a computing machine, or by a human who is capable of carrying out only very elementary operations on symbols.

An "enumerably infinite set" is one whose elements can be put into one-to-one correspondence with the integers. Thus Boolos and Jeffrey are saying that an algorithm implies instructions for a process that "creates" output integers from an arbitrary "input" integer or integers that, in theory, can be arbitrarily large. For example, an algorithm can be an algebraic equation such as y = m + n (i.e., two arbitrary "input variables" m and n that produce an output y), but various authors' attempts to define the notion indicate that the word implies much more than this, something on the order of (for the addition example):

Precise instructions (in a language understood by "the computer") for a fast, efficient, "good" process that specifies the "moves" of "the computer" (machine or human, equipped with the necessary internally contained information and capabilities) to find, decode, and then process arbitrary input integers/symbols m and n, symbols + and = ... and "effectively" produce, in a "reasonable" time, output-integer y at a specified place and in a specified format.
The concept of algorithm is also used to define the notion of decidability—a notion that is central for explaining how formal systems come into being starting from a small set of axioms and rules. In logic, the time that an algorithm requires to complete cannot be measured, as it is not apparently related to the customary physical dimension. From such uncertainties, that characterize ongoing work, stems the unavailability of a definition of algorithm that suits both concrete (in some sense) and abstract usage of the term.

Most algorithms are intended to be implemented as computer programs. However, algorithms are also implemented by other means, such as in a biological neural network (for example, the human brain implementing arithmetic or an insect looking for food), in an electrical circuit, or in a mechanical device.

Formalization
Algorithms are essential to the way computers process data. Many computer programs contain algorithms that detail the specific instructions a computer should perform—in a specific order—to carry out a specified task, such as calculating employees' paychecks or printing students' report cards. Thus, an algorithm can be considered to be any sequence of operations that can be simulated by a Turing-complete system. Authors who assert this thesis include Minsky (1967), Savage (1987), and Gurevich (2000):

Minsky: "But we will also maintain, with Turing ... that any procedure which could "naturally" be called effective, can, in fact, be realized by a (simple) machine. Although this may seem extreme, the arguments ... in its favor are hard to refute". Gurevich: "… Turing's informal argument in favor of his thesis justifies a stronger thesis: every algorithm can be simulated by a Turing machine … according to Savage , an algorithm is a computational process defined by a Turing machine".

Turing machines can define computational processes that do not terminate. The informal definitions of algorithms generally require that the algorithm always terminates. This requirement renders the task of deciding whether a formal procedure is an algorithm impossible in the general case—due to a major theorem of computability theory known as the halting problem.

Typically, when an algorithm is associated with processing information, data can be read from an input source, written to an output device and stored for further processing. Stored data are regarded as part of the internal state of the entity performing the algorithm. In practice, the state is stored in one or more data structures.

For some of these computational processes, the algorithm must be rigorously defined: and specified in the way it applies in all possible circumstances that could arise. This means that any conditional steps must be systematically dealt with, case by case; the criteria for each case must be clear (and computable).

Because an algorithm is a precise list of precise steps, the order of computation is always crucial to the functioning of the algorithm. Instructions are usually assumed to be listed explicitly, and are described as starting "from the top" and going "down to the bottom"—an idea that is described more formally by flow of control.

So far, the discussion on the formalization of an algorithm has assumed the premises of imperative programming. This is the most common conception—one which attempts to describe a task in discrete, "mechanical" means. Unique to this conception of formalized algorithms is the assignment operation, which sets the value of a variable. It derives from the intuition of "memory" as a scratchpad. An example of such an assignment can be found below.

For some alternate conceptions of what constitutes an algorithm, see functional programming and logic programming.

Expressing algorithms
Algorithms can be expressed in many kinds of notation, including natural languages, pseudocode, flowcharts, drakon-charts, programming languages or control tables (processed by interpreters). Natural language expressions of algorithms tend to be verbose and ambiguous, and are rarely used for complex or technical algorithms. Pseudocode, flowcharts, drakon-charts and control tables are structured ways to express algorithms that avoid many of the ambiguities common in the statements based on natural language. Programming languages are primarily intended for expressing algorithms in a form that can be executed by a computer, but are also often used as a way to define or document algorithms.

There is a wide variety of representations possible and one can express a given Turing machine program as a sequence of machine tables (see finite-state machine, state transition table and control table for more), as flowcharts and drakon-charts (see state diagram for more), or as a form of rudimentary machine code or assembly code called "sets of quadruples" (see Turing machine for more).

Representations of algorithms can be classed into three accepted levels of Turing machine description, as follows:

1 High-level description
"...prose to describe an algorithm, ignoring the implementation details. At this level, we do not need to mention how the machine manages its tape or head."
2 Implementation description
"...prose used to define the way the Turing machine uses its head and the way that it stores data on its tape. At this level, we do not give details of states or transition function."
3 Formal description
Most detailed, "lowest level", gives the Turing machine's "state table".
For an example of the simple algorithm "Add m+n" described in all three levels, see Examples.

Design
See also: Algorithm § By design paradigm
Algorithm design refers to a method or a mathematical process for problem-solving and engineering algorithms. The design of algorithms is part of many solution theories, such as divide-and-conquer or dynamic programming within operation research. Techniques for designing and implementing algorithm designs are also called algorithm design patterns, with examples including the template method pattern and the decorator pattern.

One of the most important aspects of algorithm design is resource (run-time, memory usage) efficiency; the big O notation is used to describe e.g. an algorithm's run-time growth as the size of its input increases.

Typical steps in the development of algorithms:

Problem definition
Development of a model
Specification of the algorithm
Designing an algorithm
Checking the correctness of the algorithm
Analysis of algorithm
Implementation of algorithm
Program testing
Documentation preparation[clarification needed]
Computer algorithms

Logical NAND algorithm implemented electronically in 7400 chip

Flowchart examples of the canonical Böhm-Jacopini structures: the SEQUENCE (rectangles descending the page), the WHILE-DO and the IF-THEN-ELSE. The three structures are made of the primitive conditional GOTO (IF test THEN GOTO step xxx, shown as diamond), the unconditional GOTO (rectangle), various assignment operators (rectangle), and HALT (rectangle). Nesting of these structures inside assignment-blocks results in complex diagrams (cf. Tausworthe 1977:100, 114).
"Elegant" (compact) programs, "good" (fast) programs : The notion of "simplicity and elegance" appears informally in Knuth and precisely in Chaitin:

Knuth: " ... we want good algorithms in some loosely defined aesthetic sense. One criterion ... is the length of time taken to perform the algorithm .... Other criteria are adaptability of the algorithm to computers, its simplicity, and elegance, etc."
Chaitin: " ... a program is 'elegant,' by which I mean that it's the smallest possible program for producing the output that it does"
Chaitin prefaces his definition with: "I'll show you can't prove that a program is 'elegant'"—such a proof would solve the Halting problem (ibid).

Algorithm versus function computable by an algorithm: For a given function multiple algorithms may exist. This is true, even without expanding the available instruction set available to the programmer. Rogers observes that "It is ... important to distinguish between the notion of algorithm, i.e. procedure and the notion of function computable by algorithm, i.e. mapping yielded by procedure. The same function may have several different algorithms".

Unfortunately, there may be a tradeoff between goodness (speed) and elegance (compactness)—an elegant program may take more steps to complete a computation than one less elegant. An example that uses Euclid's algorithm appears below.

Computers (and computors), models of computation: A computer (or human "computer") is a restricted type of machine, a "discrete deterministic mechanical device" that blindly follows its instructions. Melzak's and Lambek's primitive models reduced this notion to four elements: (i) discrete, distinguishable locations, (ii) discrete, indistinguishable counters (iii) an agent, and (iv) a list of instructions that are effective relative to the capability of the agent.

Minsky describes a more congenial variation of Lambek's "abacus" model in his "Very Simple Bases for Computability". Minsky's machine proceeds sequentially through its five (or six, depending on how one counts) instructions unless either a conditional IF-THEN GOTO or an unconditional GOTO changes program flow out of sequence. Besides HALT, Minsky's machine includes three assignment (replacement, substitution) operations: ZERO (e.g. the contents of location replaced by 0: L ← 0), SUCCESSOR (e.g. L ← L+1), and DECREMENT (e.g. L ← L − 1). Rarely must a programmer write "code" with such a limited instruction set. But Minsky shows (as do Melzak and Lambek) that his machine is Turing complete with only four general types of instructions: conditional GOTO, unconditional GOTO, assignment/replacement/substitution, and HALT. However, a few different assignment instructions (e.g. DECREMENT, INCREMENT, and ZERO/CLEAR/EMPTY for a Minsky machine) are also required for Turing-completeness; their exact specification is somewhat up to the designer. The unconditional GOTO is convenient; it can be constructed by initializing a dedicated location to zero e.g. the instruction " Z ← 0 "; thereafter the instruction IF Z=0 THEN GOTO xxx is unconditional.

Simulation of an algorithm: computer (computor) language: Knuth advises the reader that "the best way to learn an algorithm is to try it . . . immediately take pen and paper and work through an example". But what about a simulation or execution of the real thing? The programmer must translate the algorithm into a language that the simulator/computer/computor can effectively execute. Stone gives an example of this: when computing the roots of a quadratic equation the computer must know how to take a square root. If they don't, then the algorithm, to be effective, must provide a set of rules for extracting a square root.

This means that the programmer must know a "language" that is effective relative to the target computing agent (computer/computor).

But what model should be used for the simulation? Van Emde Boas observes "even if we base complexity theory on abstract instead of concrete machines, the arbitrariness of the choice of a model remains. It is at this point that the notion of simulation enters". When speed is being measured, the instruction set matters. For example, the subprogram in Euclid's algorithm to compute the remainder would execute much faster if the programmer had a "modulus" instruction available rather than just subtraction (or worse: just Minsky's "decrement").

Structured programming, canonical structures: Per the Church–Turing thesis, any algorithm can be computed by a model known to be Turing complete, and per Minsky's demonstrations, Turing completeness requires only four instruction types—conditional GOTO, unconditional GOTO, assignment, HALT. Kemeny and Kurtz observe that, while "undisciplined" use of unconditional GOTOs and conditional IF-THEN GOTOs can result in "spaghetti code", a programmer can write structured programs using only these instructions; on the other hand "it is also possible, and not too hard, to write badly structured programs in a structured language". Tausworthe augments the three Böhm-Jacopini canonical structures: SEQUENCE, IF-THEN-ELSE, and WHILE-DO, with two more: DO-WHILE and CASE. An additional benefit of a structured program is that it lends itself to proofs of correctness using mathematical induction.

Canonical flowchart symbols: The graphical aide called a flowchart offers a way to describe and document an algorithm (and a computer program corresponding to it). Like the program flow of a Minsky machine, a flowchart always starts at the top of a page and proceeds down. Its primary symbols are only four: the directed arrow showing program flow, the rectangle (SEQUENCE, GOTO), the diamond (IF-THEN-ELSE), and the dot (OR-tie). The Böhm–Jacopini canonical structures are made of these primitive shapes. Sub-structures can "nest" in rectangles, but only if a single exit occurs from the superstructure. The symbols and their use to build the canonical structures are shown in the diagram.

Examples
Further information: List of algorithms
Algorithm example
One of the simplest algorithms is to find the largest number in a list of numbers of random order. Finding the solution requires looking at every number in the list. From this follows a simple algorithm, which can be stated in a high-level description in English prose, as:

High-level description:

If there are no numbers in the set, then there is no highest number.
Assume the first number in the set is the largest number in the set.
For each remaining number in the set: if this number is larger than the current largest number, consider this number to be the largest number in the set.
When there are no numbers left in the set to iterate over, consider the current largest number to be the largest number of the set.
(Quasi-)formal description: Written in prose but much closer to the high-level language of a computer program, the following is the more formal coding of the algorithm in pseudocode or pidgin code:

Algorithm LargestNumber
Input: A list of numbers L.
Output: The largest number in the list L.
if L.size = 0 return null
largest ← L
for each item in L, do
    if item > largest, then
        largest ← item
return largest
"←" denotes assignment. For instance, "largest ← item" means that the value of largest changes to the value of item.
"return" terminates the algorithm and outputs the following value.
Euclid's algorithm
Further information: Euclid's algorithm
In mathematics, the Euclidean algorithm or Euclid's algorithm, is an efficient method for computing the greatest common divisor (GCD) of two integers (numbers), the largest number that divides them both without a remainder. It is named after the ancient Greek mathematician Euclid, who first described it in his Elements (c. 300 BC). It is one of the oldest algorithms in common use. It can be used to reduce fractions to their simplest form, and is a part of many other number-theoretic and cryptographic calculations.


The example-diagram of Euclid's algorithm from T.L. Heath (1908), with more detail added. Euclid does not go beyond a third measuring and gives no numerical examples. Nicomachus gives the example of 49 and 21: "I subtract the less from the greater; 28 is left; then again I subtract from this the same 21 (for this is possible); 7 is left; I subtract this from 21, 14 is left; from which I again subtract 7 (for this is possible); 7 is left, but 7 cannot be subtracted from 7." Heath comments that "The last phrase is curious, but the meaning of it is obvious enough, as also the meaning of the phrase about ending 'at one and the same number'."(Heath 1908:300).
Euclid poses the problem thus: "Given two numbers not prime to one another, to find their greatest common measure". He defines "A number [to be] a multitude composed of units": a counting number, a positive integer not including zero. To "measure" is to place a shorter measuring length s successively (q times) along longer length l until the remaining portion r is less than the shorter length s. In modern words, remainder r = l − q×s, q being the quotient, or remainder r is the "modulus", the integer-fractional part left over after the division.

For Euclid's method to succeed, the starting lengths must satisfy two requirements: (i) the lengths must not be zero, AND (ii) the subtraction must be "proper"; i.e., a test must guarantee that the smaller of the two numbers is subtracted from the larger (or the two can be equal so their subtraction yields zero).

Euclid's original proof adds a third requirement: the two lengths must not be prime to one another. Euclid stipulated this so that he could construct a reductio ad absurdum proof that the two numbers' common measure is in fact the greatest. While Nicomachus' algorithm is the same as Euclid's, when the numbers are prime to one another, it yields the number "1" for their common measure. So, to be precise, the following is really Nicomachus' algorithm.


A graphical expression of Euclid's algorithm to find the greatest common divisor for 1599 and 650
 1599 = 650×2 + 299
 650 = 299×2 + 52
 299 = 52×5 + 39
 52 = 39×1 + 13
 39 = 13×3 + 0
Computer language for Euclid's algorithm
Only a few instruction types are required to execute Euclid's algorithm—some logical tests (conditional GOTO), unconditional GOTO, assignment (replacement), and subtraction.

A location is symbolized by upper case letter(s), e.g. S, A, etc.
The varying quantity (number) in a location is written in lower case letter(s) and (usually) associated with the location's name. For example, location L at the start might contain the number l = 3009.
An inelegant program for Euclid's algorithm

"Inelegant" is a translation of Knuth's version of the algorithm with a subtraction-based remainder-loop replacing his use of division (or a "modulus" instruction). Derived from Knuth 1973:2–4. Depending on the two numbers "Inelegant" may compute the g.c.d. in fewer steps than "Elegant".
The following algorithm is framed as Knuth's four-step version of Euclid's and Nicomachus', but, rather than using division to find the remainder, it uses successive subtractions of the shorter length s from the remaining length r until r is less than s. The high-level description, shown in boldface, is adapted from Knuth 1973:2–4:

INPUT:

1 [Into two locations L and S put the numbers l and s that represent the two lengths]:
INPUT L, S
2 [Initialize R: make the remaining length r equal to the starting/initial/input length l]:
R ← L
E0: [Ensure r ≥ s.]

3 [Ensure the smaller of the two numbers is in S and the larger in R]:
IF R > S THEN
the contents of L is the larger number so skip over the exchange-steps 4, 5 and 6:
GOTO step 7
ELSE
swap the contents of R and S.
4 L ← R (this first step is redundant, but is useful for later discussion).
5 R ← S
6 S ← L
E1: [Find remainder]: Until the remaining length r in R is less than the shorter length s in S, repeatedly subtract the measuring number s in S from the remaining length r in R.

7 IF S > R THEN
done measuring so
GOTO 10
ELSE
measure again,
8 R ← R − S
9 [Remainder-loop]:
GOTO 7.
E2: [Is the remainder zero?]: EITHER (i) the last measure was exact, the remainder in R is zero, and the program can halt, OR (ii) the algorithm must continue: the last measure left a remainder in R less than measuring number in S.

10 IF R = 0 THEN
done so
GOTO step 15
ELSE
CONTINUE TO step 11,
E3: [Interchange s and r]: The nut of Euclid's algorithm. Use remainder r to measure what was previously smaller number s; L serves as a temporary location.

11 L ← R
12 R ← S
13 S ← L
14 [Repeat the measuring process]:
GOTO 7
OUTPUT:

15 [Done. S contains the greatest common divisor]:
PRINT S
DONE:

16 HALT, END, STOP.
An elegant program for Euclid's algorithm
The following version of Euclid's algorithm requires only six core instructions to do what thirteen are required to do by "Inelegant"; worse, "Inelegant" requires more types of instructions.[clarify] The flowchart of "Elegant" can be found at the top of this article. In the (unstructured) Basic language, the steps are numbered, and the instruction LET  =  is the assignment instruction symbolized by ←.

  5 REM Euclid's algorithm for greatest common divisor
  6 PRINT "Type two integers greater than 0"
  10 INPUT A,B
  20 IF B=0 THEN GOTO 80
  30 IF A > B THEN GOTO 60
  40 LET B=B-A
  50 GOTO 20
  60 LET A=A-B
  70 GOTO 20
  80 PRINT A
  90 END
How "Elegant" works: In place of an outer "Euclid loop", "Elegant" shifts back and forth between two "co-loops", an A > B loop that computes A ← A − B, and a B ≤ A loop that computes B ← B − A. This works because, when at last the minuend M is less than or equal to the subtrahend S (Difference = Minuend − Subtrahend), the minuend can become s (the new measuring length) and the subtrahend can become the new r (the length to be measured); in other words the "sense" of the subtraction reverses.

The following version can be used with programming languages from the C-family:

// Euclid's algorithm for greatest common divisor
int euclidAlgorithm (int A, int B) {
     A = abs(A);
     B = abs(B);
     while (B != 0) {
          while (A > B) {
               A = A-B;
          }
          B = B-A;
     }
     return A;
}
Testing the Euclid algorithms
Does an algorithm do what its author wants it to do? A few test cases usually give some confidence in the core functionality. But tests are not enough. For test cases, one source uses 3009 and 884. Knuth suggested 40902, 24140. Another interesting case is the two relatively prime numbers 14157 and 5950.

But "exceptional cases" must be identified and tested. Will "Inelegant" perform properly when R > S, S > R, R = S? Ditto for "Elegant": B > A, A > B, A = B? (Yes to all). What happens when one number is zero, both numbers are zero? ("Inelegant" computes forever in all cases; "Elegant" computes forever when A = 0.) What happens if negative numbers are entered? Fractional numbers? If the input numbers, i.e. the domain of the function computed by the algorithm/program, is to include only positive integers including zero, then the failures at zero indicate that the algorithm (and the program that instantiates it) is a partial function rather than a total function. A notable failure due to exceptions is the Ariane 5 Flight 501 rocket failure (June 4, 1996).

Proof of program correctness by use of mathematical induction: Knuth demonstrates the application of mathematical induction to an "extended" version of Euclid's algorithm, and he proposes "a general method applicable to proving the validity of any algorithm". Tausworthe proposes that a measure of the complexity of a program be the length of its correctness proof.

Measuring and improving the Euclid algorithms
Elegance (compactness) versus goodness (speed): With only six core instructions, "Elegant" is the clear winner, compared to "Inelegant" at thirteen instructions. However, "Inelegant" is faster (it arrives at HALT in fewer steps). Algorithm analysis indicates why this is the case: "Elegant" does two conditional tests in every subtraction loop, whereas "Inelegant" only does one. As the algorithm (usually) requires many loop-throughs, on average much time is wasted doing a "B = 0?" test that is needed only after the remainder is computed.

Can the algorithms be improved?: Once the programmer judges a program "fit" and "effective"—that is, it computes the function intended by its author—then the question becomes, can it be improved?

The compactness of "Inelegant" can be improved by the elimination of five steps. But Chaitin proved that compacting an algorithm cannot be automated by a generalized algorithm; rather, it can only be done heuristically; i.e., by exhaustive search (examples to be found at Busy beaver), trial and error, cleverness, insight, application of inductive reasoning, etc. Observe that steps 4, 5 and 6 are repeated in steps 11, 12 and 13. Comparison with "Elegant" provides a hint that these steps, together with steps 2 and 3, can be eliminated. This reduces the number of core instructions from thirteen to eight, which makes it "more elegant" than "Elegant", at nine steps.

The speed of "Elegant" can be improved by moving the "B=0?" test outside of the two subtraction loops. This change calls for the addition of three instructions (B = 0?, A = 0?, GOTO). Now "Elegant" computes the example-numbers faster; whether this is always the case for any given A, B, and R, S would require a detailed analysis.

Algorithmic analysis
Main article: Analysis of algorithms
It is frequently important to know how much of a particular resource (such as time or storage) is theoretically required for a given algorithm. Methods have been developed for the analysis of algorithms to obtain such quantitative answers (estimates); for example, an algorithm which adds up the elements of a list of n numbers would have a time requirement of O(n), using big O notation. At all times the algorithm only needs to remember two values: the sum of all the elements so far, and its current position in the input list. Therefore, it is said to have a space requirement of O(1), if the space required to store the input numbers is not counted, or O(n) if it is counted.

Different algorithms may complete the same task with a different set of instructions in less or more time, space, or 'effort' than others. For example, a binary search algorithm (with cost O(log n)) outperforms a sequential search (cost O(n) ) when used for table lookups on sorted lists or arrays.

Formal versus empirical
Main articles: Empirical algorithmics, Profiling (computer programming), and Program optimization
The analysis, and study of algorithms is a discipline of computer science, and is often practiced abstractly without the use of a specific programming language or implementation. In this sense, algorithm analysis resembles other mathematical disciplines in that it focuses on the underlying properties of the algorithm and not on the specifics of any particular implementation. Usually pseudocode is used for analysis as it is the simplest and most general representation. However, ultimately, most algorithms are usually implemented on particular hardware/software platforms and their algorithmic efficiency is eventually put to the test using real code. For the solution of a "one off" problem, the efficiency of a particular algorithm may not have significant consequences (unless n is extremely large) but for algorithms designed for fast interactive, commercial or long life scientific usage it may be critical. Scaling from small n to large n frequently exposes inefficient algorithms that are otherwise benign.

Empirical testing is useful because it may uncover unexpected interactions that affect performance. Benchmarks may be used to compare before/after potential improvements to an algorithm after program optimization. Empirical tests cannot replace formal analysis, though, and are not trivial to perform in a fair manner.

Execution efficiency
Main article: Algorithmic efficiency
To illustrate the potential improvements possible even in well-established algorithms, a recent significant innovation, relating to FFT algorithms (used heavily in the field of image processing), can decrease processing time up to 1,000 times for applications like medical imaging. In general, speed improvements depend on special properties of the problem, which are very common in practical applications. Speedups of this magnitude enable computing devices that make extensive use of image processing (like digital cameras and medical equipment) to consume less power.

Classification
There are various ways to classify algorithms, each with its own merits.

By implementation
One way to classify algorithms is by implementation means.

int gcd(int A, int B) {
    if (B == 0)
        return A;
    else if (A > B)
        return gcd(A-B,B);
    else
        return gcd(A,B-A);
}
Recursive C implementation of Euclid's algorithm from the above flowchart
Recursion
A recursive algorithm is one that invokes (makes reference to) itself repeatedly until a certain condition (also known as termination condition) matches, which is a method common to functional programming. Iterative algorithms use repetitive constructs like loops and sometimes additional data structures like stacks to solve the given problems. Some problems are naturally suited for one implementation or the other. For example, towers of Hanoi is well understood using recursive implementation. Every recursive version has an equivalent (but possibly more or less complex) iterative version, and vice versa.
Logical
An algorithm may be viewed as controlled logical deduction. This notion may be expressed as: Algorithm = logic + control. The logic component expresses the axioms that may be used in the computation and the control component determines the way in which deduction is applied to the axioms. This is the basis for the logic programming paradigm. In pure logic programming languages, the control component is fixed and algorithms are specified by supplying only the logic component. The appeal of this approach is the elegant semantics: a change in the axioms produces a well-defined change in the algorithm.
Serial, parallel or distributed
Algorithms are usually discussed with the assumption that computers execute one instruction of an algorithm at a time. Those computers are sometimes called serial computers. An algorithm designed for such an environment is called a serial algorithm, as opposed to parallel algorithms or distributed algorithms. Parallel algorithms are algorithms that take advantage of computer architectures where multiple processors can work on a problem at the same time. Distributed algorithms are algorithms that use multiple machines connected with a computer network. Parallel and distributed algorithms divide the problem into more symmetrical or asymmetrical subproblems and collect the results back together. For example, a CPU would be an example of a parallel algorithm. The resource consumption in such algorithms is not only processor cycles on each processor but also the communication overhead between the processors. Some sorting algorithms can be parallelized efficiently, but their communication overhead is expensive. Iterative algorithms are generally parallelizable, but some problems have no parallel algorithms and are called inherently serial problems.
Deterministic or non-deterministic
Deterministic algorithms solve the problem with exact decision at every step of the algorithm whereas non-deterministic algorithms solve problems via guessing although typical guesses are made more accurate through the use of heuristics.
Exact or approximate
While many algorithms reach an exact solution, approximation algorithms seek an approximation that is closer to the true solution. The approximation can be reached by either using a deterministic or a random strategy. Such algorithms have practical value for many hard problems. One of the examples of an approximate algorithm is the Knapsack problem, where there is a set of given items. Its goal is to pack the knapsack to get the maximum total value. Each item has some weight and some value. Total weight that can be carried is no more than some fixed number X. So, the solution must consider weights of items as well as their value.
Quantum algorithm
They run on a realistic model of quantum computation. The term is usually used for those algorithms which seem inherently quantum, or use some essential feature of Quantum computing such as quantum superposition or quantum entanglement.
By design paradigm
Another way of classifying algorithms is by their design methodology or paradigm. There is a certain number of paradigms, each different from the other. Furthermore, each of these categories includes many different types of algorithms. Some common paradigms are:

Brute-force or exhaustive search
Brute force is a method of problem-solving that involves systematically trying every possible option until the optimal solution is found. This approach can be very time consuming, as it requires going through every possible combination of variables. However, it is often used when other methods are not available or too complex. Brute force can be used to solve a variety of problems, including finding the shortest path between two points and cracking passwords.
Divide and conquer
A divide-and-conquer algorithm repeatedly reduces an instance of a problem to one or more smaller instances of the same problem (usually recursively) until the instances are small enough to solve easily. One such example of divide and conquer is merge sorting. Sorting can be done on each segment of data after dividing data into segments and sorting of entire data can be obtained in the conquer phase by merging the segments. A simpler variant of divide and conquer is called a decrease-and-conquer algorithm, which solves an identical subproblem and uses the solution of this subproblem to solve the bigger problem. Divide and conquer divides the problem into multiple subproblems and so the conquer stage is more complex than decrease and conquer algorithms. An example of a decrease and conquer algorithm is the binary search algorithm.
Search and enumeration
Many problems (such as playing chess) can be modeled as problems on graphs. A graph exploration algorithm specifies rules for moving around a graph and is useful for such problems. This category also includes search algorithms, branch and bound enumeration and backtracking.
Randomized algorithm
Such algorithms make some choices randomly (or pseudo-randomly). They can be very useful in finding approximate solutions for problems where finding exact solutions can be impractical (see heuristic method below). For some of these problems, it is known that the fastest approximations must involve some randomness. Whether randomized algorithms with polynomial time complexity can be the fastest algorithms for some problems is an open question known as the P versus NP problem. There are two large classes of such algorithms:
Monte Carlo algorithms return a correct answer with high-probability. E.g. RP is the subclass of these that run in polynomial time.
Las Vegas algorithms always return the correct answer, but their running time is only probabilistically bound, e.g. ZPP.
Reduction of complexity
This technique involves solving a difficult problem by transforming it into a better-known problem for which we have (hopefully) asymptotically optimal algorithms. The goal is to find a reducing algorithm whose complexity is not dominated by the resulting reduced algorithm's. For example, one selection algorithm for finding the median in an unsorted list involves first sorting the list (the expensive portion) and then pulling out the middle element in the sorted list (the cheap portion). This technique is also known as transform and conquer.
Back tracking
In this approach, multiple solutions are built incrementally and abandoned when it is determined that they cannot lead to a valid full solution.
Optimization problems
For optimization problems there is a more specific classification of algorithms; an algorithm for such problems may fall into one or more of the general categories described above as well as into one of the following:

Linear programming
When searching for optimal solutions to a linear function bound to linear equality and inequality constraints, the constraints of the problem can be used directly in producing the optimal solutions. There are algorithms that can solve any problem in this category, such as the popular simplex algorithm. Problems that can be solved with linear programming include the maximum flow problem for directed graphs. If a problem additionally requires that one or more of the unknowns must be an integer then it is classified in integer programming. A linear programming algorithm can solve such a problem if it can be proved that all restrictions for integer values are superficial, i.e., the solutions satisfy these restrictions anyway. In the general case, a specialized algorithm or an algorithm that finds approximate solutions is used, depending on the difficulty of the problem.
Dynamic programming
When a problem shows optimal substructures—meaning the optimal solution to a problem can be constructed from optimal solutions to subproblems—and overlapping subproblems, meaning the same subproblems are used to solve many different problem instances, a quicker approach called dynamic programming avoids recomputing solutions that have already been computed. For example, Floyd–Warshall algorithm, the shortest path to a goal from a vertex in a weighted graph can be found by using the shortest path to the goal from all adjacent vertices. Dynamic programming and memoization go together. The main difference between dynamic programming and divide and conquer is that subproblems are more or less independent in divide and conquer, whereas subproblems overlap in dynamic programming. The difference between dynamic programming and straightforward recursion is in caching or memoization of recursive calls. When subproblems are independent and there is no repetition, memoization does not help; hence dynamic programming is not a solution for all complex problems. By using memoization or maintaining a table of subproblems already solved, dynamic programming reduces the exponential nature of many problems to polynomial complexity.
The greedy method
A greedy algorithm is similar to a dynamic programming algorithm in that it works by examining substructures, in this case not of the problem but of a given solution. Such algorithms start with some solution, which may be given or have been constructed in some way, and improve it by making small modifications. For some problems they can find the optimal solution while for others they stop at local optima, that is, at solutions that cannot be improved by the algorithm but are not optimum. The most popular use of greedy algorithms is for finding the minimal spanning tree where finding the optimal solution is possible with this method. Huffman Tree, Kruskal, Prim, Sollin are greedy algorithms that can solve this optimization problem.
The heuristic method
In optimization problems, heuristic algorithms can be used to find a solution close to the optimal solution in cases where finding the optimal solution is impractical. These algorithms work by getting closer and closer to the optimal solution as they progress. In principle, if run for an infinite amount of time, they will find the optimal solution. Their merit is that they can find a solution very close to the optimal solution in a relatively short time. Such algorithms include local search, tabu search, simulated annealing, and genetic algorithms. Some of them, like simulated annealing, are non-deterministic algorithms while others, like tabu search, are deterministic. When a bound on the error of the non-optimal solution is known, the algorithm is further categorized as an approximation algorithm.
By field of study
See also: List of algorithms
Every field of science has its own problems and needs efficient algorithms. Related problems in one field are often studied together. Some example classes are search algorithms, sorting algorithms, merge algorithms, numerical algorithms, graph algorithms, string algorithms, computational geometric algorithms, combinatorial algorithms, medical algorithms, machine learning, cryptography, data compression algorithms and parsing techniques.

Fields tend to overlap with each other, and algorithm advances in one field may improve those of other, sometimes completely unrelated, fields. For example, dynamic programming was invented for optimization of resource consumption in industry but is now used in solving a broad range of problems in many fields.

By complexity
See also: Complexity class and Parameterized complexity
Algorithms can be classified by the amount of time they need to complete compared to their input size:

Constant time: if the time needed by the algorithm is the same, regardless of the input size. E.g. an access to an array element.
Logarithmic time: if the time is a logarithmic function of the input size. E.g. binary search algorithm.
Linear time: if the time is proportional to the input size. E.g. the traverse of a list.
Polynomial time: if the time is a power of the input size. E.g. the bubble sort algorithm has quadratic time complexity.
Exponential time: if the time is an exponential function of the input size. E.g. Brute-force search.
Some problems may have multiple algorithms of differing complexity, while other problems might have no algorithms or no known efficient algorithms. There are also mappings from some problems to other problems. Owing to this, it was found to be more suitable to classify the problems themselves instead of the algorithms into equivalence classes based on the complexity of the best possible algorithms for them.

Continuous algorithms
The adjective "continuous" when applied to the word "algorithm" can mean:

An algorithm operating on data that represents continuous quantities, even though this data is represented by discrete approximations—such algorithms are studied in numerical analysis; or
An algorithm in the form of a differential equation that operates continuously on the data, running on an analog computer.
Legal issues
See also: Software patent
Algorithms, by themselves, are not usually patentable. In the United States, a claim consisting solely of simple manipulations of abstract concepts, numbers, or signals does not constitute "processes" (USPTO 2006), and hence algorithms are not patentable (as in Gottschalk v. Benson). However practical applications of algorithms are sometimes patentable. For example, in Diamond v. Diehr, the application of a simple feedback algorithm to aid in the curing of synthetic rubber was deemed patentable. The patenting of software is highly controversial, and there are highly criticized patents involving algorithms, especially data compression algorithms, such as Unisys' LZW patent.

Additionally, some cryptographic algorithms have export restrictions (see export of cryptography).

History: Development of the notion of "algorithm"
Ancient Near East
The earliest evidence of algorithms is found in the Babylonian mathematics of ancient Mesopotamia (modern Iraq). A Sumerian clay tablet found in Shuruppak near Baghdad and dated to c. 2500 BC described the earliest division algorithm. During the Hammurabi dynasty c. 1800 – c. 1600 BC, Babylonian clay tablets described algorithms for computing formulas. Algorithms were also used in Babylonian astronomy. Babylonian clay tablets describe and employ algorithmic procedures to compute the time and place of significant astronomical events.

Algorithms for arithmetic are also found in ancient Egyptian mathematics, dating back to the Rhind Mathematical Papyrus c. 1550 BC. Algorithms were later used in ancient Hellenistic mathematics. Two examples are the Sieve of Eratosthenes, which was described in the Introduction to Arithmetic by Nicomachus,: Ch 9.2  and the Euclidean algorithm, which was first described in Euclid's Elements (c. 300 BC).: Ch 9.1 

Discrete and distinguishable symbols
Tally-marks: To keep track of their flocks, their sacks of grain and their money the ancients used tallying: accumulating stones or marks scratched on sticks or making discrete symbols in clay. Through the Babylonian and Egyptian use of marks and symbols, eventually Roman numerals and the abacus evolved (Dilson, p. 16–41). Tally marks appear prominently in unary numeral system arithmetic used in Turing machine and Post–Turing machine computations.

Manipulation of symbols as "place holders" for numbers: algebra
Muhammad ibn Mūsā al-Khwārizmī, a Persian mathematician, wrote the Al-jabr in the 9th century. The terms "algorism" and "algorithm" are derived from the name al-Khwārizmī, while the term "algebra" is derived from the book Al-jabr. In Europe, the word "algorithm" was originally used to refer to the sets of rules and techniques used by Al-Khwarizmi to solve algebraic equations, before later being generalized to refer to any set of rules or techniques. This eventually culminated in Leibniz's notion of the calculus ratiocinator (c. 1680):

A good century and a half ahead of his time, Leibniz proposed an algebra of logic, an algebra that would specify the rules for manipulating logical concepts in the manner that ordinary algebra specifies the rules for manipulating numbers.

Cryptographic algorithms
The first cryptographic algorithm for deciphering encrypted code was developed by Al-Kindi, a 9th-century Arab mathematician, in A Manuscript On Deciphering Cryptographic Messages. He gave the first description of cryptanalysis by frequency analysis, the earliest codebreaking algorithm.

Mechanical contrivances with discrete states
The clock: Bolter credits the invention of the weight-driven clock as "The key invention [of Europe in the Middle Ages]", in particular, the verge escapement that provides us with the tick and tock of a mechanical clock. "The accurate automatic machine" led immediately to "mechanical automata" beginning in the 13th century and finally to "computational machines"—the difference engine and analytical engines of Charles Babbage and Countess Ada Lovelace, mid-19th century. Lovelace is credited with the first creation of an algorithm intended for processing on a computer—Babbage's analytical engine, the first device considered a real Turing-complete computer instead of just a calculator—and is sometimes called "history's first programmer" as a result, though a full implementation of Babbage's second device would not be realized until decades after her lifetime.

Logical machines 1870 – Stanley Jevons' "logical abacus" and "logical machine": The technical problem was to reduce Boolean equations when presented in a form similar to what is now known as Karnaugh maps. Jevons (1880) describes first a simple "abacus" of "slips of wood furnished with pins, contrived so that any part or class of the [logical] combinations can be picked out mechanically ... More recently, however, I have reduced the system to a completely mechanical form, and have thus embodied the whole of the indirect process of inference in what may be called a Logical Machine" His machine came equipped with "certain moveable wooden rods" and "at the foot are 21 keys like those of a piano [etc.] ...". With this machine he could analyze a "syllogism or any other simple logical argument".

This machine he displayed in 1870 before the Fellows of the Royal Society. Another logician John Venn, however, in his 1881 Symbolic Logic, turned a jaundiced eye to this effort: "I have no high estimate myself of the interest or importance of what are sometimes called logical machines ... it does not seem to me that any contrivances at present known or likely to be discovered really deserve the name of logical machines"; see more at Algorithm characterizations. But not to be outdone he too presented "a plan somewhat analogous, I apprehend, to Prof. Jevon's abacus ... [And] [a]gain, corresponding to Prof. Jevons's logical machine, the following contrivance may be described. I prefer to call it merely a logical-diagram machine ... but I suppose that it could do very completely all that can be rationally expected of any logical machine".

Jacquard loom, Hollerith punch cards, telegraphy and telephony – the electromechanical relay: Bell and Newell (1971) indicate that the Jacquard loom (1801), precursor to Hollerith cards (punch cards, 1887), and "telephone switching technologies" were the roots of a tree leading to the development of the first computers. By the mid-19th century the telegraph, the precursor of the telephone, was in use throughout the world, its discrete and distinguishable encoding of letters as "dots and dashes" a common sound. By the late 19th century the ticker tape (c. 1870s) was in use, as was the use of Hollerith cards in the 1890 U.S. census. Then came the teleprinter (c. 1910) with its punched-paper use of Baudot code on tape.

Telephone-switching networks of electromechanical relays (invented 1835) was behind the work of George Stibitz (1937), the inventor of the digital adding device. As he worked in Bell Laboratories, he observed the "burdensome' use of mechanical calculators with gears. "He went home one evening in 1937 intending to test his idea... When the tinkering was over, Stibitz had constructed a binary adding device".

The mathematician Martin Davis observes the particular importance of the electromechanical relay (with its two "binary states" open and closed):

It was only with the development, beginning in the 1930s, of electromechanical calculators using electrical relays, that machines were built having the scope Babbage had envisioned."
Mathematics during the 19th century up to the mid-20th century
Symbols and rules: In rapid succession, the mathematics of George Boole (1847, 1854), Gottlob Frege (1879), and Giuseppe Peano (1888–1889) reduced arithmetic to a sequence of symbols manipulated by rules. Peano's The principles of arithmetic, presented by a new method (1888) was "the first attempt at an axiomatization of mathematics in a symbolic language".

But Heijenoort gives Frege (1879) this kudos: Frege's is "perhaps the most important single work ever written in logic. ... in which we see a "'formula language', that is a lingua characterica, a language written with special symbols, "for pure thought", that is, free from rhetorical embellishments ... constructed from specific symbols that are manipulated according to definite rules". The work of Frege was further simplified and amplified by Alfred North Whitehead and Bertrand Russell in their Principia Mathematica (1910–1913).

The paradoxes: At the same time a number of disturbing paradoxes appeared in the literature, in particular, the Burali-Forti paradox (1897), the Russell paradox (1902–03), and the Richard Paradox. The resultant considerations led to Kurt Gödel's paper (1931)—he specifically cites the paradox of the liar—that completely reduces rules of recursion to numbers.

Effective calculability: In an effort to solve the Entscheidungsproblem defined precisely by Hilbert in 1928, mathematicians first set about to define what was meant by an "effective method" or "effective calculation" or "effective calculability" (i.e., a calculation that would succeed). In rapid succession the following appeared: Alonzo Church, Stephen Kleene and J.B. Rosser's λ-calculus a finely honed definition of "general recursion" from the work of Gödel acting on suggestions of Jacques Herbrand (cf. Gödel's Princeton lectures of 1934) and subsequent simplifications by Kleene. Church's proof that the Entscheidungsproblem was unsolvable, Emil Post's definition of effective calculability as a worker mindlessly following a list of instructions to move left or right through a sequence of rooms and while there either mark or erase a paper or observe the paper and make a yes-no decision about the next instruction. Alan Turing's proof of that the Entscheidungsproblem was unsolvable by use of his "a- [automatic-] machine"—in effect almost identical to Post's "formulation", J. Barkley Rosser's definition of "effective method" in terms of "a machine". Kleene's proposal of a precursor to "Church thesis" that he called "Thesis I", and a few years later Kleene's renaming his Thesis "Church's Thesis" and proposing "Turing's Thesis".

Emil Post (1936) and Alan Turing (1936–37, 1939)
Emil Post (1936) described the actions of a "computer" (human being) as follows:

"...two concepts are involved: that of a symbol space in which the work leading from problem to answer is to be carried out, and a fixed unalterable set of directions.
His symbol space would be

"a two-way infinite sequence of spaces or boxes ... The problem solver or worker is to move and work in this symbol space, being capable of being in, and operating in but one box at a time. ... a box is to admit of but two possible conditions, i.e., being empty or unmarked, and having a single mark in it, say a vertical stroke.
"One box is to be singled out and called the starting point. ... a specific problem is to be given in symbolic form by a finite number of boxes [i.e., INPUT] being marked with a stroke. Likewise, the answer [i.e., OUTPUT] is to be given in symbolic form by such a configuration of marked boxes...
"A set of directions applicable to a general problem sets up a deterministic process when applied to each specific problem. This process terminates only when it comes to the direction of type (C ) [i.e., STOP]". See more at Post–Turing machine

Alan Turing's statue at Bletchley Park
Alan Turing's work preceded that of Stibitz (1937); it is unknown whether Stibitz knew of the work of Turing. Turing's biographer believed that Turing's use of a typewriter-like model derived from a youthful interest: "Alan had dreamt of inventing typewriters as a boy; Mrs. Turing had a typewriter, and he could well have begun by asking himself what was meant by calling a typewriter 'mechanical'". Given the prevalence at the time of Morse code, telegraphy, ticker tape machines, and teletypewriters, it is quite possible that all were influences on Turing during his youth.

Turing—his model of computation is now called a Turing machine—begins, as did Post, with an analysis of a human computer that he whittles down to a simple set of basic motions and "states of mind". But he continues a step further and creates a machine as a model of computation of numbers.

"Computing is normally done by writing certain symbols on paper. We may suppose this paper is divided into squares like a child's arithmetic book...I assume then that the computation is carried out on one-dimensional paper, i.e., on a tape divided into squares. I shall also suppose that the number of symbols which may be printed is finite...
"The behavior of the computer at any moment is determined by the symbols which he is observing, and his "state of mind" at that moment. We may suppose that there is a bound B to the number of symbols or squares that the computer can observe at one moment. If he wishes to observe more, he must use successive observations. We will also suppose that the number of states of mind which need be taken into account is finite...
"Let us imagine that the operations performed by the computer to be split up into 'simple operations' which are so elementary that it is not easy to imagine them further divided."
Turing's reduction yields the following:

"The simple operations must therefore include:
"(a) Changes of the symbol on one of the observed squares
"(b) Changes of one of the squares observed to another square within L squares of one of the previously observed squares.
"It may be that some of these change necessarily invoke a change of state of mind. The most general single operation must, therefore, be taken to be one of the following:

"(A) A possible change (a) of symbol together with a possible change of state of mind.
"(B) A possible change (b) of observed squares, together with a possible change of state of mind"
"We may now construct a machine to do the work of this computer."
A few years later, Turing expanded his analysis (thesis, definition) with this forceful expression of it:

"A function is said to be "effectively calculable" if its values can be found by some purely mechanical process. Though it is fairly easy to get an intuitive grasp of this idea, it is nevertheless desirable to have some more definite, mathematical expressible definition ... [he discusses the history of the definition pretty much as presented above with respect to Gödel, Herbrand, Kleene, Church, Turing, and Post] ... We may take this statement literally, understanding by a purely mechanical process one which could be carried out by a machine. It is possible to give a mathematical description, in a certain normal form, of the structures of these machines. The development of these ideas leads to the author's definition of a computable function, and to an identification of computability † with effective calculability...
"† We shall use the expression "computable function" to mean a function calculable by a machine, and we let "effectively calculable" refer to the intuitive idea without particular identification with any one of these definitions".
J. B. Rosser (1939) and S. C. Kleene (1943)
J. Barkley Rosser defined an "effective [mathematical] method" in the following manner (italicization added):

"'Effective method' is used here in the rather special sense of a method each step of which is precisely determined and which is certain to produce the answer in a finite number of steps. With this special meaning, three different precise definitions have been given to date. [his footnote #5; see discussion immediately below]. The simplest of these to state (due to Post and Turing) says essentially that an effective method of solving certain sets of problems exists if one can build a machine which will then solve any problem of the set with no human intervention beyond inserting the question and (later) reading the answer. All three definitions are equivalent, so it doesn't matter which one is used. Moreover, the fact that all three are equivalent is a very strong argument for the correctness of any one." (Rosser 1939:225–226)
Rosser's footnote No. 5 references the work of (1) Church and Kleene and their definition of λ-definability, in particular, Church's use of it in his An Unsolvable Problem of Elementary Number Theory (1936); (2) Herbrand and Gödel and their use of recursion, in particular, Gödel's use in his famous paper On Formally Undecidable Propositions of Principia Mathematica and Related Systems I (1931); and (3) Post (1936) and Turing (1936–37) in their mechanism-models of computation.

Stephen C. Kleene defined as his now-famous "Thesis I" known as the Church–Turing thesis. But he did this in the following context (boldface in original):

"12. Algorithmic theories... In setting up a complete algorithmic theory, what we do is to describe a procedure, performable for each set of values of the independent variables, which procedure necessarily terminates and in such manner that from the outcome we can read a definite answer, "yes" or "no," to the question, "is the predicate value true?"" (Kleene 1943:273)
History after 1950
A number of efforts have been directed toward further refinement of the definition of "algorithm", and activity is on-going because of issues surrounding, in particular, foundations of mathematics (especially the Church–Turing thesis) and philosophy of mind (especially arguments about artificial intelligence). For more, see Algorithm characterizations.

Humans (Homo sapiens) are the most common and widespread species of primate in the great ape family Hominidae, and also the most common species of primate overall. Humans are broadly characterized by their bipedalism and high intelligence. Humans' large brain and resulting cognitive skills have allowed them to thrive in a variety of environments and develop complex societies and civilizations. Humans are highly social and tend to live in complex social structures composed of many cooperating and competing groups, from families and kinship networks to political states. As such, social interactions between humans have established a wide variety of values, social norms, languages, and rituals, each of which bolsters human society. The desire to understand and influence phenomena has motivated humanity's development of science, technology, philosophy, mythology, religion, and other conceptual frameworks.

Although some scientists equate the term "humans" with all members of the genus Homo, in common usage it generally refers to Homo sapiens, the only extant member. Anatomically modern humans emerged around 300,000 years ago in Africa, evolving from Homo heidelbergensis or a similar species and migrating out of Africa, gradually replacing or interbreeding with local populations of archaic humans. For most of history, humans were nomadic hunter-gatherers. Humans began exhibiting behavioral modernity about 160,000–60,000 years ago. The Neolithic Revolution, which began in Southwest Asia around 13,000 years ago (and separately in a few other places), saw the emergence of agriculture and permanent human settlement. As populations became larger and denser, forms of governance developed within and between communities, and a large number of civilizations have risen and fallen. Humans have continued to expand, with a global population of over 8 billion as of 2022.

Genes and the environment influence human biological variation in visible characteristics, physiology, disease susceptibility, mental abilities, body size, and life span. Though humans vary in many traits (such as genetic predispositions and physical features), any two humans are at least 99% genetically similar. Humans are sexually dimorphic: generally, males have greater body strength and females have a higher body fat percentage. At puberty, humans develop secondary sexual characteristics. Females are capable of pregnancy, usually between puberty, at around 12 years old, and menopause, around the age of 50.

Humans are omnivorous, capable of consuming a wide variety of plant and animal material, and have used fire and other forms of heat to prepare and cook food since the time of Homo erectus. Humans can survive for up to eight weeks without food and three or four days without water. Humans are generally diurnal, sleeping on average seven to nine hours per day. Childbirth is dangerous, with a high risk of complications and death. Often, both the mother and the father provide care for their children, who are helpless at birth.

Humans have a large, highly developed, and complex prefrontal cortex, the region of the brain associated with higher cognition. Humans are highly intelligent, capable of episodic memory, have flexible facial expressions, self-awareness, and a theory of mind. The human mind is capable of introspection, private thought, imagination, volition, and forming views on existence. This has allowed great technological advancements and complex tool development to be possible through complex reasoning and the transmission of knowledge to subsequent generations. Language, art, and trade are defining characteristics of humans. Long-distance trade routes might have led to cultural explosions and resource distribution that gave humans an advantage over other similar species.

All modern humans are classified into the species Homo sapiens, coined by Carl Linnaeus in his 1735 work Systema Naturae. The generic name "Homo" is a learned 18th-century derivation from Latin homō, which refers to humans of either sex. The word human can refer to all members of the Homo genus, although in common usage it generally just refers to Homo sapiens, the only extant species. The name "Homo sapiens" means 'wise man' or 'knowledgeable man'. There is disagreement if certain extinct members of the genus, namely Neanderthals, should be included as a separate species of humans or as a subspecies of H. sapiens.

Human is a loanword of Middle English from Old French humain, ultimately from Latin hūmānus, the adjectival form of homō ('man' – in the sense of humankind). The native English term man can refer to the species generally (a synonym for humanity) as well as to human males. It may also refer to individuals of either sex, though this form is less common in contemporary English.

Despite the fact that the word animal is colloquially used as an antonym for human, and contrary to a common biological misconception, humans are animals. The word person is often used interchangeably with human, but philosophical debate exists as to whether personhood applies to all humans or all sentient beings, and further if one can lose personhood (such as by going into a persistent vegetative state).

Humans are apes (superfamily Hominoidea). The lineage of apes that eventually gave rise to humans first split from gibbons (family Hylobatidae) and orangutans (genus Pongo), then gorillas (genus Gorilla), and finally, chimpanzees and bonobos (genus Pan). The last split, between the human and chimpanzee–bonobo lineages, took place around 8–4 million years ago, in the late Miocene epoch. During this split, chromosome 2 was formed from the joining of two other chromosomes, leaving humans with only 23 pairs of chromosomes, compared to 24 for the other apes. Following their split with chimpanzees and bonobos, the hominins diversified into many species and at least two distinct genera. All but one of these lineages – representing the genus Homo and its sole extant species Homo sapiens – are now extinct.

The genus Homo evolved from Australopithecus. Though fossils from the transition are scarce, the earliest members of Homo share several key traits with Australopithecus. The earliest record of Homo is the 2.8 million-year-old specimen LD 350-1 from Ethiopia, and the earliest named species are Homo habilis and Homo rudolfensis which evolved by 2.3 million years ago. H. erectus (the African variant is sometimes called H. ergaster) evolved 2 million years ago and was the first archaic human species to leave Africa and disperse across Eurasia. H. erectus also was the first to evolve a characteristically human body plan. Homo sapiens emerged in Africa around 300,000 years ago from a species commonly designated as either H. heidelbergensis or H. rhodesiensis, the descendants of H. erectus that remained in Africa. H. sapiens migrated out of the continent, gradually replacing or interbreeding with local populations of archaic humans. Humans began exhibiting behavioral modernity about 160,000–70,000 years ago, and possibly earlier.

The "out of Africa" migration took place in at least two waves, the first around 130,000 to 100,000 years ago, the second (Southern Dispersal) around 70,000 to 50,000 years ago. H. sapiens proceeded to colonize all the continents and larger islands, arriving in Eurasia 125,000 years ago, Australia around 65,000 years ago, the Americas around 15,000 years ago, and remote islands such as Hawaii, Easter Island, Madagascar, and New Zealand between the years 300 and 1280 CE.

Human evolution was not a simple linear or branched progression but involved interbreeding between related species. Genomic research has shown that hybridization between substantially diverged lineages was common in human evolution. DNA evidence suggests that several genes of Neanderthal origin are present among all non sub-Saharan African populations, and Neanderthals and other hominins, such as Denisovans, may have contributed up to 6% of their genome to present-day non sub-Saharan African humans.

Human evolution is characterized by a number of morphological, developmental, physiological, and behavioral changes that have taken place since the split between the last common ancestor of humans and chimpanzees. The most significant of these adaptations are obligate bipedalism, increased brain size and decreased sexual dimorphism (neoteny). The relationship between all these changes is the subject of ongoing debate.

Until about 12,000 years ago, all humans lived as hunter-gatherers. The Neolithic Revolution (the invention of agriculture) first took place in Southwest Asia and spread through large parts of the Old World over the following millennia. It also occurred independently in Mesoamerica (about 6,000 years ago), China, Papua New Guinea, and the Sahel and West Savanna regions of Africa. Access to food surplus led to the formation of permanent human settlements, the domestication of animals and the use of metal tools for the first time in history. Agriculture and sedentary lifestyle led to the emergence of early civilizations.


Great Pyramids of Giza, Egypt
An urban revolution took place in the 4th millennium BCE with the development of city-states, particularly Sumerian cities located in Mesopotamia. It was in these cities that the earliest known form of writing, cuneiform script, appeared around 3000 BCE. Other major civilizations to develop around this time were Ancient Egypt and the Indus Valley Civilisation. They eventually traded with each other and invented technology such as wheels, plows and sails. Astronomy and mathematics were also developed and the Great Pyramid of Giza was built. There is evidence of a severe drought lasting about a hundred years that may have caused the decline of these civilizations, with new ones appearing in the aftermath. Babylonians came to dominate Mesopotamia while others, such as the Poverty Point culture, Minoans and the Shang dynasty, rose to prominence in new areas. The Late Bronze Age collapse around 1200 BCE resulted in the disappearance of a number of civilizations and the beginning of the Greek Dark Ages. During this period iron started replacing bronze, leading to the Iron Age.

In the 5th century BCE, history started being recorded as a discipline, which provided a much clearer picture of life at the time. Between the 8th and 6th century BCE, Europe entered the classical antiquity age, a period when ancient Greece and ancient Rome flourished. Around this time other civilizations also came to prominence. The Maya civilization started to build cities and create complex calendars. In Africa, the Kingdom of Aksum overtook the declining Kingdom of Kush and facilitated trade between India and the Mediterranean. In West Asia, the Achaemenid Empire's system of centralized governance became the precursor to many later empires, while the Gupta Empire in India and the Han dynasty in China have been described as golden ages in their respective regions.


Medieval French manuscript illustration of the three classes of medieval society from the 13th-century Li Livres dou Santé
Following the fall of the Western Roman Empire in 476, Europe entered the Middle Ages. During this period, Christianity and the Church would provide centralized authority and education. In the Middle East, Islam became the prominent religion and expanded into North Africa. It led to an Islamic Golden Age, inspiring achievements in architecture, the revival of old advances in science and technology, and the formation of a distinct way of life. The Christian and Islamic worlds would eventually clash, with the Kingdom of England, the Kingdom of France and the Holy Roman Empire declaring a series of holy wars to regain control of the Holy Land from Muslims. In the Americas, complex Mississippian societies would arise starting around 800 CE, while further south, the Aztecs and Incas would become the dominant powers. The Mongol Empire would conquer much of Eurasia in the 13th and 14th centuries. Over this same time period, the Mali Empire in Africa grew to be the largest empire on the continent, stretching from Senegambia to Ivory Coast. Oceania would see the rise of the Tuʻi Tonga Empire which expanded across many islands in the South Pacific.

The early modern period in Europe and the Near East (c. 1450–1800) began with the final defeat of the Byzantine Empire, and the rise of the Ottoman Empire. Meanwhile, Japan entered the Edo period, the Qing dynasty rose in China and the Mughal Empire ruled much of India. Europe underwent the Renaissance, starting in the 15th century, and the Age of Discovery began with the exploring and colonizing of new regions. This includes the British Empire expanding to become the world's largest empire and the colonization of the Americas. This expansion led to the Atlantic slave trade and the genocide of Native American peoples. This period also marked the Scientific Revolution, with great advances in mathematics, mechanics, astronomy and physiology.

The late modern period (1800–present) saw the Technological and Industrial Revolution bring such discoveries as imaging technology, major innovations in transport and energy development. The United States of America underwent great change, going from a small group of colonies to one of the global superpowers. The Napoleonic Wars raged through Europe in the early 1800s, Spain lost most of its colonies in the New World, while Europeans continued expansion into Africa – where European control went from 10% to almost 90% in less than 50 years – and Oceania. A tenuous balance of power among European nations collapsed in 1914 with the outbreak of the First World War, one of the deadliest conflicts in history. In the 1930s, a worldwide economic crisis led to the rise of authoritarian regimes and a Second World War, involving almost all of the world's countries. Following its conclusion in 1945, the Cold War between the USSR and the United States saw a struggle for global influence, including a nuclear arms race and a space race. The current Information Age sees the world becoming increasingly globalized and interconnected.

Early human settlements were dependent on proximity to water and – depending on the lifestyle – other natural resources used for subsistence, such as populations of animal prey for hunting and arable land for growing crops and grazing livestock. Modern humans, however, have a great capacity for altering their habitats by means of technology, irrigation, urban planning, construction, deforestation and desertification. Human settlements continue to be vulnerable to natural disasters, especially those placed in hazardous locations and with low quality of construction. Grouping and deliberate habitat alteration is often done with the goals of providing protection, accumulating comforts or material wealth, expanding the available food, improving aesthetics, increasing knowledge or enhancing the exchange of resources.

Humans are one of the most adaptable species, despite having a low or narrow tolerance for many of the earth's extreme environments. Through advanced tools, humans have been able to extend their tolerance to a wide variety of temperatures, humidity, and altitudes. As a result, humans are a cosmopolitan species found in almost all regions of the world, including tropical rainforest, arid desert, extremely cold arctic regions, and heavily polluted cities; in comparison, most other species are confined to a few geographical areas by their limited adaptability. The human population is not, however, uniformly distributed on the Earth's surface, because the population density varies from one region to another, and large stretches of surface are almost completely uninhabited, like Antarctica and vast swathes of the ocean. Most humans (61%) live in Asia; the remainder live in the Americas (14%), Africa (14%), Europe (11%), and Oceania (0.5%).

Within the last century, humans have explored challenging environments such as Antarctica, the deep sea, and outer space. Human habitation within these hostile environments is restrictive and expensive, typically limited in duration, and restricted to scientific, military, or industrial expeditions. Humans have briefly visited the Moon and made their presence felt on other celestial bodies through human-made robotic spacecraft. Since the early 20th century, there has been continuous human presence in Antarctica through research stations and, since 2000, in space through habitation on the International Space Station.

Estimates of the population at the time agriculture emerged in around 10,000 BC have ranged between 1 million and 15 million. Around 50–60 million people lived in the combined eastern and western Roman Empire in the 4th century AD. Bubonic plagues, first recorded in the 6th century AD, reduced the population by 50%, with the Black Death killing 75–200 million people in Eurasia and North Africa alone. Human population is believed to have reached one billion in 1800. It has since then increased exponentially, reaching two billion in 1930 and three billion in 1960, four in 1975, five in 1987 and six billion in 1999. It passed seven billion in 2011 and passed eight billion in November 2022. It took over two million years of human prehistory and history for the human population to reach one billion and only 207 years more to grow to 7 billion. The combined biomass of the carbon of all the humans on Earth in 2018 was estimated at 60 million tons, about 10 times larger than that of all non-domesticated mammals.

In 2018, 4.2 billion humans (55%) lived in urban areas, up from 751 million in 1950. The most urbanized regions are Northern America (82%), Latin America (81%), Europe (74%) and Oceania (68%), with Africa and Asia having nearly 90% of the world's 3.4 billion rural population. Problems for humans living in cities include various forms of pollution and crime, especially in inner city and suburban slums. Humans have had a dramatic effect on the environment. They are apex predators, being rarely preyed upon by other species. Human population growth, industrialization, land development, overconsumption and combustion of fossil fuels have led to environmental destruction and pollution that significantly contributes to the ongoing mass extinction of other forms of life.

Most aspects of human physiology are closely homologous to corresponding aspects of animal physiology. The human body consists of the legs, the torso, the arms, the neck, and the head. An adult human body consists of about 100 trillion (1014) cells. The most commonly defined body systems in humans are the nervous, the cardiovascular, the digestive, the endocrine, the immune, the integumentary, the lymphatic, the musculoskeletal, the reproductive, the respiratory, and the urinary system. The dental formula of humans is: 
2.1.2.3
2.1.2.3
. Humans have proportionately shorter palates and much smaller teeth than other primates. They are the only primates to have short, relatively flush canine teeth. Humans have characteristically crowded teeth, with gaps from lost teeth usually closing up quickly in young individuals. Humans are gradually losing their third molars, with some individuals having them congenitally absent.

Humans share with chimpanzees a vestigial tail, appendix, flexible shoulder joints, grasping fingers and opposable thumbs. Apart from bipedalism and brain size, humans differ from chimpanzees mostly in smelling, hearing and digesting proteins. While humans have a density of hair follicles comparable to other apes, it is predominantly vellus hair, most of which is so short and wispy as to be practically invisible. Humans have about 2 million sweat glands spread over their entire bodies, many more than chimpanzees, whose sweat glands are scarce and are mainly located on the palm of the hand and on the soles of the feet.

It is estimated that the worldwide average height for an adult human male is about 171 cm (5 ft 7 in), while the worldwide average height for adult human females is about 159 cm (5 ft 3 in). Shrinkage of stature may begin in middle age in some individuals but tends to be typical in the extremely aged. Throughout history, human populations have universally become taller, probably as a consequence of better nutrition, healthcare, and living conditions. The average mass of an adult human is 59 kg (130 lb) for females and 77 kg (170 lb) for males. Like many other conditions, body weight and body type are influenced by both genetic susceptibility and environment and varies greatly among individuals.

Humans have a far faster and more accurate throw than other animals. Humans are also among the best long-distance runners in the animal kingdom, but slower over short distances. Humans' thinner body hair and more productive sweat glands help avoid heat exhaustion while running for long distances.

Like most animals, humans are a diploid and eukaryotic species. Each somatic cell has two sets of 23 chromosomes, each set received from one parent; gametes have only one set of chromosomes, which is a mixture of the two parental sets. Among the 23 pairs of chromosomes, there are 22 pairs of autosomes and one pair of sex chromosomes. Like other mammals, humans have an XY sex-determination system, so that females have the sex chromosomes XX and males have XY. Genes and environment influence human biological variation in visible characteristics, physiology, disease susceptibility and mental abilities. The exact influence of genes and environment on certain traits is not well understood.

While no humans – not even monozygotic twins – are genetically identical, two humans on average will have a genetic similarity of 99.5%-99.9%. This makes them more homogeneous than other great apes, including chimpanzees. This small variation in human DNA compared to many other species suggests a population bottleneck during the Late Pleistocene (around 100,000 years ago), in which the human population was reduced to a small number of breeding pairs. The forces of natural selection have continued to operate on human populations, with evidence that certain regions of the genome display directional selection in the past 15,000 years.

The human genome was first sequenced in 2001 and by 2020 hundreds of thousands of genomes had been sequenced. In 2012 the International HapMap Project had compared the genomes of 1,184 individuals from 11 populations and identified 1.6 million single nucleotide polymorphisms. African populations harbor the highest number of private genetic variants. While many of the common variants found in populations outside of Africa are also found on the African continent, there are still large numbers that are private to these regions, especially Oceania and the Americas. By 2010 estimates, humans have approximately 22,000 genes. By comparing mitochondrial DNA, which is inherited only from the mother, geneticists have concluded that the last female common ancestor whose genetic marker is found in all modern humans, the so-called mitochondrial Eve, must have lived around 90,000 to 200,000 years ago.

Most human reproduction takes place by internal fertilization via sexual intercourse, but can also occur through assisted reproductive technology procedures. The average gestation period is 38 weeks, but a normal pregnancy can vary by up to 37 days. Embryonic development in the human covers the first eight weeks of development; at the beginning of the ninth week the embryo is termed a fetus. Humans are able to induce early labor or perform a caesarean section if the child needs to be born earlier for medical reasons. In developed countries, infants are typically 3–4 kg (7–9 lb) in weight and 47–53 cm (19–21 in) in height at birth. However, low birth weight is common in developing countries, and contributes to the high levels of infant mortality in these regions.

Compared with other species, human childbirth is dangerous, with a much higher risk of complications and death. The size of the fetus's head is more closely matched to the pelvis than other primates. The reason for this is not completely understood,[n 3] but it contributes to a painful labor that can last 24 hours or more. The chances of a successful labor increased significantly during the 20th century in wealthier countries with the advent of new medical technologies. In contrast, pregnancy and natural childbirth remain hazardous ordeals in developing regions of the world, with maternal death rates approximately 100 times greater than in developed countries.

Both the mother and the father provide care for human offspring, in contrast to other primates, where parental care is mostly done by the mother. Helpless at birth, humans continue to grow for some years, typically reaching sexual maturity at 15 to 17 years of age. The human life span has been split into various stages ranging from three to twelve. Common stages include infancy, childhood, adolescence, adulthood and old age. The lengths of these stages have varied across cultures and time periods but is typified by an unusually rapid growth spurt during adolescence. Human females undergo menopause and become infertile at around the age of 50. It has been proposed that menopause increases a woman's overall reproductive success by allowing her to invest more time and resources in her existing offspring, and in turn their children (the grandmother hypothesis), rather than by continuing to bear children into old age.

The life span of an individual depends on two major factors, genetics and lifestyle choices. For various reasons, including biological/genetic causes, women live on average about four years longer than men. As of 2018, the global average life expectancy at birth of a girl is estimated to be 74.9 years compared to 70.4 for a boy. There are significant geographical variations in human life expectancy, mostly correlated with economic development – for example, life expectancy at birth in Hong Kong is 87.6 years for girls and 81.8 for boys, while in the Central African Republic, it is 55.0 years for girls and 50.6 for boys. The developed world is generally aging, with the median age around 40 years. In the developing world, the median age is between 15 and 20 years. While one in five Europeans is 60 years of age or older, only one in twenty Africans is 60 years of age or older. In 2012, the United Nations estimated that there were 316,600 living centenarians (humans of age 100 or older) worldwide.

Humans are omnivorous, capable of consuming a wide variety of plant and animal material. Human groups have adopted a range of diets from purely vegan to primarily carnivorous. In some cases, dietary restrictions in humans can lead to deficiency diseases; however, stable human groups have adapted to many dietary patterns through both genetic specialization and cultural conventions to use nutritionally balanced food sources. The human diet is prominently reflected in human culture and has led to the development of food science.

Until the development of agriculture approximately 10,000 years ago, Homo sapiens employed a hunter-gatherer method as their sole means of food collection. This involved combining stationary food sources (such as fruits, grains, tubers, and mushrooms, insect larvae and aquatic mollusks) with wild game, which must be hunted and captured in order to be consumed. It has been proposed that humans have used fire to prepare and cook food since the time of Homo erectus. Around ten thousand years ago, humans developed agriculture, which substantially altered their diet. This change in diet may also have altered human biology; with the spread of dairy farming providing a new and rich source of food, leading to the evolution of the ability to digest lactose in some adults. The types of food consumed, and how they are prepared, have varied widely by time, location, and culture.

In general, humans can survive for up to eight weeks without food, depending on stored body fat. Survival without water is usually limited to three or four days, with a maximum of one week. In 2020 it is estimated 9 million humans die every year from causes directly or indirectly related to starvation. Childhood malnutrition is also common and contributes to the global burden of disease. However, global food distribution is not even, and obesity among some human populations has increased rapidly, leading to health complications and increased mortality in some developed and a few developing countries. Worldwide, over one billion people are obese, while in the United States 35% of people are obese, leading to this being described as an "obesity epidemic." Obesity is caused by consuming more calories than are expended, so excessive weight gain is usually caused by an energy-dense diet.

There is biological variation in the human species – with traits such as blood type, genetic diseases, cranial features, facial features, organ systems, eye color, hair color and texture, height and build, and skin color varying across the globe. The typical height of an adult human is between 1.4 and 1.9 m (4 ft 7 in and 6 ft 3 in), although this varies significantly depending on sex, ethnic origin, and family bloodlines. Body size is partly determined by genes and is also significantly influenced by environmental factors such as diet, exercise, and sleep patterns.

There is evidence that populations have adapted genetically to various external factors. The genes that allow adult humans to digest lactose are present in high frequencies in populations that have long histories of cattle domestication and are more dependent on cow milk. Sickle cell anemia, which may provide increased resistance to malaria, is frequent in populations where malaria is endemic. Populations that have for a very long time inhabited specific climates tend to have developed specific phenotypes that are beneficial for those environments – short stature and stocky build in cold regions, tall and lanky in hot regions, and with high lung capacities or other adaptations at high altitudes. Some populations have evolved highly unique adaptations to very specific environmental conditions, such as those advantageous to ocean-dwelling lifestyles and freediving in the Bajau.

Human hair ranges in color from red to blond to brown to black, which is the most frequent. Hair color depends on the amount of melanin, with concentrations fading with increased age, leading to grey or even white hair. Skin color can range from darkest brown to lightest peach, or even nearly white or colorless in cases of albinism. It tends to vary clinally and generally correlates with the level of ultraviolet radiation in a particular geographic area, with darker skin mostly around the equator. Skin darkening may have evolved as protection against ultraviolet solar radiation. Light skin pigmentation protects against depletion of vitamin D, which requires sunlight to make. Human skin also has a capacity to darken (tan) in response to exposure to ultraviolet radiation.


A Libyan, a Nubian, a Syrian, and an Egyptian, drawing by an unknown artist after a mural of the tomb of Seti I
There is relatively little variation between human geographical populations, and most of the variation that occurs is at the individual level. Much of human variation is continuous, often with no clear points of demarcation. Genetic data shows that no matter how population groups are defined, two people from the same population group are almost as different from each other as two people from any two different population groups. Dark-skinned populations that are found in Africa, Australia, and South Asia are not closely related to each other.

Genetic research has demonstrated that human populations native to the African continent are the most genetically diverse and genetic diversity decreases with migratory distance from Africa, possibly the result of bottlenecks during human migration. These non-African populations acquired new genetic inputs from local admixture with archaic populations and have much greater variation from Neanderthals and Denisovans than is found in Africa, though Neanderthal admixture into African populations may be underestimated. Furthermore, recent studies have found that populations in sub-Saharan Africa, and particularly West Africa, have ancestral genetic variation which predates modern humans and has been lost in most non-African populations. Some of this ancestry is thought to originate from admixture with an unknown archaic hominin that diverged before the split of Neanderthals and modern humans.

Humans are a gonochoric species, meaning they are divided into male and female sexes. The greatest degree of genetic variation exists between males and females. While the nucleotide genetic variation of individuals of the same sex across global populations is no greater than 0.1%–0.5%, the genetic difference between males and females is between 1% and 2%. Males on average are 15% heavier and 15 cm (6 in) taller than females. On average, men have about 40–50% more upper body strength and 20–30% more lower body strength than women at the same weight, due to higher amounts of muscle and larger muscle fibers. Women generally have a higher body fat percentage than men. Women have lighter skin than men of the same population; this has been explained by a higher need for vitamin D in females during pregnancy and lactation. As there are chromosomal differences between females and males, some X and Y chromosome-related conditions and disorders only affect either men or women. After allowing for body weight and volume, the male voice is usually an octave deeper than the female voice. Women have a longer life span in almost every population around the world.There are intersex conditions in the human population, however these are rare.

The human brain, the focal point of the central nervous system in humans, controls the peripheral nervous system. In addition to controlling "lower," involuntary, or primarily autonomic activities such as respiration and digestion, it is also the locus of "higher" order functioning such as thought, reasoning, and abstraction. These cognitive processes constitute the mind, and, along with their behavioral consequences, are studied in the field of psychology.

Humans have a larger and more developed prefrontal cortex than other primates, the region of the brain associated with higher cognition. This has led humans to proclaim themselves to be more intelligent than any other known species. Objectively defining intelligence is difficult, with other animals adapting senses and excelling in areas that humans are unable to.

There are some traits that, although not strictly unique, do set humans apart from other animals. Humans may be the only animals who have episodic memory and who can engage in "mental time travel". Even compared with other social animals, humans have an unusually high degree of flexibility in their facial expressions. Humans are the only animals known to cry emotional tears. Humans are one of the few animals able to self-recognize in mirror tests and there is also debate over to what extent humans are the only animals with a theory of mind.

Sleep and dreaming
Main articles: Sleep and Dream
Humans are generally diurnal. The average sleep requirement is between seven and nine hours per day for an adult and nine to ten hours per day for a child; elderly people usually sleep for six to seven hours. Having less sleep than this is common among humans, even though sleep deprivation can have negative health effects. A sustained restriction of adult sleep to four hours per day has been shown to correlate with changes in physiology and mental state, including reduced memory, fatigue, aggression, and bodily discomfort.

During sleep humans dream, where they experience sensory images and sounds. Dreaming is stimulated by the pons and mostly occurs during the REM phase of sleep. The length of a dream can vary, from a few seconds up to 30 minutes. Humans have three to five dreams per night, and some may have up to seven. Dreamers are more likely to remember the dream if awakened during the REM phase. The events in dreams are generally outside the control of the dreamer, with the exception of lucid dreaming, where the dreamer is self-aware. Dreams can at times make a creative thought occur or give a sense of inspiration.

Consciousness and thought
Main articles: Consciousness and Cognition
Human consciousness, at its simplest, is sentience or awareness of internal or external existence. Despite centuries of analyses, definitions, explanations and debates by philosophers and scientists, consciousness remains puzzling and controversial, being "at once the most familiar and most mysterious aspect of our lives". The only widely agreed notion about the topic is the intuition that it exists. Opinions differ about what exactly needs to be studied and explained as consciousness. Some philosophers divide consciousness into phenomenal consciousness, which is sensory experience itself, and access consciousness, which can be used for reasoning or directly controlling actions. It is sometimes synonymous with 'the mind', and at other times, an aspect of it. Historically it is associated with introspection, private thought, imagination and volition. It now often includes some kind of experience, cognition, feeling or perception. It may be 'awareness', or 'awareness of awareness', or self-awareness. There might be different levels or orders of consciousness, or different kinds of consciousness, or just one kind with different features.

The process of acquiring knowledge and understanding through thought, experience, and the senses is known as cognition. The human brain perceives the external world through the senses, and each individual human is influenced greatly by his or her experiences, leading to subjective views of existence and the passage of time. The nature of thought is central to psychology and related fields. Cognitive psychology studies cognition, the mental processes underlying behavior. Largely focusing on the development of the human mind through the life span, developmental psychology seeks to understand how people come to perceive, understand, and act within the world and how these processes change as they age. This may focus on intellectual, cognitive, neural, social, or moral development. Psychologists have developed intelligence tests and the concept of intelligence quotient in order to assess the relative intelligence of human beings and study its distribution among population.

Motivation and emotion
Main articles: Motivation and Emotion

Illustration of grief from Charles Darwin's 1872 book The Expression of the Emotions in Man and Animals
Human motivation is not yet wholly understood. From a psychological perspective, Maslow's hierarchy of needs is a well-established theory that can be defined as the process of satisfying certain needs in ascending order of complexity. From a more general, philosophical perspective, human motivation can be defined as a commitment to, or withdrawal from, various goals requiring the application of human ability. Furthermore, incentive and preference are both factors, as are any perceived links between incentives and preferences. Volition may also be involved, in which case willpower is also a factor. Ideally, both motivation and volition ensure the selection, striving for, and realization of goals in an optimal manner, a function beginning in childhood and continuing throughout a lifetime in a process known as socialization.

Emotions are biological states associated with the nervous system brought on by neurophysiological changes variously associated with thoughts, feelings, behavioral responses, and a degree of pleasure or displeasure. They are often intertwined with mood, temperament, personality, disposition, creativity, and motivation. Emotion has a significant influence on human behavior and their ability to learn. Acting on extreme or uncontrolled emotions can lead to social disorder and crime, with studies showing criminals may have a lower emotional intelligence than normal.

Emotional experiences perceived as pleasant, such as joy, interest or contentment, contrast with those perceived as unpleasant, like anxiety, sadness, anger, and despair. Happiness, or the state of being happy, is a human emotional condition. The definition of happiness is a common philosophical topic. Some define it as experiencing the feeling of positive emotional affects, while avoiding the negative ones. Others see it as an appraisal of life satisfaction or quality of life. Recent research suggests that being happy might involve experiencing some negative emotions when humans feel they are warranted.

Sexuality and love
Main articles: Human sexuality and Love

Parents can display familial love for their children.
For humans, sexuality involves biological, erotic, physical, emotional, social, or spiritual feelings and behaviors. Because it is a broad term, which has varied with historical contexts over time, it lacks a precise definition. The biological and physical aspects of sexuality largely concern the human reproductive functions, including the human sexual response cycle. Sexuality also affects and is affected by cultural, political, legal, philosophical, moral, ethical, and religious aspects of life. Sexual desire, or libido, is a basic mental state present at the beginning of sexual behavior. Studies show that men desire sex more than women and masturbate more often.

Humans can fall anywhere along a continuous scale of sexual orientation, although most humans are heterosexual. While homosexual behavior occurs in some other animals, only humans and domestic sheep have so far been found to exhibit exclusive preference for same-sex relationships. Most evidence supports nonsocial, biological causes of sexual orientation, as cultures that are very tolerant of homosexuality do not have significantly higher rates of it. Research in neuroscience and genetics suggests that other aspects of human sexuality are biologically influenced as well.

Love most commonly refers to a feeling of strong attraction or emotional attachment. It can be impersonal (the love of an object, ideal, or strong political or spiritual connection) or interpersonal (love between humans). When in love dopamine, norepinephrine, serotonin and other chemicals stimulate the brain's pleasure center, leading to side effects such as increased heart rate, loss of appetite and sleep, and an intense feeling of excitement.

Culture
Main articles: Culture and Cultural universal
Human society statistics
Most widely spoken languages	English, Mandarin Chinese, Hindi, Spanish, Standard Arabic, Bengali, French, Russian, Portuguese, Urdu
Most practiced religions	Christianity, Islam, Hinduism, Buddhism, folk religions, Sikhism, Judaism, unaffiliated
Humanity's unprecedented set of intellectual skills were a key factor in the species' eventual technological advancement and concomitant domination of the biosphere. Disregarding extinct hominids, humans are the only animals known to teach generalizable information, innately deploy recursive embedding to generate and communicate complex concepts, engage in the "folk physics" required for competent tool design, or cook food in the wild. Teaching and learning preserves the cultural and ethnographic identity of human societies. Other traits and behaviors that are mostly unique to humans include starting fires, phoneme structuring and vocal learning.

Language
Main article: Language
While many species communicate, language is unique to humans, a defining feature of humanity, and a cultural universal. Unlike the limited systems of other animals, human language is open – an infinite number of meanings can be produced by combining a limited number of symbols. Human language also has the capacity of displacement, using words to represent things and happenings that are not presently or locally occurring but reside in the shared imagination of interlocutors.

Language differs from other forms of communication in that it is modality independent; the same meanings can be conveyed through different media, audibly in speech, visually by sign language or writing, and through tactile media such as braille. Language is central to the communication between humans, and to the sense of identity that unites nations, cultures and ethnic groups. There are approximately six thousand different languages currently in use, including sign languages, and many thousands more that are extinct.

The arts
Main article: The arts
Human arts can take many forms including visual, literary and performing. Visual art can range from paintings and sculptures to film, interaction design and architecture. Literary arts can include prose, poetry and dramas; while the performing arts generally involve theatre, music and dance. Humans often combine the different forms (for example, music videos). Other entities that have been described as having artistic qualities include food preparation, video games and medicine. As well as providing entertainment and transferring knowledge, the arts are also used for political purposes.


The Deluge tablet of the Gilgamesh epic in Akkadian
Art is a defining characteristic of humans and there is evidence for a relationship between creativity and language. The earliest evidence of art was shell engravings made by Homo erectus 300,000 years before modern humans evolved. Art attributed to H. sapiens existed at least 75,000 years ago, with jewellery and drawings found in caves in South Africa. There are various hypotheses as to why humans have adapted to the arts. These include allowing them to better problem solve issues, providing a means to control or influence other humans, encouraging cooperation and contribution within a society or increasing the chance of attracting a potential mate. The use of imagination developed through art, combined with logic may have given early humans an evolutionary advantage.

Evidence of humans engaging in musical activities predates cave art and so far music has been practiced by virtually all known human cultures. There exists a wide variety of music genres and ethnic musics; with humans' musical abilities being related to other abilities, including complex social human behaviours. It has been shown that human brains respond to music by becoming synchronized with the rhythm and beat, a process called entrainment. Dance is also a form of human expression found in all cultures and may have evolved as a way to help early humans communicate. Listening to music and observing dance stimulates the orbitofrontal cortex and other pleasure sensing areas of the brain.

Unlike speaking, reading and writing does not come naturally to humans and must be taught. Still, literature has been present before the invention of words and language, with 30,000-year-old paintings on walls inside some caves portraying a series of dramatic scenes. One of the oldest surviving works of literature is the Epic of Gilgamesh, first engraved on ancient Babylonian tablets about 4,000 years ago. Beyond simply passing down knowledge, the use and sharing of imaginative fiction through stories might have helped develop humans' capabilities for communication and increased the likelihood of securing a mate. Storytelling may also be used as a way to provide the audience with moral lessons and encourage cooperation.

Tools and technologies
Main articles: Tool and Technology
Train running on a track
The SCMaglev, the fastest train in the world clocking in at 603 km/h (375 mph) as of 2015
Stone tools were used by proto-humans at least 2.5 million years ago. The use and manufacture of tools has been put forward as the ability that defines humans more than anything else and has historically been seen as an important evolutionary step. The technology became much more sophisticated about 1.8 million years ago, with the controlled use of fire beginning around 1 million years ago. The wheel and wheeled vehicles appeared simultaneously in several regions some time in the fourth millennium BC. The development of more complex tools and technologies allowed land to be cultivated and animals to be domesticated, thus proving essential in the development of agriculture – what is known as the Neolithic Revolution.

China developed paper, the printing press, gunpowder, the compass and other important inventions. The continued improvements in smelting allowed forging of copper, bronze, iron and eventually steel, which is used in railways, skyscrapers and many other products. This coincided with the Industrial Revolution, where the invention of automated machines brought major changes to humans' lifestyles. Modern technology is observed as progressing exponentially, with major innovations in the 20th century including: electricity, penicillin, semiconductors, internal combustion engines, the Internet, nitrogen fixing fertilisers, airplanes, computers, automobiles, contraceptive pills, nuclear fission, the green revolution, radio, scientific plant breeding, rockets, air conditioning, television and the assembly line.

Religion and spirituality
Main articles: Religion and Spirituality

Shango, the Orisha of fire, lightning, and thunder, in the Yoruba religion, depicted on horseback
Religion is generally defined as a belief system concerning the supernatural, sacred or divine, and practices, values, institutions and rituals associated with such belief. Some religions also have a moral code. The evolution and the history of the first religions have recently become areas of active scientific investigation. While the exact time when humans first became religious remains unknown, research shows credible evidence of religious behaviour from around the Middle Paleolithic era (45–200 thousand years ago). It may have evolved to play a role in helping enforce and encourage cooperation between humans.

There is no accepted academic definition of what constitutes religion. Religion has taken on many forms that vary by culture and individual perspective in alignment with the geographic, social, and linguistic diversity of the planet. Religion can include a belief in life after death (commonly involving belief in an afterlife), the origin of life, the nature of the universe (religious cosmology) and its ultimate fate (eschatology), and what is moral or immoral. A common source for answers to these questions are beliefs in transcendent divine beings such as deities or a singular God, although not all religions are theistic.

Although the exact level of religiosity can be hard to measure, a majority of humans profess some variety of religious or spiritual belief. In 2015 the plurality were Christian followed by Muslims, Hindus and Buddhists. As of 2015, about 16%, or slightly under 1.2 billion humans, were irreligious, including those with no religious beliefs or no identity with any religion.

Science and philosophy
Main articles: Science and Philosophy

The Dunhuang map, a star map showing the North Polar region. China circa 700.
An aspect unique to humans is their ability to transmit knowledge from one generation to the next and to continually build on this information to develop tools, scientific laws and other advances to pass on further. This accumulated knowledge can be tested to answer questions or make predictions about how the universe functions and has been very successful in advancing human ascendancy.

Aristotle has been described as the first scientist, and preceded the rise of scientific thought through the Hellenistic period. Other early advances in science came from the Han Dynasty in China and during the Islamic Golden Age. The scientific revolution, near the end of the Renaissance, led to the emergence of modern science.

A chain of events and influences led to the development of the scientific method, a process of observation and experimentation that is used to differentiate science from pseudoscience. An understanding of mathematics is unique to humans, although other species of animals have some numerical cognition. All of science can be divided into three major branches, the formal sciences (e.g., logic and mathematics), which are concerned with formal systems, the applied sciences (e.g., engineering, medicine), which are focused on practical applications, and the empirical sciences, which are based on empirical observation and are in turn divided into natural sciences (e.g., physics, chemistry, biology) and social sciences (e.g., psychology, economics, sociology).

Philosophy is a field of study where humans seek to understand fundamental truths about themselves and the world in which they live. Philosophical inquiry has been a major feature in the development of humans' intellectual history. It has been described as the "no man's land" between definitive scientific knowledge and dogmatic religious teachings. Philosophy relies on reason and evidence, unlike religion, but does not require the empirical observations and experiments provided by science. Major fields of philosophy include metaphysics, epistemology, logic, and axiology (which includes ethics and aesthetics).

Society
Main article: Society

Humans often live in family-based social structures
Society is the system of organizations and institutions arising from interaction between humans. Humans are highly social and tend to live in large complex social groups. They can be divided into different groups according to their income, wealth, power, reputation and other factors. The structure of social stratification and the degree of social mobility differs, especially between modern and traditional societies.[unreliable source?] Human groups range from the size of families to nations. The first form of human social organization is thought to have resembled hunter-gatherer band societies.[better source needed]

Gender
Main article: Gender
Human societies typically exhibit gender identities and gender roles that distinguish between masculine and feminine characteristics and prescribe the range of acceptable behaviours and attitudes for their members based on their sex. The most common categorisation is a gender binary of men and women. Many societies recognise a third gender, or less commonly a fourth or fifth. In some other societies, non-binary is used as an umbrella term for a range of gender identities that are not solely male or female.

Gender roles are often associated with a division of norms, practices, dress, behavior, rights, duties, privileges, status, and power, with men enjoying more rights and privileges than women in most societies, both today and in the past. As a social construct, gender roles are not fixed and vary historically within a society. Challenges to predominant gender norms have recurred in many societies. Little is known about gender roles in the earliest human societies. Early modern humans probably had a range of gender roles similar to that of modern cultures from at least the Upper Paleolithic, while the Neanderthals were less sexually dimorphic and there is evidence that the behavioural difference between males and females was minimal.

Kinship
Main article: Kinship
All human societies organize, recognize and classify types of social relationships based on relations between parents, children and other descendants (consanguinity), and relations through marriage (affinity). There is also a third type applied to godparents or adoptive children (fictive). These culturally defined relationships are referred to as kinship. In many societies, it is one of the most important social organizing principles and plays a role in transmitting status and inheritance. All societies have rules of incest taboo, according to which marriage between certain kinds of kin relations are prohibited, and some also have rules of preferential marriage with certain kin relations.

Ethnicity
Main article: Ethnic group
Human ethnic groups are a social category that identifies together as a group based on shared attributes that distinguish them from other groups. These can be a common set of traditions, ancestry, language, history, society, culture, nation, religion, or social treatment within their residing area. Ethnicity is separate from the concept of race, which is based on physical characteristics, although both are socially constructed. Assigning ethnicity to a certain population is complicated, as even within common ethnic designations there can be a diverse range of subgroups, and the makeup of these ethnic groups can change over time at both the collective and individual level. Also, there is no generally accepted definition of what constitutes an ethnic group. Ethnic groupings can play a powerful role in the social identity and solidarity of ethnopolitical units. This has been closely tied to the rise of the nation state as the predominant form of political organization in the 19th and 20th centuries.

Government and politics
Main articles: Government and Politics

The United Nations headquarters in New York City, which houses one of the world's largest political organizations
As farming populations gathered in larger and denser communities, interactions between these different groups increased. This led to the development of governance within and between the communities. Humans have evolved the ability to change affiliation with various social groups relatively easily, including previously strong political alliances, if doing so is seen as providing personal advantages. This cognitive flexibility allows individual humans to change their political ideologies, with those with higher flexibility less likely to support authoritarian and nationalistic stances.

Governments create laws and policies that affect the citizens that they govern. There have been many forms of government throughout human history, each having various means of obtaining power and the ability to exert diverse controls on the population. As of 2017, more than half of all national governments are democracies, with 13% being autocracies and 28% containing elements of both. Many countries have formed international political organizations and alliances, the largest being the United Nations with 193 member states.

Trade and economics
Main articles: Trade and Economics

The Silk Road (red) and spice trade routes (blue)
Trade, the voluntary exchange of goods and services, is seen as a characteristic that differentiates humans from other animals and has been cited as a practice that gave Homo sapiens a major advantage over other hominids. Evidence suggests early H. sapiens made use of long-distance trade routes to exchange goods and ideas, leading to cultural explosions and providing additional food sources when hunting was sparse, while such trade networks did not exist for the now extinct Neanderthals. Early trade likely involved materials for creating tools like obsidian. The first truly international trade routes were around the spice trade through the Roman and medieval periods.

Early human economies were more likely to be based around gift giving instead of a bartering system. Early money consisted of commodities; the oldest being in the form of cattle and the most widely used being cowrie shells. Money has since evolved into governmental issued coins, paper and electronic money. Human study of economics is a social science that looks at how societies distribute scarce resources among different people. There are massive inequalities in the division of wealth among humans; the eight richest humans are worth the same monetary value as the poorest half of all the human population.

Conflict
See also: War and Violence
Humans commit violence on other humans at a rate comparable to other primates, but have an increased preference for killing adults, infanticide being more common among other primates. It is predicted that 2% of early H. sapiens would be murdered, rising to 12% during the medieval period, before dropping to below 2% in modern times. There is great variation in violence between human populations with rates of homicide in societies that have legal systems and strong cultural attitudes against violence at about 0.01%.

The willingness of humans to kill other members of their species en masse through organized conflict (i.e., war) has long been the subject of debate. One school of thought holds that war evolved as a means to eliminate competitors, and has always been an innate human characteristic. Another suggests that war is a relatively recent phenomenon and has appeared due to changing social conditions. While not settled, current evidence indicates warlike predispositions only became common about 10,000 years ago, and in many places much more recently than that. War has had a high cost on human life; it is estimated that during the 20th century, between 167 million and 188 million people died as a result of war.

Life is a quality that distinguishes matter that has biological processes, such as signaling and self-sustaining processes, from matter that does not, and is defined by the capacity for growth, reaction to stimuli, metabolism, energy transformation, and reproduction. Various forms of life exist, such as plants, animals, fungi, protists, archaea, and bacteria. Biology is the science that studies life.

The gene is the unit of heredity, whereas the cell is the structural and functional unit of life. There are two kinds of cells, prokaryotic and eukaryotic, both of which consist of cytoplasm enclosed within a membrane and contain many biomolecules such as proteins and nucleic acids. Cells reproduce through a process of cell division, in which the parent cell divides into two or more daughter cells and passes its genes onto a new generation, sometimes producing genetic variation.

Organisms, or the individual entities of life, are generally thought to be open systems that maintain homeostasis, are composed of cells, have a life cycle, undergo metabolism, can grow, adapt to their environment, respond to stimuli, reproduce and evolve over multiple generations. Other definitions sometimes include non-cellular life forms such as viruses and viroids, but they are usually excluded because they do not function on their own; rather, they exploit the biological processes of hosts.

Abiogenesis, also known as the origin of life, is the natural process of life arising from non-living matter, such as simple organic compounds. Since its primordial beginnings, life on Earth has changed its environment on a geologic time scale, but it has also adapted to survive in most ecosystems and conditions. New lifeforms have evolved from common ancestors through hereditary variation and natural selection, and today, estimates of the number of distinct species range anywhere from 3 million to over 100 million.

Death is the permanent termination of all biological processes which sustain an organism, and as such, is the end of its life. Extinction is the term describing the dying-out of a group or taxon, usually a species. Once extinct, the extinct species or taxon cannot come back to life. Fossils are the preserved remains or traces of organisms.

Definitions
The definition of life has long been a challenge for scientists and philosophers. This is partially because life is a process, not a substance. This is complicated by a lack of knowledge of the characteristics of living entities, if any, that may have developed outside of Earth. Philosophical definitions of life have also been put forward, with similar difficulties on how to distinguish living things from the non-living. Legal definitions of life have also been described and debated, though these generally focus on the decision to declare a human dead, and the legal ramifications of this decision. As many as 123 definitions of life have been compiled.

Biology
See also: Organism
Since there is no consensus for a definition of life, most current definitions in biology are descriptive. Life is considered a characteristic of something that preserves, furthers or reinforces its existence in the given environment. This characteristic exhibits all or most of the following traits:

Homeostasis: regulation of the internal environment to maintain a constant state; for example, sweating to reduce temperature
Organisation: being structurally composed of one or more cells – the basic units of life
Metabolism: transformation of energy by converting chemicals and energy into cellular components (anabolism) and decomposing organic matter (catabolism). Living things require energy to maintain internal organisation (homeostasis) and to produce the other phenomena associated with life.
Growth: maintenance of a higher rate of anabolism than catabolism. A growing organism increases in size in all of its parts, rather than simply accumulating matter.
Adaptation: the evolutionary process whereby an organism becomes better able to live in its habitat or habitats.
Response to stimuli: a response can take many forms, from the contraction of a unicellular organism to external chemicals, to complex reactions involving all the senses of multicellular organisms. A response is often expressed by motion; for example, the leaves of a plant turning toward the sun (phototropism), and chemotaxis.
Reproduction: the ability to produce new individual organisms, either asexually from a single parent organism or sexually from two parent organisms.
These complex processes, called physiological functions, have underlying physical and chemical bases, as well as signaling and control mechanisms that are essential to maintaining life.

Alternative definitions
See also: Entropy and life
From a physics perspective, living beings are thermodynamic systems with an organised molecular structure that can reproduce itself and evolve as survival dictates. Thermodynamically, life has been described as an open system which makes use of gradients in its surroundings to create imperfect copies of itself. Another way of putting this is to define life as "a self-sustained chemical system capable of undergoing Darwinian evolution", a definition adopted by a NASA committee attempting to define life for the purposes of exobiology, based on a suggestion by Carl Sagan. This definition, however, has been widely criticized because according to it, a single sexually reproducing individual is not alive as it is incapable of evolving on its own. The reason for this potential flaw is that "NASA's definition" refers to life as a phenomenon, not a living individual, which makes it incomplete. Alternative, definitions based on the notion of life as a phenomenon and a living individual have been proposed as continuum of a self-maintainable information, and a distinct element of this continuum, respectively. A major strength of this approach is that it defines life in terms of mathematics and physics, avoiding biological vocabulary, which inevitably leads to pleonasticity.


According to self-maintainable information's theory, entities are given gradually more alive status, with gaining the ability to evolve and maintaining distinctness.
Others take a systemic viewpoint that does not necessarily depend on molecular chemistry. One systemic definition of life is that living things are self-organizing and autopoietic (self-producing). Variations of this definition include Stuart Kauffman's definition as an autonomous agent or a multi-agent system capable of reproducing itself or themselves, and of completing at least one thermodynamic work cycle. This definition is extended by the apparition of novel functions over time.

Viruses
Main articles: Virus and Virus classification

Adenovirus as seen under an electron microscope
Whether or not viruses should be considered as alive is controversial. They are most often considered as just gene coding replicators rather than forms of life. They have been described as "organisms at the edge of life" because they possess genes, evolve by natural selection, and replicate by making multiple copies of themselves through self-assembly. However, viruses do not metabolise and they require a host cell to make new products. Virus self-assembly within host cells has implications for the study of the origin of life, as it may support the hypothesis that life could have started as self-assembling organic molecules.

Biophysics
Main article: Biophysics
To reflect the minimum phenomena required, other biological definitions of life have been proposed, with many of these being based upon chemical systems. Biophysicists have commented that living things function on negative entropy. In other words, living processes can be viewed as a delay of the spontaneous diffusion or dispersion of the internal energy of biological molecules towards more potential microstates. In more detail, according to physicists such as John Bernal, Erwin Schrödinger, Eugene Wigner, and John Avery, life is a member of the class of phenomena that are open or continuous systems able to decrease their internal entropy at the expense of substances or free energy taken in from the environment and subsequently rejected in a degraded form. The emergence and increasing popularity of biomimetics or biomimicry (the design and production of materials, structures, and systems that are modelled on biological entities and processes) will likely redefine the boundary between natural and artificial life.

Living systems theories
Main article: Living systems
Living systems are open self-organizing living things that interact with their environment. These systems are maintained by flows of information, energy, and matter.


Definition of cellular life according to Budisa, Kubyshkin and Schmidt
Budisa, Kubyshkin and Schmidt defined cellular life as an organizational unit resting on four pillars/cornerstones: (i) energy, (ii) metabolism, (iii) information and (iv) form. This system is able to regulate and control metabolism and energy supply and contains at least one subsystem that functions as an information carrier (genetic information). Cells as self-sustaining units are parts of different populations that are involved in the unidirectional and irreversible open-ended process known as evolution.

Some scientists have proposed in the last few decades that a general living systems theory is required to explain the nature of life. Such a general theory would arise out of the ecological and biological sciences and attempt to map general principles for how all living systems work. Instead of examining phenomena by attempting to break things down into components, a general living systems theory explores phenomena in terms of dynamic patterns of the relationships of organisms with their environment.

Gaia hypothesis
Main article: Gaia hypothesis
The idea that Earth is alive is found in philosophy and religion, but the first scientific discussion of it was by the Scottish scientist James Hutton. In 1785, he stated that Earth was a superorganism and that its proper study should be physiology. Hutton is considered the father of geology, but his idea of a living Earth was forgotten in the intense reductionism of the 19th century.: 10  The Gaia hypothesis, proposed in the 1960s by scientist James Lovelock, suggests that life on Earth functions as a single organism that defines and maintains environmental conditions necessary for its survival. This hypothesis served as one of the foundations of the modern Earth system science.

Self-maintainable information
All living entities posess genetic information that maintains itself by processess called cis-actions. Cis-action is any action that has an impact on the initiator, and in chemical systems is known as the autocatalytic set. In living systems, all the cis-actions have generally a positive influence on the system as those with negative impact are eliminated by natural selection. Genetic information acts as an initiator, and it can maintain itself via a series of cis-actions like self-repair or self-production (the production of parts of the body to be distinguished from self-reproduction, which is a duplication of the entire entity). Various cis-actions give the entity additional traits to be considered alive. Self-maintainable information is a basic requirement - a level zero for gaining lifeness and it can be obtained by any cis-action like self-repair (like a gene coding a protein that fixes alteration to a nucleic acid caused by UV radiation). Subsequently, if the entity is able to perform error-prone self-reproduction it gains the trait of evolution and belongs to a continuum of self-maintainable information - it becomes part of the living world in meaning of phenomenon but not yet a living individual. For this upgrade, the entity has to process the trait of distinctness, understood as an ability to define itself as a separate entity with its own fate. There are two possible ways of reaching distinctness: 1) maintaining an open-system (a cell) or/and 2) maintaining a transmission process (for obligatory parasites). Fulfiling any of these cis-actions raises the entity to a level of living individual - a distinct element of the self-maintainable information's continuum. The final level regards the state of the entity as dead or alive and requires the trait of functionality.

This approach provides a lather-like hierarchy of entities depending on their ability to maintain themselves, their evolvability, and their distinctness. It also distinguishes between life as a phenomenon, a living individual, and an alive individual.

Nonfractionability
Robert Rosen devoted a large part of his career, from 1958 onwards, to developing a comprehensive theory of life as a self-organizing complex system, "closed to efficient causation".[note 5] He defined a system component as "a unit of organization; a part with a function, i.e., a definite relation between part and whole." He identified the "nonfractionability of components in an organism" as the fundamental difference between living systems and "biological machines." He summarised his views in his book Life Itself. Similar ideas may be found in the book Living Systems by James Grier Miller.

Property of ecosystems
A systems view of life treats environmental fluxes and biological fluxes together as a "reciprocity of influence," and a reciprocal relation with environment is arguably as important for understanding life as it is for understanding ecosystems. As Harold J. Morowitz (1992) explains it, life is a property of an ecological system rather than a single organism or species. He argues that an ecosystemic definition of life is preferable to a strictly biochemical or physical one. Robert Ulanowicz (2009) highlights mutualism as the key to understand the systemic, order-generating behaviour of life and ecosystems.

Complex systems biology
Main article: Complex systems biology
See also: Mathematical and theoretical biology
Complex systems biology (CSB) is a field of science that studies the emergence of complexity in functional organisms from the viewpoint of dynamic systems theory. The latter is also often called systems biology and aims to understand the most fundamental aspects of life. A closely related approach to CSB and systems biology called relational biology is concerned mainly with understanding life processes in terms of the most important relations, and categories of such relations among the essential functional components of organisms; for multicellular organisms, this has been defined as "categorical biology", or a model representation of organisms as a category theory of biological relations, as well as an algebraic topology of the functional organisation of living organisms in terms of their dynamic, complex networks of metabolic, genetic, and epigenetic processes and signalling pathways. Alternative but closely related approaches focus on the interdependence of constraints, where constraints can be either molecular, such as enzymes, or macroscopic, such as the geometry of a bone or of the vascular system.

Darwinian dynamic
Main article: Evolutionary dynamics
It has also been argued that the evolution of order in living systems and certain physical systems obeys a common fundamental principle termed the Darwinian dynamic. The Darwinian dynamic was formulated by first considering how macroscopic order is generated in a simple non-biological system far from thermodynamic equilibrium, and then extending consideration to short, replicating RNA molecules. The underlying order-generating process was concluded to be basically similar for both types of systems.

Operator theory
See also: Operon
Another systemic definition called the operator theory proposes that life is a general term for the presence of the typical closures found in organisms; the typical closures are a membrane and an autocatalytic set in the cell and that an organism is any system with an organisation that complies with an operator type that is at least as complex as the cell. Life can also be modelled as a network of inferior negative feedbacks of regulatory mechanisms subordinated to a superior positive feedback formed by the potential of expansion and reproduction.

History of study
Materialism
Main article: Materialism

Plant growth in the Hoh Rainforest

Herds of zebra and impala gathering on the Maasai Mara plain

An aerial photo of microbial mats around the Grand Prismatic Spring of Yellowstone National Park
Some of the earliest theories of life were materialist, holding that all that exists is matter, and that life is merely a complex form or arrangement of matter. Empedocles (430 BC) argued that everything in the universe is made up of a combination of four eternal "elements" or "roots of all": earth, water, air, and fire. All change is explained by the arrangement and rearrangement of these four elements. The various forms of life are caused by an appropriate mixture of elements.

Democritus (460 BC) thought that the essential characteristic of life is having a soul (psyche). Like other ancient writers, he was attempting to explain what makes something a living thing. His explanation was that fiery atoms make a soul in exactly the same way atoms and void account for any other thing. He elaborates on fire because of the apparent connection between life and heat, and because fire moves.

Plato's world of eternal and unchanging Forms, imperfectly represented in matter by a divine Artisan, contrasts sharply with the various mechanistic Weltanschauungen, of which atomism was, by the fourth century at least, the most prominent ... This debate persisted throughout the ancient world. Atomistic mechanism got a shot in the arm from Epicurus ... while the Stoics adopted a divine teleology ... The choice seems simple: either show how a structured, regular world could arise out of undirected processes, or inject intelligence into the system.

— R.J. Hankinson, Cause and Explanation in Ancient Greek Thought
The mechanistic materialism that originated in ancient Greece was revived and revised by the French philosopher René Descartes (1596–1650), who held that animals and humans were assemblages of parts that together functioned as a machine. This idea was developed further by Julien Offray de La Mettrie (1709–1750) in his book L'Homme Machine.

In the 19th century the advances in cell theory in biological science encouraged this view. The evolutionary theory of Charles Darwin (1859) is a mechanistic explanation for the origin of species by means of natural selection.

At the beginning of the 20th century Stéphane Leduc (1853–1939) promoted the idea that biological processes could be understood in terms of physics and chemistry, and that their growth resembled that of inorganic crystals immersed in solutions of sodium silicate. His ideas, set out in his book La biologie synthétique was widely dismissed during his lifetime, but has incurred a resurgence of interest in the work of Russell, Barge and colleagues.

Hylomorphism
Main article: Hylomorphism

The structure of the souls of plants, animals, and humans, according to Aristotle
Hylomorphism is a theory first expressed by the Greek philosopher Aristotle (322 BC). The application of hylomorphism to biology was important to Aristotle, and biology is extensively covered in his extant writings. In this view, everything in the material universe has both matter and form, and the form of a living thing is its soul (Greek psyche, Latin anima). There are three kinds of souls: the vegetative soul of plants, which causes them to grow and decay and nourish themselves, but does not cause motion and sensation; the animal soul, which causes animals to move and feel; and the rational soul, which is the source of consciousness and reasoning, which (Aristotle believed) is found only in man. Each higher soul has all of the attributes of the lower ones. Aristotle believed that while matter can exist without form, form cannot exist without matter, and that therefore the soul cannot exist without the body.

This account is consistent with teleological explanations of life, which account for phenomena in terms of purpose or goal-directedness. Thus, the whiteness of the polar bear's coat is explained by its purpose of camouflage. The direction of causality (from the future to the past) is in contradiction with the scientific evidence for natural selection, which explains the consequence in terms of a prior cause. Biological features are explained not by looking at future optimal results, but by looking at the past evolutionary history of a species, which led to the natural selection of the features in question.

Spontaneous generation
Main article: Spontaneous generation
Spontaneous generation was the belief that living organisms can form without descent from similar organisms. Typically, the idea was that certain forms such as fleas could arise from inanimate matter such as dust or the supposed seasonal generation of mice and insects from mud or garbage.

The theory of spontaneous generation was proposed by Aristotle, who compiled and expanded the work of prior natural philosophers and the various ancient explanations of the appearance of organisms; it was considered the best explanation for two millennia. It was decisively dispelled by the experiments of Louis Pasteur in 1859, who expanded upon the investigations of predecessors such as Francesco Redi. Disproof of the traditional ideas of spontaneous generation is no longer controversial among biologists.

Vitalism
Main article: Vitalism
Vitalism is the belief that the life-principle is non-material. This originated with Georg Ernst Stahl (17th century), and remained popular until the middle of the 19th century. It appealed to philosophers such as Henri Bergson, Friedrich Nietzsche, and Wilhelm Dilthey, anatomists like Xavier Bichat, and chemists like Justus von Liebig. Vitalism included the idea that there was a fundamental difference between organic and inorganic material, and the belief that organic material can only be derived from living things. This was disproved in 1828, when Friedrich Wöhler prepared urea from inorganic materials. This Wöhler synthesis is considered the starting point of modern organic chemistry. It is of historical significance because for the first time an organic compound was produced in inorganic reactions.

During the 1850s Hermann von Helmholtz, anticipated by Julius Robert von Mayer, demonstrated that no energy is lost in muscle movement, suggesting that there were no "vital forces" necessary to move a muscle. These results led to the abandonment of scientific interest in vitalistic theories, especially after Buchner's demonstration that alcoholic fermentation could occur in cell-free extracts of yeast. Nonetheless, the belief still exists in pseudoscientific theories such as homoeopathy, which interprets diseases and sickness as caused by disturbances in a hypothetical vital force or life force.

Origin
Life timeline
This box: viewtalkedit
−4500 —–—–−4000 —–—–−3500 —–—–−3000 —–—–−2500 —–—–−2000 —–—–−1500 —–—–−1000 —–—–−500 —–—–0 —
 
Water
 
Single-celled life
 
Photosynthesis
 
Eukaryotes
 
Multicellular life
 
P
l
a
n
t
s
 
Arthropods Molluscs
Flowers
Dinosaurs
 
Mammals
Birds
Primates
H
a
d
e
a
n



A
r
c
h
e
a
n







P
r
o
t
e
r
o
z
o
i
c
P
h
a
n
e
r
o
z
o
i
c
 
 
←	
Earth formed
←	
Earliest water
←	
LUCA
←	
Earliest fossils
←	
LHB meteorites
←	
Earliest oxygen
←	
Pongola glaciation*
←	
Atmospheric oxygen
←	
Huronian glaciation*
←	
Sexual reproduction
←	
Earliest multicellular life
←	
Earliest fungi
←	
Earliest plants
←	
Earliest animals
←	
Cryogenian ice age*
←	
Ediacaran biota
←	
Cambrian explosion
←	
Andean glaciation*
←	
Earliest tetrapods
←	
Karoo ice age*
←	
Earliest apes / humans
←	
Quaternary ice age*
(million years ago)*Ice Ages
Main article: Abiogenesis
The age of Earth is about 4.54 billion years. Evidence suggests that life on Earth has existed for at least 3.5 billion years, with the oldest physical traces of life dating back 3.7 billion years; however, some hypotheses, such as Late Heavy Bombardment, suggest that life on Earth may have started even earlier, as early as 4.1–4.4 billion years ago, and the chemistry leading to life may have begun shortly after the Big Bang, 13.8 billion years ago, during an epoch when the universe was only 10–17 million years old. Time estimates from molecular clocks, as summarized in TimeTree, generally place the origin of life around 4.0 billion years ago or earlier.

More than 99% of all species of life forms, amounting to over five billion species, that ever lived on Earth are estimated to be extinct.


The Francevillian biota are thought by some to represent the oldest known (dated to around 2.1 billion years) examples of life, although some have suggested they may be pseudofossils of inorganic pyrite.
Although the number of Earth's catalogued species of lifeforms is between 1.2 million and 2 million, the total number of species in the planet is uncertain. Estimates range from 8 million to 100 million, with a more narrow range between 10 and 14 million, but it may be as high as 1 trillion (with only one-thousandth of one per cent of the species described) according to studies realised in May 2016. The total number of related DNA base pairs on Earth is estimated at 5.0 x 1037 and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon). In July 2016, scientists reported identifying a set of 355 genes from the Last Universal Common Ancestor (LUCA) of all organisms living on Earth.

All known life forms share fundamental molecular mechanisms, reflecting their common descent; based on these observations, hypotheses on the origin of life attempt to find a mechanism explaining the formation of a universal common ancestor, from simple organic molecules via pre-cellular life to protocells and metabolism. Models have been divided into "genes-first" and "metabolism-first" categories, but a recent trend is the emergence of hybrid models that combine both categories.

There is no current scientific consensus as to how life originated. However, most accepted scientific models build on the Miller–Urey experiment and the work of Sidney Fox, which show that conditions on the primitive Earth favoured chemical reactions that synthesize amino acids and other organic compounds from inorganic precursors, and phospholipids spontaneously form lipid bilayers, the basic structure of a cell membrane.

Living organisms synthesize proteins, which are polymers of amino acids using instructions encoded by deoxyribonucleic acid (DNA). Protein synthesis entails intermediary ribonucleic acid (RNA) polymers. One possibility for how life began is that genes originated first, followed by proteins; the alternative being that proteins came first and then genes.

However, because genes and proteins are both required to produce the other, the problem of considering which came first is like that of the chicken or the egg. Most scientists have adopted the hypothesis that because of this, it is unlikely that genes and proteins arose independently.

Therefore, a possibility, first suggested by Francis Crick, is that the first life was based on RNA, which has the DNA-like properties of information storage and the catalytic properties of some proteins. This is called the RNA world hypothesis, and it is supported by the observation that many of the most critical components of cells (those that evolve the slowest) are composed mostly or entirely of RNA. Also, many critical cofactors (ATP, Acetyl-CoA, NADH, etc.) are either nucleotides or substances clearly related to them. The catalytic properties of RNA had not yet been demonstrated when the hypothesis was first proposed, but they were confirmed by Thomas Cech in 1986.

One issue with the RNA world hypothesis is that synthesis of RNA from simple inorganic precursors is more difficult than for other organic molecules. One reason for this is that RNA precursors are very stable and react with each other very slowly under ambient conditions, and it has also been proposed that living organisms consisted of other molecules before RNA. However, the successful synthesis of certain RNA molecules under the conditions that existed prior to life on Earth has been achieved by adding alternative precursors in a specified order with the precursor phosphate present throughout the reaction. This study makes the RNA world hypothesis more plausible.

Geological findings in 2013 showed that reactive phosphorus species (like phosphite) were in abundance in the ocean before 3.5 Ga, and that Schreibersite easily reacts with aqueous glycerol to generate phosphite and glycerol 3-phosphate. It is hypothesized that Schreibersite-containing meteorites from the Late Heavy Bombardment could have provided early reduced phosphorus, which could react with prebiotic organic molecules to form phosphorylated biomolecules, like RNA.

In 2009, experiments demonstrated Darwinian evolution of a two-component system of RNA enzymes (ribozymes) in vitro. The work was performed in the laboratory of Gerald Joyce, who stated "This is the first example, outside of biology, of evolutionary adaptation in a molecular genetic system."

Prebiotic compounds may have originated extraterrestrially. NASA findings in 2011, based on studies with meteorites found on Earth, suggest DNA and RNA components (adenine, guanine and related organic molecules) may be formed in outer space.

In March 2015, NASA scientists reported that, for the first time, complex DNA and RNA organic compounds of life, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.

According to the panspermia hypothesis, microscopic life—distributed by meteoroids, asteroids and other small Solar System bodies—may exist throughout the universe.

Environmental conditions
See also: Primordial soup, Gaia hypothesis, and Entropy and life

Cyanobacteria dramatically changed the composition of life forms on Earth by leading to the near-extinction of oxygen-intolerant organisms.
The diversity of life on Earth is a result of the dynamic interplay between genetic opportunity, metabolic capability, environmental challenges, and symbiosis. For most of its existence, Earth's habitable environment has been dominated by microorganisms and subjected to their metabolism and evolution. As a consequence of these microbial activities, the physical-chemical environment on Earth has been changing on a geologic time scale, thereby affecting the path of evolution of subsequent life. For example, the release of molecular oxygen by cyanobacteria as a by-product of photosynthesis induced global changes in the Earth's environment. Because oxygen was toxic to most life on Earth at the time, this posed novel evolutionary challenges, and ultimately resulted in the formation of Earth's major animal and plant species. This interplay between organisms and their environment is an inherent feature of living systems.

Biosphere
Main article: Biosphere
The biosphere is the global sum of all ecosystems. It can also be termed as the zone of life on Earth, a closed system (apart from solar and cosmic radiation and heat from the interior of the Earth), and largely self-regulating. By the most general biophysiological definition, the biosphere is the global ecological system integrating all living beings and their relationships, including their interaction with the elements of the lithosphere, geosphere, hydrosphere, and atmosphere.

Life forms live in every part of the Earth's biosphere, including soil, hot springs, inside rocks at least 19 km (12 mi) deep underground, the deepest parts of the ocean, and at least 64 km (40 mi) high in the atmosphere. Under certain test conditions, life forms have been observed to thrive in the near-weightlessness of space and to survive in the vacuum of outer space. Life forms appear to thrive in the Mariana Trench, the deepest spot in the Earth's oceans. Other researchers reported related studies that life forms thrive inside rocks up to 580 m (1,900 ft; 0.36 mi) below the sea floor under 2,590 m (8,500 ft; 1.61 mi) of ocean off the coast of the northwestern United States, as well as 2,400 m (7,900 ft; 1.5 mi) beneath the seabed off Japan. In August 2014, scientists confirmed the existence of life forms living 800 m (2,600 ft; 0.50 mi) below the ice of Antarctica. According to one researcher, "You can find microbes everywhere—they're extremely adaptable to conditions, and survive wherever they are."

The biosphere is postulated to have evolved, beginning with a process of biopoesis (life created naturally from non-living matter, such as simple organic compounds) or biogenesis (life created from living matter), at least some 3.5 billion years ago. The earliest evidence for life on Earth includes biogenic graphite found in 3.7 billion-year-old metasedimentary rocks from Western Greenland and microbial mat fossils found in 3.48 billion-year-old sandstone from Western Australia. More recently, in 2015, "remains of biotic life" were found in 4.1 billion-year-old rocks in Western Australia. In 2017, putative fossilised microorganisms (or microfossils) were announced to have been discovered in hydrothermal vent precipitates in the Nuvvuagittuq Belt of Quebec, Canada that were as old as 4.28 billion years, the oldest record of life on Earth, suggesting "an almost instantaneous emergence of life" after ocean formation 4.4 billion years ago, and not long after the formation of the Earth 4.54 billion years ago. According to biologist Stephen Blair Hedges, "If life arose relatively quickly on Earth ... then it could be common in the universe."

In a general sense, biospheres are any closed, self-regulating systems containing ecosystems. This includes artificial biospheres such as Biosphere 2 and BIOS-3, and potentially ones on other planets or moons.

Range of tolerance

Deinococcus radiodurans is an extremophile that can resist extremes of cold, dehydration, vacuum, acid, and radiation exposure.
The inert components of an ecosystem are the physical and chemical factors necessary for life—energy (sunlight or chemical energy), water, heat, atmosphere, gravity, nutrients, and ultraviolet solar radiation protection. In most ecosystems, the conditions vary during the day and from one season to the next. To live in most ecosystems, then, organisms must be able to survive a range of conditions, called the "range of tolerance." Outside that are the "zones of physiological stress," where the survival and reproduction are possible but not optimal. Beyond these zones are the "zones of intolerance," where survival and reproduction of that organism is unlikely or impossible. Organisms that have a wide range of tolerance are more widely distributed than organisms with a narrow range of tolerance.

Extremophiles
Further information: Extremophile
To survive, selected microorganisms can assume forms that enable them to withstand freezing, complete desiccation, starvation, high levels of radiation exposure, and other physical or chemical challenges. These microorganisms may survive exposure to such conditions for weeks, months, years, or even centuries. Extremophiles are microbial life forms that thrive outside the ranges where life is commonly found. They excel at exploiting uncommon sources of energy. While all organisms are composed of nearly identical molecules, evolution has enabled such microbes to cope with this wide range of physical and chemical conditions. Characterization of the structure and metabolic diversity of microbial communities in such extreme environments is ongoing.

Microbial life forms thrive even in the Mariana Trench, the deepest spot in the Earth's oceans. Microbes also thrive inside rocks up to 1,900 feet (580 m) below the sea floor under 8,500 feet (2,600 m) of ocean. Expeditions of the International Ocean Discovery Program found unicellular life in 120 °C sediment that is 1.2 km below seafloor in the Nankai Trough subduction zone.

Investigation of the tenacity and versatility of life on Earth, as well as an understanding of the molecular systems that some organisms utilise to survive such extremes, is important for the search for life beyond Earth. For example, lichen could survive for a month in a simulated Martian environment.

Chemical elements
All life forms require certain core chemical elements needed for biochemical functioning. These include carbon, hydrogen, nitrogen, oxygen, phosphorus, and sulfur—the elemental macronutrients for all organisms—often represented by the acronym CHNOPS. Together these make up nucleic acids, proteins and lipids, the bulk of living matter. Five of these six elements comprise the chemical components of DNA, the exception being sulfur. The latter is a component of the amino acids cysteine and methionine. The most biologically abundant of these elements is carbon, which has the desirable attribute of forming multiple, stable covalent bonds. This allows carbon-based (organic) molecules to form an immense variety of chemical arrangements.[citation needed] Alternative hypothetical types of biochemistry have been proposed that eliminate one or more of these elements, swap out an element for one not on the list, or change required chiralities or other chemical properties.

DNA
Main article: DNA
Deoxyribonucleic acid is a molecule that carries most of the genetic instructions used in the growth, development, functioning and reproduction of all known living organisms and many viruses. DNA and RNA are nucleic acids; alongside proteins and complex carbohydrates, they are one of the three major types of macromolecule that are essential for all known forms of life. Most DNA molecules consist of two biopolymer strands coiled around each other to form a double helix. The two DNA strands are known as polynucleotides since they are composed of simpler units called nucleotides. Each nucleotide is composed of a nitrogen-containing nucleobase—either cytosine (C), guanine (G), adenine (A), or thymine (T)—as well as a sugar called deoxyribose and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. According to base pairing rules (A with T, and C with G), hydrogen bonds bind the nitrogenous bases of the two separate polynucleotide strands to make double-stranded DNA. The total amount of related DNA base pairs on Earth is estimated at 5.0 x 1037, and weighs 50 billion tonnes. In comparison, the total mass of the biosphere has been estimated to be as much as 4 TtC (trillion tons of carbon).

DNA stores biological information. The DNA backbone is resistant to cleavage, and both strands of the double-stranded structure store the same biological information. Biological information is replicated as the two strands are separated. A significant portion of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences.

The two strands of DNA run in opposite directions to each other and are, therefore, anti-parallel. Attached to each sugar is one of four types of nucleobases (informally, bases). It is the sequence of these four nucleobases along the backbone that encodes biological information. Under the genetic code, RNA strands are translated to specify the sequence of amino acids within proteins. These RNA strands are initially created using DNA strands as a template in a process called transcription.

Within cells, DNA is organised into long structures called chromosomes. During cell division these chromosomes are duplicated in the process of DNA replication, providing each cell its own complete set of chromosomes. Eukaryotic organisms (animals, plants, fungi, and protists) store most of their DNA inside the cell nucleus and some of their DNA in organelles, such as mitochondria or chloroplasts. In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm. Within the chromosomes, chromatin proteins such as histones compact and organise DNA. These compact structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.

DNA was first isolated by Friedrich Miescher in 1869. Its molecular structure was identified by James Watson and Francis Crick in 1953, whose model-building efforts were guided by X-ray diffraction data acquired by Rosalind Franklin.

Classification
Main article: Biological classification

The hierarchy of biological classification's eight major taxonomic ranks. Life is divided into domains, which are subdivided into further groups. Intermediate minor rankings are not shown.
Antiquity
The first known attempt to classify organisms was conducted by the Greek philosopher Aristotle (384–322 BC), who classified all living organisms known at that time as either a plant or an animal, based mainly on their ability to move. He also distinguished animals with blood from animals without blood (or at least without red blood), which can be compared with the concepts of vertebrates and invertebrates respectively, and divided the blooded animals into five groups: viviparous quadrupeds (mammals), oviparous quadrupeds (reptiles and amphibians), birds, fishes and whales. The bloodless animals were also divided into five groups: cephalopods, crustaceans, insects (which included the spiders, scorpions, and centipedes, in addition to what we define as insects today), shelled animals (such as most molluscs and echinoderms), and "zoophytes" (animals that resemble plants). Though Aristotle's work in zoology was not without errors, it was the grandest biological synthesis of the time and remained the ultimate authority for many centuries after his death.

Linnaean
The exploration of the Americas revealed large numbers of new plants and animals that needed descriptions and classification. In the latter part of the 16th century and the beginning of the 17th, careful study of animals commenced and was gradually extended until it formed a sufficient body of knowledge to serve as an anatomical basis for classification.

In the late 1740s, Carl Linnaeus introduced his system of binomial nomenclature for the classification of species. Linnaeus attempted to improve the composition and reduce the length of the previously used many-worded names by abolishing unnecessary rhetoric, introducing new descriptive terms and precisely defining their meaning. The Linnaean classification has eight levels: domains, kingdoms, phyla, class, order, family, genus, and species.

The fungi were originally treated as plants. For a short period Linnaeus had classified them in the taxon Vermes in Animalia, but later placed them back in Plantae. Copeland classified the Fungi in his Protoctista, thus partially avoiding the problem but acknowledging their special status. The problem was eventually solved by Whittaker, when he gave them their own kingdom in his five-kingdom system. Evolutionary history shows that the fungi are more closely related to animals than to plants.

As new discoveries enabled detailed study of cells and microorganisms, new groups of life were revealed, and the fields of cell biology and microbiology were created. These new organisms were originally described separately in protozoa as animals and protophyta/thallophyta as plants, but were united by Haeckel in the kingdom Protista; later, the prokaryotes were split off in the kingdom Monera, which would eventually be divided into two separate groups, the Bacteria and the Archaea. This led to the six-kingdom system and eventually to the current three-domain system, which is based on evolutionary relationships. However, the classification of eukaryotes, especially of protists, is still controversial.

As microbiology, molecular biology and virology developed, non-cellular reproducing agents were discovered, such as viruses and viroids. Whether these are considered alive has been a matter of debate; viruses lack characteristics of life such as cell membranes, metabolism and the ability to grow or respond to their environments. Viruses can still be classed into "species" based on their biology and genetics, but many aspects of such a classification remain controversial.

In May 2016, scientists reported that 1 trillion species are estimated to be on Earth currently with only one-thousandth of one per cent described.

The original Linnaean system has been modified over time as follows:

Linnaeus
1735	Haeckel
1866	Chatton
1925	Copeland
1938	Whittaker
1969	Woese et al.
1990	Cavalier-Smith
1998	Cavalier-Smith
2015
2 kingdoms	3 kingdoms	2 empires	4 kingdoms	5 kingdoms	3 domains	2 empires, 6 kingdoms	2 empires, 7 kingdoms
(not treated)	Protista	Prokaryota	Monera	Monera	Bacteria	Bacteria	Bacteria
Archaea	Archaea
Eukaryota	Protoctista	Protista	Eucarya	Protozoa	Protozoa
Chromista	Chromista
Vegetabilia	Plantae	Plantae	Plantae	Plantae	Plantae
Fungi	Fungi	Fungi
Animalia	Animalia	Animalia	Animalia	Animalia	Animalia
Main article: Kingdom (biology) § Summary
Cells
Main article: Cell (biology)
Cells are the basic unit of structure in every living thing, and all cells arise from pre-existing cells by division. Cell theory was formulated by Henri Dutrochet, Theodor Schwann, Rudolf Virchow and others during the early nineteenth century, and subsequently became widely accepted. The activity of an organism depends on the total activity of its cells, with energy flow occurring within and between them. Cells contain hereditary information that is carried forward as a genetic code during cell division.

There are two primary types of cells. Prokaryotes lack a nucleus and other membrane-bound organelles, although they have circular DNA and ribosomes. Bacteria and Archaea are two domains of prokaryotes. The other primary type of cells are the eukaryotes, which have distinct nuclei bound by a nuclear membrane and membrane-bound organelles, including mitochondria, chloroplasts, lysosomes, rough and smooth endoplasmic reticulum, and vacuoles. In addition, they possess organised chromosomes that store genetic material. All species of large complex organisms are eukaryotes, including animals, plants and fungi, though most species of eukaryote are protist microorganisms. The conventional model is that eukaryotes evolved from prokaryotes, with the main organelles of the eukaryotes forming through endosymbiosis between bacteria and the progenitor eukaryotic cell.

The molecular mechanisms of cell biology are based on proteins. Most of these are synthesised by the ribosomes through an enzyme-catalyzed process called protein biosynthesis. A sequence of amino acids is assembled and joined based upon gene expression of the cell's nucleic acid. In eukaryotic cells, these proteins may then be transported and processed through the Golgi apparatus in preparation for dispatch to their destination.

Cells reproduce through a process of cell division in which the parent cell divides into two or more daughter cells. For prokaryotes, cell division occurs through a process of fission in which the DNA is replicated, then the two copies are attached to parts of the cell membrane. In eukaryotes, a more complex process of mitosis is followed. However, the result is the same; the resulting cell copies are identical to each other and to the original cell (except for mutations), and both are capable of further division following an interphase period.

Multicellular organisms may have first evolved through the formation of colonies of identical cells. These cells can form group organisms through cell adhesion. The individual members of a colony are capable of surviving on their own, whereas the members of a true multi-cellular organism have developed specialisations, making them dependent on the remainder of the organism for survival. Such organisms are formed clonally or from a single germ cell that is capable of forming the various specialised cells that form the adult organism. This specialisation allows multicellular organisms to exploit resources more efficiently than single cells. In January 2016, scientists reported that, about 800 million years ago, a minor genetic change in a single molecule, called GK-PID, may have allowed organisms to go from a single cell organism to one of many cells.

Cells have evolved methods to perceive and respond to their microenvironment, thereby enhancing their adaptability. Cell signalling coordinates cellular activities, and hence governs the basic functions of multicellular organisms. Signaling between cells can occur through direct cell contact using juxtacrine signalling, or indirectly through the exchange of agents as in the endocrine system. In more complex organisms, coordination of activities can occur through a dedicated nervous system.

Extraterrestrial
Main articles: Extraterrestrial life, Astrobiology, and Astroecology
Though life is confirmed only on Earth, many think that extraterrestrial life is not only plausible, but probable or inevitable. Other planets and moons in the Solar System and other planetary systems are being examined for evidence of having once supported simple life, and projects such as SETI are trying to detect radio transmissions from possible alien civilisations. Other locations within the Solar System that may host microbial life include the subsurface of Mars, the upper atmosphere of Venus, and subsurface oceans on some of the moons of the giant planets. Beyond the Solar System, the region around another main-sequence star that could support Earth-like life on an Earth-like planet is known as the habitable zone. The inner and outer radii of this zone vary with the luminosity of the star, as does the time interval during which the zone survives. Stars more massive than the Sun have a larger habitable zone, but remain on the Sun-like "main sequence" of stellar evolution for a shorter time interval. Small red dwarfs have the opposite problem, with a smaller habitable zone that is subject to higher levels of magnetic activity and the effects of tidal locking from close orbits. Hence, stars in the intermediate mass range such as the Sun may have a greater likelihood for Earth-like life to develop. The location of the star within a galaxy may also affect the likelihood of life forming. Stars in regions with a greater abundance of heavier elements that can form planets, in combination with a low rate of potentially habitat-damaging supernova events, are predicted to have a higher probability of hosting planets with complex life. The variables of the Drake equation are used to discuss the conditions in planetary systems where civilisation is most likely to exist. Use of the equation to predict the amount of extraterrestrial life, however, is difficult; because many of the variables are unknown, the equation functions as more of a mirror to what its user already thinks. As a result, the number of civilisations in the galaxy can be estimated as low as 9.1 x 10−13, suggesting a minimum value of 1, or as high as 15.6 million (1.56 x 108); for the calculations, see Drake equation.

A "Confidence of Life Detection" scale (CoLD) for reporting evidence of life beyond Earth has been proposed.

Artificial
Main articles: Artificial life and Synthetic biology
Artificial life is the simulation of any aspect of life, as through computers, robotics, or biochemistry. The study of artificial life imitates traditional biology by recreating some aspects of biological phenomena. Scientists study the logic of living systems by creating artificial environments—seeking to understand the complex information processing that defines such systems. While life is, by definition, alive, artificial life is generally referred to as data confined to a digital environment and existence.

Synthetic biology is a new area of biotechnology that combines science and biological engineering. The common goal is the design and construction of new biological functions and systems not found in nature. Synthetic biology includes the broad redefinition and expansion of biotechnology, with the ultimate goals of being able to design and build engineered biological systems that process information, manipulate chemicals, fabricate materials and structures, produce energy, provide food, and maintain and enhance human health and the environment.

Death
Main article: Death

Animal corpses, like this African buffalo, are recycled by the ecosystem, providing energy and nutrients for living creatures.
Death is the termination of all vital functions or life processes in an organism or cell. It can occur as a result of an accident, violence, medical conditions, biological interaction, malnutrition, poisoning, senescence, or suicide. After death, the remains of an organism re-enter the biogeochemical cycle. Organisms may be consumed by a predator or a scavenger and leftover organic material may then be further decomposed by detritivores, organisms that recycle detritus, returning it to the environment for reuse in the food chain.

One of the challenges in defining death is in distinguishing it from life. Death would seem to refer to either the moment life ends, or when the state that follows life begins. However, determining when death has occurred is difficult, as cessation of life functions is often not simultaneous across organ systems. Such determination, therefore, requires drawing conceptual lines between life and death. This is problematic, however, because there is little consensus over how to define life. The nature of death has for millennia been a central concern of the world's religious traditions and of philosophical inquiry. Many religions maintain faith in either a kind of afterlife or reincarnation for the soul, or resurrection of the body at a later date.

Extinction
Main article: Extinction
Extinction is the process by which a group of taxa or species dies out, reducing biodiversity. The moment of extinction is generally considered the death of the last individual of that species. Because a species' potential range may be very large, determining this moment is difficult, and is usually done retrospectively after a period of apparent absence. Species become extinct when they are no longer able to survive in changing habitat or against superior competition. Over 99% of all the species that have ever lived are now extinct. Mass extinctions may have accelerated evolution by providing opportunities for new groups of organisms to diversify.

Fossils
Main article: Fossils
Fossils are the preserved remains or traces of animals, plants, and other organisms from the remote past. The totality of fossils, both discovered and undiscovered, and their placement in fossil-containing rock formations and sedimentary layers (strata) is known as the fossil record. A preserved specimen is called a fossil if it is older than the arbitrary date of 10,000 years ago. Hence, fossils range in age from the youngest at the start of the Holocene Epoch to the oldest from the Archaean Eon, up to 3.4 billion years old.

Mathematics is an area of knowledge that includes the topics of numbers, formulas and related structures, shapes and the spaces in which they are contained, and quantities and their changes. These topics are represented in modern mathematics with the major subdisciplines of number theory, algebra, geometry, and analysis, respectively. There is no general consensus among mathematicians about a common definition for their academic discipline.

Most mathematical activity involves the discovery of properties of abstract objects and the use of pure reason to prove them. These objects consist of either abstractions from nature or—in modern mathematics—entities that are stipulated to have certain properties, called axioms. A proof consists of a succession of applications of deductive rules to already established results. These results include previously proved theorems, axioms, and—in case of abstraction from nature—some basic properties that are considered true starting points of the theory under consideration.

Mathematics is essential in the natural sciences, engineering, medicine, finance, computer science and the social sciences. Although mathematics is extensively used for modeling phenomena, the fundamental truths of mathematics are independent from any scientific experimentation. Some areas of mathematics, such as statistics and game theory, are developed in close correlation with their applications and are often grouped under applied mathematics. Other areas are developed independently from any application (and are therefore called pure mathematics), but often later find practical applications. The problem of integer factorization, for example, which goes back to Euclid in 300 BC, had no practical application before its use in the RSA cryptosystem, now widely used for the security of computer networks.

Historically, the concept of a proof and its associated mathematical rigour first appeared in Greek mathematics, most notably in Euclid's Elements. Since its beginning, mathematics was essentially divided into geometry and arithmetic (the manipulation of natural numbers and fractions), until the 16th and 17th centuries, when algebra[a] and infinitesimal calculus were introduced as new areas. Since then, the interaction between mathematical innovations and scientific discoveries has led to a rapid lockstep increase in the development of both. At the end of the 19th century, the foundational crisis of mathematics led to the systematization of the axiomatic method, which heralded a dramatic increase in the number of mathematical areas and their fields of application. The contemporary Mathematics Subject Classification lists more than 60 first-level areas of mathematics.

Etymology
The word mathematics comes from Ancient Greek máthēma (μάθημα), meaning "that which is learnt", "what one gets to know", hence also "study" and "science". The word came to have the narrower and more technical meaning of "mathematical study" even in Classical times. Its adjective is mathēmatikós (μαθηματικός), meaning "related to learning" or "studious", which likewise further came to mean "mathematical". In particular, mathēmatikḗ tékhnē (μαθηματικὴ τέχνη; Latin: ars mathematica) meant "the mathematical art".

Similarly, one of the two main schools of thought in Pythagoreanism was known as the mathēmatikoi (μαθηματικοί)—which at the time meant "learners" rather than "mathematicians" in the modern sense. The Pythagoreans were likely the first to constrain the use of the word to just the study of arithmetic and geometry. By the time of Aristotle (384–322 BC) this meaning was fully established.

In Latin, and in English until around 1700, the term mathematics more commonly meant "astrology" (or sometimes "astronomy") rather than "mathematics"; the meaning gradually changed to its present one from about 1500 to 1800. This change has resulted in several mistranslations: For example, Saint Augustine's warning that Christians should beware of mathematici, meaning "astrologers", is sometimes mistranslated as a condemnation of mathematicians.

The apparent plural form in English goes back to the Latin neuter plural mathematica (Cicero), based on the Greek plural ta mathēmatiká (τὰ μαθηματικά) and means roughly "all things mathematical", although it is plausible that English borrowed only the adjective mathematic(al) and formed the noun mathematics anew, after the pattern of physics and metaphysics, inherited from Greek. In English, the noun mathematics takes a singular verb. It is often shortened to maths or, in North America, math.

Areas of mathematics
Before the Renaissance, mathematics was divided into two main areas: arithmetic—regarding the manipulation of numbers, and geometry, regarding the study of shapes. Some types of pseudoscience, such as numerology and astrology, were not then clearly distinguished from mathematics.

During the Renaissance, two more areas appeared. Mathematical notation led to algebra which, roughly speaking, consists of the study and the manipulation of formulas. Calculus, consisting of the two subfields differential calculus and integral calculus, is the study of continuous functions, which model the typically nonlinear relationships between varying quantities, as represented by variables. This division into four main areas–arithmetic, geometry, algebra, calculus–endured until the end of the 19th century. Areas such as celestial mechanics and solid mechanics were then studied by mathematicians, but now are considered as belonging to physics. The subject of combinatorics has been studied for much of recorded history, yet did not become a separate branch of mathematics until the seventeenth century.

At the end of the 19th century, the foundational crisis in mathematics and the resulting systematization of the axiomatic method led to an explosion of new areas of mathematics. The 2020 Mathematics Subject Classification contains no less than sixty-three first-level areas. Some of these areas correspond to the older division, as is true regarding number theory (the modern name for higher arithmetic) and geometry. Several other first-level areas have "geometry" in their names or are otherwise commonly considered part of geometry. Algebra and calculus do not appear as first-level areas but are respectively split into several first-level areas. Other first-level areas emerged during the 20th century or had not previously been considered as mathematics, such as mathematical logic and foundations.

Number theory
Main article: Number theory

This is the Ulam spiral, which illustrates the distribution of prime numbers. The dark diagonal lines in the spiral hint at the hypothesized approximate independence between being prime and being a value of a quadratic polynomial, a conjecture now known as Hardy and Littlewood's Conjecture F.
Number theory began with the manipulation of numbers, that is, natural numbers 
(
�
)
,
{\displaystyle (\mathbb {N} ),} and later expanded to integers 
(
�
)
{\displaystyle (\mathbb {Z} )} and rational numbers 
(
�
)
.
{\displaystyle (\mathbb {Q} ).} Number theory was once called arithmetic, but nowadays this term is mostly used for numerical calculations. Number theory dates back to ancient Babylon and probably China. Two prominent early number theorists were Euclid of ancient Greece and Diophantus of Alexandria. The modern study of number theory in its abstract form is largely attributed to Pierre de Fermat and Leonhard Euler. The field came to full fruition with the contributions of Adrien-Marie Legendre and Carl Friedrich Gauss.

Many easily stated number problems have solutions that require sophisticated methods, often from across mathematics. A prominent example is Fermat's Last Theorem. This conjecture was stated in 1637 by Pierre de Fermat, but it was proved only in 1994 by Andrew Wiles, who used tools including scheme theory from algebraic geometry, category theory, and homological algebra. Another example is Goldbach's conjecture, which asserts that every even integer greater than 2 is the sum of two prime numbers. Stated in 1742 by Christian Goldbach, it remains unproven despite considerable effort.

Number theory includes several subareas, including analytic number theory, algebraic number theory, geometry of numbers (method oriented), diophantine equations, and transcendence theory (problem oriented).

Geometry
Main article: Geometry

On the surface of a sphere, Euclidian geometry only applies as a local approximation. For larger scales the sum of the angles of a triangle is not equal to 180°.
Geometry is one of the oldest branches of mathematics. It started with empirical recipes concerning shapes, such as lines, angles and circles, which were developed mainly for the needs of surveying and architecture, but has since blossomed out into many other subfields.

A fundamental innovation was the ancient Greeks' introduction of the concept of proofs, which require that every assertion must be proved. For example, it is not sufficient to verify by measurement that, say, two lengths are equal; their equality must be proven via reasoning from previously accepted results (theorems) and a few basic statements. The basic statements are not subject to proof because they are self-evident (postulates), or are part of the definition of the subject of study (axioms). This principle, foundational for all mathematics, was first elaborated for geometry, and was systematized by Euclid around 300 BC in his book Elements.

The resulting Euclidean geometry is the study of shapes and their arrangements constructed from lines, planes and circles in the Euclidean plane (plane geometry) and the three-dimensional Euclidean space.[b]

Euclidean geometry was developed without change of methods or scope until the 17th century, when René Descartes introduced what is now called Cartesian coordinates. This constituted a major change of paradigm: Instead of defining real numbers as lengths of line segments (see number line), it allowed the representation of points using their coordinates, which are numbers. Algebra (and later, calculus) can thus be used to solve geometrical problems. Geometry was split into two new subfields: synthetic geometry, which uses purely geometrical methods, and analytic geometry, which uses coordinates systemically.

Analytic geometry allows the study of curves unrelated to circles and lines. Such curves can be defined as the graph of functions, the study of which led to differential geometry. They can also be defined as implicit equations, often polynomial equations (which spawned algebraic geometry). Analytic geometry also makes it possible to consider Euclidean spaces of higher than three dimensions.

In the 19th century, mathematicians discovered non-Euclidean geometries, which do not follow the parallel postulate. By questioning that postulate's truth, this discovery has been viewed as joining Russell's paradox in revealing the foundational crisis of mathematics. This aspect of the crisis was solved by systematizing the axiomatic method, and adopting that the truth of the chosen axioms is not a mathematical problem. In turn, the axiomatic method allows for the study of various geometries obtained either by changing the axioms or by considering properties that do not change under specific transformations of the space.

Today's subareas of geometry include:

Projective geometry, introduced in the 16th century by Girard Desargues, extends Euclidean geometry by adding points at infinity at which parallel lines intersect. This simplifies many aspects of classical geometry by unifying the treatments for intersecting and parallel lines.
Affine geometry, the study of properties relative to parallelism and independent from the concept of length.
Differential geometry, the study of curves, surfaces, and their generalizations, which are defined using differentiable functions.
Manifold theory, the study of shapes that are not necessarily embedded in a larger space.
Riemannian geometry, the study of distance properties in curved spaces.
Algebraic geometry, the study of curves, surfaces, and their generalizations, which are defined using polynomials.
Topology, the study of properties that are kept under continuous deformations.
Algebraic topology, the use in topology of algebraic methods, mainly homological algebra.
Discrete geometry, the study of finite configurations in geometry.
Convex geometry, the study of convex sets, which takes its importance from its applications in optimization.
Complex geometry, the geometry obtained by replacing real numbers with complex numbers.
Algebra
Main article: Algebra

The quadratic formula, which concisely expresses the solutions of all quadratic equations

The Rubik's Cube group is a concrete application of group theory
Algebra is the art of manipulating equations and formulas. Diophantus (3rd century) and al-Khwarizmi (9th century) were the two main precursors of algebra. Diophantus solved some equations involving unknown natural numbers by deducing new relations until he obtained the solution. Al-Khwarizmi introduced systematic methods for transforming equations, such as moving a term from one side of an equation into the other side. The term algebra is derived from the Arabic word al-jabr meaning 'the reunion of broken parts' that he used for naming one of these methods in the title of his main treatise.

Algebra became an area in its own right only with François Viète (1540–1603), who introduced the use of variables for representing unknown or unspecified numbers. Variables allow mathematicians to describe the operations that have to be done on the numbers represented using mathematical formulas.

Until the 19th century, algebra consisted mainly of the study of linear equations (presently linear algebra), and polynomial equations in a single unknown, which were called algebraic equations (a term still in use, although it may be ambiguous). During the 19th century, mathematicians began to use variables to represent things other than numbers (such as matrices, modular integers, and geometric transformations), on which generalizations of arithmetic operations are often valid. The concept of algebraic structure addresses this, consisting of a set whose elements are unspecified, of operations acting on the elements of the set, and rules that these operations must follow. The scope of algebra thus grew to include the study of algebraic structures. This object of algebra was called modern algebra or abstract algebra, as established by the influence and works of Emmy Noether. (The latter term appears mainly in an educational context, in opposition to elementary algebra, which is concerned with the older way of manipulating formulas.)

Some types of algebraic structures have useful and often fundamental properties, in many areas of mathematics. Their study became autonomous parts of algebra, and include:

group theory;
field theory;
vector spaces, whose study is essentially the same as linear algebra;
ring theory;
commutative algebra, which is the study of commutative rings, includes the study of polynomials, and is a foundational part of algebraic geometry;
homological algebra;
Lie algebra and Lie group theory;
Boolean algebra, which is widely used for the study of the logical structure of computers.
The study of types of algebraic structures as mathematical objects is the purpose of universal algebra and category theory. The latter applies to every mathematical structure (not only algebraic ones). At its origin, it was introduced, together with homological algebra for allowing the algebraic study of non-algebraic objects such as topological spaces; this particular area of application is called algebraic topology.

Calculus and analysis
Main articles: Calculus and Mathematical analysis

A Cauchy sequence consists of elements that become arbitrarily close to each other as the sequence progresses (from left to right).
Calculus, formerly called infinitesimal calculus, was introduced independently and simultaneously by 17th-century mathematicians Newton and Leibniz. It is fundamentally the study of the relationship of variables that depend on each other. Calculus was expanded in the 18th century by Euler with the introduction of the concept of a function and many other results. Presently, "calculus" refers mainly to the elementary part of this theory, and "analysis" is commonly used for advanced parts.

Analysis is further subdivided into real analysis, where variables represent real numbers, and complex analysis, where variables represent complex numbers. Analysis includes many subareas shared by other areas of mathematics which include:

Multivariable calculus
Functional analysis, where variables represent varying functions;
Integration, measure theory and potential theory, all strongly related with probability theory on a continuum;
Ordinary differential equations;
Partial differential equations;
Numerical analysis, mainly devoted to the computation on computers of solutions of ordinary and partial differential equations that arise in many applications.
Discrete mathematics
Main article: Discrete mathematics

A diagram representing a two-state Markov chain. The states are represented by 'A' and 'E'. The numbers are the probability of flipping the state.
Discrete mathematics, broadly speaking, is the study of individual, countable mathematical objects. An example is the set of all integers. Because the objects of study here are discrete, the methods of calculus and mathematical analysis do not directly apply.[c] Algorithms—especially their implementation and computational complexity—play a major role in discrete mathematics.

The four color theorem and optimal sphere packing were two major problems of discrete mathematics solved in the second half of the 20th century. The P versus NP problem, which remains open to this day, is also important for discrete mathematics, since its solution would potentially impact a large number of computationally difficult problems.

Discrete mathematics includes:

Combinatorics, the art of enumerating mathematical objects that satisfy some given constraints. Originally, these objects were elements or subsets of a given set; this has been extended to various objects, which establishes a strong link between combinatorics and other parts of discrete mathematics. For example, discrete geometry includes counting configurations of geometric shapes
Graph theory and hypergraphs
Coding theory, including error correcting codes and a part of cryptography
Matroid theory
Discrete geometry
Discrete probability distributions
Game theory (although continuous games are also studied, most common games, such as chess and poker are discrete)
Discrete optimization, including combinatorial optimization, integer programming, constraint programming
Mathematical logic and set theory

The Venn diagram is a commonly used method to illustrate the relations between sets.
Main articles: Mathematical logic and set theory
The two subjects of mathematical logic and set theory have belonged to mathematics since the end of the 19th century. Before this period, sets were not considered to be mathematical objects, and logic, although used for mathematical proofs, belonged to philosophy and was not specifically studied by mathematicians.

Before Cantor's study of infinite sets, mathematicians were reluctant to consider actually infinite collections, and considered infinity to be the result of endless enumeration. Cantor's work offended many mathematicians not only by considering actually infinite sets but by showing that this implies different sizes of infinity, per Cantor's diagonal argument. This led to the controversy over Cantor's set theory.

In the same period, various areas of mathematics concluded the former intuitive definitions of the basic mathematical objects were insufficient for ensuring mathematical rigour. Examples of such intuitive definitions are "a set is a collection of objects", "natural number is what is used for counting", "a point is a shape with a zero length in every direction", "a curve is a trace left by a moving point", etc.

This became the foundational crisis of mathematics. It was eventually solved in mainstream mathematics by systematizing the axiomatic method inside a formalized set theory. Roughly speaking, each mathematical object is defined by the set of all similar objects and the properties that these objects must have. For example, in Peano arithmetic, the natural numbers are defined by "zero is a number", "each number has a unique successor", "each number but zero has a unique predecessor", and some rules of reasoning. This mathematical abstraction from reality is embodied in the modern philosophy of formalism, as founded by David Hilbert around 1910.

The "nature" of the objects defined this way is a philosophical problem that mathematicians leave to philosophers, even if many mathematicians have opinions on this nature, and use their opinion—sometimes called "intuition"—to guide their study and proofs. The approach allows considering "logics" (that is, sets of allowed deducing rules), theorems, proofs, etc. as mathematical objects, and to prove theorems about them. For example, Gödel's incompleteness theorems assert, roughly speaking that, in every consistent formal system that contains the natural numbers, there are theorems that are true (that is provable in a stronger system), but not provable inside the system. This approach to the foundations of mathematics was challenged during the first half of the 20th century by mathematicians led by Brouwer, who promoted intuitionistic logic, which explicitly lacks the law of excluded middle.

These problems and debates led to a wide expansion of mathematical logic, with subareas such as model theory (modeling some logical theories inside other theories), proof theory, type theory, computability theory and computational complexity theory. Although these aspects of mathematical logic were introduced before the rise of computers, their use in compiler design, program certification, proof assistants and other aspects of computer science, contributed in turn to the expansion of these logical theories.

Statistics and other decision sciences
Main articles: Statistics and Probability theory

Whatever the form of a random population distribution (μ), the sampling mean (x̄) tends to a Gaussian distribution and its variance (σ) is given by the central limit theorem of probability theory.
The field of statistics is a mathematical application that is employed for the collection and processing of data samples, using procedures based on mathematical methods especially probability theory. Statisticians generate data with random sampling or randomized experiments. The design of a statistical sample or experiment determines the analytical methods that will be used. Analysis of data from observational studies is done using statistical models and the theory of inference, using model selection and estimation. The models and consequential predictions should then be tested against new data.[d]

Statistical theory studies decision problems such as minimizing the risk (expected loss) of a statistical action, such as using a procedure in, for example, parameter estimation, hypothesis testing, and selecting the best. In these traditional areas of mathematical statistics, a statistical-decision problem is formulated by minimizing an objective function, like expected loss or cost, under specific constraints. For example, designing a survey often involves minimizing the cost of estimating a population mean with a given level of confidence. Because of its use of optimization, the mathematical theory of statistics overlaps with other decision sciences, such as operations research, control theory, and mathematical economics.

Computational mathematics
Main article: Computational mathematics
Computational mathematics is the study of mathematical problems that are typically too large for human, numerical capacity. Numerical analysis studies methods for problems in analysis using functional analysis and approximation theory; numerical analysis broadly includes the study of approximation and discretization with special focus on rounding errors. Numerical analysis and, more broadly, scientific computing also study non-analytic topics of mathematical science, especially algorithmic-matrix-and-graph theory. Other areas of computational mathematics include computer algebra and symbolic computation.

History
Main article: History of mathematics
Ancient
The history of mathematics is an ever-growing series of abstractions. Evolutionarily speaking, the first abstraction to ever be discovered, one shared by many animals, was probably that of numbers: the realization that, for example, a collection of two apples and a collection of two oranges (say) have something in common, namely that there are two of them. As evidenced by tallies found on bone, in addition to recognizing how to count physical objects, prehistoric peoples may have also known how to count abstract quantities, like time—days, seasons, or years.


The Babylonian mathematical tablet Plimpton 322, dated to 1800 BC
Evidence for more complex mathematics does not appear until around 3000 BC, when the Babylonians and Egyptians began using arithmetic, algebra, and geometry for taxation and other financial calculations, for building and construction, and for astronomy. The oldest mathematical texts from Mesopotamia and Egypt are from 2000 to 1800 BC. Many early texts mention Pythagorean triples and so, by inference, the Pythagorean theorem seems to be the most ancient and widespread mathematical concept after basic arithmetic and geometry. It is in Babylonian mathematics that elementary arithmetic (addition, subtraction, multiplication, and division) first appear in the archaeological record. The Babylonians also possessed a place-value system and used a sexagesimal numeral system which is still in use today for measuring angles and time.

In the 6th century BC, Greek mathematics began to emerge as a distinct discipline and some Ancient Greeks such as the Pythagoreans appeared to have considered it a subject in its own right. Around 300 BC, Euclid organized mathematical knowledge by way of postulates and first principles, which evolved into the axiomatic method that is used in mathematics today, consisting of definition, axiom, theorem, and proof. His book, Elements, is widely considered the most successful and influential textbook of all time. The greatest mathematician of antiquity is often held to be Archimedes (c. 287–212 BC) of Syracuse. He developed formulas for calculating the surface area and volume of solids of revolution and used the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, in a manner not too dissimilar from modern calculus. Other notable achievements of Greek mathematics are conic sections (Apollonius of Perga, 3rd century BC), trigonometry (Hipparchus of Nicaea, 2nd century BC), and the beginnings of algebra (Diophantus, 3rd century AD).


The numerals used in the Bakhshali manuscript, dated between the 2nd century BC and the 2nd century AD
The Hindu–Arabic numeral system and the rules for the use of its operations, in use throughout the world today, evolved over the course of the first millennium AD in India and were transmitted to the Western world via Islamic mathematics. Other notable developments of Indian mathematics include the modern definition and approximation of sine and cosine, and an early form of infinite series.

Medieval and later

A page from al-Khwārizmī's Algebra
During the Golden Age of Islam, especially during the 9th and 10th centuries, mathematics saw many important innovations building on Greek mathematics. The most notable achievement of Islamic mathematics was the development of algebra. Other achievements of the Islamic period include advances in spherical trigonometry and the addition of the decimal point to the Arabic numeral system. Many notable mathematicians from this period were Persian, such as Al-Khwarismi, Omar Khayyam and Sharaf al-Dīn al-Ṭūsī. The Greek and Arabic mathematical texts were in turn translated to Latin during the Middle Ages and made available in Europe.

During the early modern period, mathematics began to develop at an accelerating pace in Western Europe, with innovations that revolutionized mathematics, such as the introduction of variables and symbolic notation by François Viète (1540–1603), the introduction of coordinates by René Descartes (1596–1650) for reducing geometry to algebra, and the development of calculus by Isaac Newton (1642–1726/27) and Gottfried Leibniz (1646–1716) in the 17th century. Leonhard Euler (1707–1783), the most notable mathematician of the 18th century, unified these innovations into a single corpus with a standardized terminology, and completed them with the discovery and the proof of numerous theorems. Perhaps the foremost mathematician of the 19th century was the German mathematician Carl Gauss, who made numerous contributions to fields such as algebra, analysis, differential geometry, matrix theory, number theory, and statistics. In the early 20th century, Kurt Gödel transformed mathematics by publishing his incompleteness theorems, which show in part that any consistent axiomatic system—if powerful enough to describe arithmetic—will contain true propositions that cannot be proved.

Mathematics has since been greatly extended, and there has been a fruitful interaction between mathematics and science, to the benefit of both. Mathematical discoveries continue to be made to this very day. According to Mikhail B. Sevryuk, in the January 2006 issue of the Bulletin of the American Mathematical Society, "The number of papers and books included in the Mathematical Reviews database since 1940 (the first year of operation of MR) is now more than 1.9 million, and more than 75 thousand items are added to the database each year. The overwhelming majority of works in this ocean contain new mathematical theorems and their proofs."

Symbolic notation and terminology
Main articles: Mathematical notation, Language of mathematics, and Glossary of mathematics

An explanation of the sigma (Σ) summation notation
Mathematical notation is widely used in science and engineering for representing complex concepts and properties in a concise, unambiguous, and accurate way. This notation consists of symbols used for representing operations, unspecified numbers, relations and any other mathematical objects, and then assembling them into expressions and formulas. More precisely, numbers and other mathematical objects are represented by symbols called variables, which are generally Latin or Greek letters, and often include subscripts. Operation and relations are generally represented by specific symbols or glyphs, such as + (plus), × (multiplication), 
∫{\textstyle \int } (integral), = (equal), and < (less than). All these symbols are generally grouped according to specific rules to form expressions and formulas. Normally, expressions and formulas do not appear alone, but are included in sentences of the current language, where expressions play the role of noun phrases and formulas play the role of clauses.

Mathematics has developed a rich terminology covering a broad range of fields that study the properties of various abstract, idealized objects and how they interact. It is based on rigorous definitions that provide a standard foundation for communication. An axiom or postulate is a mathematical statement that is taken to be true without need of proof. If a mathematical statement has yet to be proven (or disproven), it is termed a conjecture. Through a series of rigorous arguments employing deductive reasoning, a statement that is proven to be true becomes a theorem. A specialized theorem that is mainly used to prove another theorem is called a lemma. A proven instance that forms part of a more general finding is termed a corollary.

Numerous technical terms used in mathematics are neologisms, such as polynomial and homeomorphism. Other technical terms are words of the common language that are used in an accurate meaning that may differ slightly from their common meaning. For example, in mathematics, "or" means "one, the other or both", while, in common language, it is either ambiguous or means "one or the other but not both" (in mathematics, the latter is called "exclusive or"). Finally, many mathematical terms are common words that are used with a completely different meaning. This may lead to sentences that are correct and true mathematical assertions, but appear to be nonsense to people who do not have the required background. For example, "every free module is flat" and "a field is always a ring".

Relationship with sciences
Mathematics is used in most sciences for modeling phenomena, which then allows predictions to be made from experimental laws. The independence of mathematical truth from any experimentation implies that the accuracy of such predictions depends only on the adequacy of the model. Inaccurate predictions, rather than being caused by invalid mathematical concepts, imply the need to change the mathematical model used. For example, the perihelion precession of Mercury could only be explained after the emergence of Einstein's general relativity, which replaced Newton's law of gravitation as a better mathematical model.

There is still a philosophical debate whether mathematics is a science. However, in practice, mathematicians are typically grouped with scientists, and mathematics shares much in common with the physical sciences. Like them, it is falsifiable, which means in mathematics that, if a result or a theory is wrong, this can be proved by providing a counterexample. Similarly as in science, theories and results (theorems) are often obtained from experimentation. In mathematics, the experimentation may consist of computation on selected examples or of the study of figures or other representations of mathematical objects (often mind representations without physical support). For example, when asked how he came about his theorems, Gauss once replied "durch planmässiges Tattonieren" (through systematic experimentation). However, some authors emphasize that mathematics differs from the modern notion of science by not relying on empirical evidence.

Pure and applied mathematics
Main articles: Applied mathematics and Pure mathematics
Isaac Newton
Gottfried Wilhelm von Leibniz
Isaac Newton (left) and Gottfried Wilhelm Leibniz developed infinitesimal calculus.
Until the 19th century, the development of mathematics in the West was mainly motivated by the needs of technology and science, and there was no clear distinction between pure and applied mathematics. For example, the natural numbers and arithmetic were introduced for the need of counting, and geometry was motivated by surveying, architecture and astronomy. Later, Isaac Newton introduced infinitesimal calculus for explaining the movement of the planets with his law of gravitation. Moreover, most mathematicians were also scientists, and many scientists were also mathematicians. However, a notable exception occurred with the tradition of pure mathematics in Ancient Greece.

In the 19th century, mathematicians such as Karl Weierstrass and Richard Dedekind increasingly focused their research on internal problems, that is, pure mathematics. This led to split mathematics into pure mathematics and applied mathematics, the latter being often considered as having a lower value among mathematical purists. However, the lines between the two are frequently blurred.

The aftermath of World War II led to a surge in the development of applied mathematics in the US and elsewhere. Many of the theories developed for applications were found interesting from the point of view of pure mathematics, and many results of pure mathematics were shown to have applications outside mathematics; in turn, the study of these applications may give new insights on the "pure theory".

An example of the first case is the theory of distributions, introduced by Laurent Schwartz for validating computations done in quantum mechanics, which became immediately an important tool of (pure) mathematical analysis. An example of the second case is the decidability of the first-order theory of the real numbers, a problem of pure mathematics that was proved true by Alfred Tarski, with an algorithm that is impossible to implement because of a computational complexity that is much too high. For getting an algorithm that can be implemented and can solve systems of polynomial equations and inequalities, George Collins introduced the cylindrical algebraic decomposition that became a fundamental tool in real algebraic geometry.

In the present day, the distinction between pure and applied mathematics is more a question of personal research aim of mathematicians than a division of mathematics into broad areas. The Mathematics Subject Classification has a section for "general applied mathematics" but does not mention "pure mathematics". However, these terms are still used in names of some university departments, such as at the Faculty of Mathematics at the University of Cambridge.

Unreasonable effectiveness
The unreasonable effectiveness of mathematics is a phenomenon that was named and first made explicit by physicist Eugene Wigner. It is the fact that many mathematical theories, even the "purest" have applications outside their initial object. These applications may be completely outside their initial area of mathematics, and may concern physical phenomena that were completely unknown when the mathematical theory was introduced. Examples of unexpected applications of mathematical theories can be found in many areas of mathematics.

A notable example is the prime factorization of natural numbers that was discovered more than 2,000 years before its common use for secure internet communications through the RSA cryptosystem. A second historical example is the theory of ellipses. They were studied by the ancient Greek mathematicians as conic sections (that is, intersections of cones with planes). It is almost 2,000 years later that Johannes Kepler discovered that the trajectories of the planets are ellipses.

In the 19th century, the internal development of geometry (pure mathematics) led to definition and study of non-Euclidean geometries, spaces of dimension higher than three and manifolds. At this time, these concepts seemed totally disconnected from the physical reality, but at the beginning of the 20th century, Albert Einstein developed the theory of relativity that uses fundamentally these concepts. In particular, spacetime of special relativity is a non-Euclidean space of dimension four, and spacetime of general relativity is a (curved) manifold of dimension four.

A striking aspect of the interaction between mathematics and physics is when mathematics drives research in physics. This is illustrated by the discoveries of the positron and the baryon 
Ω
−
.
{\displaystyle \Omega ^{-}.} In both cases, the equations of the theories had unexplained solutions, which led to conjecture of the existence of an unknown particle, and the search for these particles. In both cases, these particles were discovered a few years later by specific experiments.

Specific sciences

This subsection needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this subsection. Unsourced material may be challenged and removed.
Find sources: "Mathematics" relationship to science – news · newspapers · books · scholar · JSTOR (December 2022) (Learn how and when to remove this template message)

This subsection is written like a personal reflection, personal essay, or argumentative essay that states a Wikipedia editor's personal feelings or presents an original argument about a topic. Please help improve it by rewriting it in an encyclopedic style. (December 2022) (Learn how and when to remove this template message)
Physics
Main article: Relationship between mathematics and physics

Diagram of a pendulum
Mathematics and physics have influenced each other over their modern history. Modern physics uses mathematics abundantly, and is also the motivation of major mathematical developments.

Computing
Further information: Theoretical computer science and Computational mathematics
The rise of technology in the 20th century opened the way to a new science: computing.[e] This field is closely related to mathematics in several ways. Theoretical computer science is essentially mathematical in nature. Communication technologies apply branches of mathematics that may be very old (e.g., arithmetic), especially with respect to transmission security, in cryptography and coding theory. Discrete mathematics is useful in many areas of computer science, such as complexity theory, information theory, graph theory, and so on.[citation needed]

In return, computing has also become essential for obtaining new results. This is a group of techniques known as experimental mathematics, which is the use of experimentation to discover mathematical insights. The most well-known example is the four-color theorem, which was proven in 1976 with the help of a computer. This revolutionized traditional mathematics, where the rule was that the mathematician should verify each part of the proof. In 1998, the Kepler conjecture on sphere packing seemed to also be partially proven by computer. An international team had since worked on writing a formal proof; it was finished (and verified) in 2015.

Once written formally, a proof can be verified using a program called a proof assistant. These programs are useful in situations where one is uncertain about a proof's correctness.

A major open problem in theoretical computer science is P versus NP. It is one of the seven Millennium Prize Problems.

Biology and chemistry
Main articles: Mathematical and theoretical biology and Mathematical chemistry

The skin of this giant pufferfish exhibits a Turing pattern, which can be modeled by reaction–diffusion systems.
Biology uses probability extensively – for example, in ecology or neurobiology. Most of the discussion of probability in biology, however, centers on the concept of evolutionary fitness.

Ecology heavily uses modeling to simulate population dynamics, study ecosystems such as the predator-prey model, measure pollution diffusion, or to assess climate change. The dynamics of a population can be modeled by coupled differential equations, such as the Lotka–Volterra equations. However, there is the problem of model validation. This is particularly acute when the results of modeling influence political decisions; the existence of contradictory models could allow nations to choose the most favorable model.

Genotype evolution can be modeled with the Hardy-Weinberg principle.[citation needed]

Phylogeography uses probabilistic models.[citation needed]

Medicine uses statistical hypothesis testing, run on data from clinical trials, to determine whether a new treatment works.[citation needed]

Since the start of the 20th century, chemistry has used computing to model molecules in three dimensions. It turns out that the form of macromolecules in biology is variable and determines the action. Such modeling uses Euclidean geometry; neighboring atoms form a polyhedron whose distances and angles are fixed by the laws of interaction.[citation needed]

Earth sciences
Main article: Geomathematics
Structural geology and climatology use probabilistic models to predict the risk of natural catastrophes.[citation needed] Similarly, meteorology, oceanography, and planetology also use mathematics due to their heavy use of models.[citation needed]

Social sciences
Further information: Mathematical economics and Historical dynamics
Areas of mathematics used in the social sciences include probability/statistics and differential equations (stochastic or deterministic).[citation needed] These areas are used in fields such as sociology, psychology, economics, finance, and linguistics.[citation needed]


Supply and demand curves, like this one, are a staple of mathematical economics.
The fundamental postulate of mathematical economics is that of the rational individual actor – Homo economicus (lit. 'economic man'). In this model, each individual aims solely to accumulate as much profit as possible, and always makes optimal choices using perfect information.[better source needed] This atomistic view of economics allows it to relatively easily mathematize its thinking, because individual calculations are transposed into mathematical calculations. Such mathematical modeling allows one to probe economic mechanisms which would be very difficult to discover by a "literary" analysis.[citation needed] For example, explanations of economic cycles are not trivial. Without mathematical modeling, it is hard to go beyond simple statistical observations or unproven speculation.[citation needed]

However, many people have rejected or criticized the concept of Homo economicus.[better source needed] Economists note that real people usually have limited information and often make poor choices.[better source needed] Also, as shown in laboratory experiments, people care about fairness and sometimes altruism, not just personal gain.[better source needed] According to critics, mathematization is a veneer that allows for the material's scientific valorization.[citation needed]

At the start of the 20th century, there was a movement to express historical movements in formulas.[citation needed] In 1922, Nikolai Kondratiev discerned the ~50-year-long Kondratiev cycle, which explains phases of economic growth or crisis. Towards the end of the 19th century, Nicolas-Remi Brück [fr] and Charles Henri Lagrange [fr] had extended their analysis into geopolitics. They wanted to establish the historical existence of vast movements that took peoples to their apogee, then to their decline.[verification needed] More recently, Peter Turchin has been working on developing cliodynamics since the 1990s. (In particular, he discovered the Turchin cycle, which predicts that violence spikes in a short cycle of ~50-year intervals, superimposed over a longer cycle of ~200–300 years.)

Even so, mathematization of the social sciences is not without danger. In the controversial book Fashionable Nonsense (1997), Sokal and Bricmont denounced the unfounded or abusive use of scientific terminology, particularly from mathematics or physics, in the social sciences. The study of complex systems (evolution of unemployment, business capital, demographic evolution of a population, etc.) uses elementary mathematical knowledge. However, the choice of counting criteria, particularly for unemployment, or of models can be subject to controversy.[citation needed]

Relationship with astrology and esotericism
Mathematics has had a close relationship with astrology for a long time. Biased by astral themes, it had motivated the study of astronomy. Renowned mathematicians have also been considered to be renowned astrologists; for example, Ptolemy, Arab astronomers, Regiomantus, Cardano, Kepler, or John Dee. In the Middle Ages, astrology was considered a science that included mathematics. In his encyclopedia, Theodor Zwinger wrote that astrology was a mathematical science that studied the "active movement of bodies as they act on other bodies". He reserved to mathematics the need to "calculate with probability the influences [of stars]" to foresee their "conjunctions and oppositions".

These disciplines are no longer considered sciences.

Philosophy
Main article: Philosophy of mathematics
Reality
The connection between mathematics and material reality has led to philosophical debates since at least the time of Pythagoras. The ancient philosopher Plato argued that abstractions that reflect material reality have themselves a reality that exists outside space and time. As a result, the philosophical view that mathematical objects somehow exist on their own in abstraction is often referred to as Platonism. Independently of their possible philosophical opinions, modern mathematicians may be generally considered as Platonists, since they think of and talk of their objects of study as real objects.

Armand Borel summarized this view of mathematics reality as follows, and provided quotations of G. H. Hardy, Charles Hermite, Henri Poincaré and Albert Einstein that support his views.

Something becomes objective (as opposed to "subjective") as soon as we are convinced that it exists in the minds of others in the same form as it does in ours and that we can think about it and discuss it together. Because the language of mathematics is so precise, it is ideally suited to defining concepts for which such a consensus exists. In my opinion, that is sufficient to provide us with a feeling of an objective existence, of a reality of mathematics ...

Nevertheless, Platonism and the concurrent views on abstraction do not explain the unreasonable effectiveness of mathematics.

Proposed definitions
Main article: Definitions of mathematics
There is no general consensus about a definition of mathematics or its epistemological status—that is, its place among other human activities. A great many professional mathematicians take no interest in a definition of mathematics, or consider it undefinable. There is not even consensus on whether mathematics is an art or a science. Some just say, "mathematics is what mathematicians do". This makes sense, as there is a strong consensus among them about what is mathematics and what is not. Most proposed definitions try to define mathematics by its object of study.

Aristotle defined mathematics as "the science of quantity" and this definition prevailed until the 18th century. However, Aristotle also noted a focus on quantity alone may not distinguish mathematics from sciences like physics; in his view, abstraction and studying quantity as a property "separable in thought" from real instances set mathematics apart. In the 19th century, when mathematicians began to address topics—such as infinite sets—which have no clear-cut relation to physical reality, a variety of new definitions were given. With the large number of new areas of mathematics that appeared since the beginning of the 20th century and continue to appear, defining mathematics by this object of study becomes an impossible task.

Another approach for defining mathematics is to use its methods. So, an area of study can be qualified as mathematics as soon as one can prove theorems—assertions whose validity relies on a proof, that is, a purely-logical deduction. Others take the perspective that mathematics is an investigation of axiomatic set theory, as this study is now a foundational discipline for much of modern mathematics.

Rigor
See also: Logic
Mathematical reasoning requires rigor. This means that the definitions must be absolutely unambiguous and the proofs must be reducible to a succession of applications of inference rules,[f] without any use of empirical evidence and intuition.[g] Rigorous reasoning is not specific to mathematics, but, in mathematics, the standard of rigor is much higher than elsewhere. Despite mathematics' concision, rigorous proofs can require hundreds of pages to express. The emergence of computer-assisted proofs has allowed proof lengths to further expand,[h] such as the 255-page Feit–Thompson theorem.[i] The result of this trend is a philosophy of the quasi-empiricist proof that can not be considered infallible, but has a probability attached to it.

The concept of rigor in mathematics dates back to ancient Greece, where their society encouraged logical, deductive reasoning. However, this rigorous approach would tend to discourage exploration of new approaches, such as irrational numbers and concepts of infinity. The method of demonstrating rigorous proof was enhanced in the sixteenth century through the use of symbolic notation. In the 18th century, social transition led to mathematicians earning their keep through teaching, which led to more careful thinking about the underlying concepts of mathematics. This produced more rigorous approaches, while transitioning from geometric methods to algebraic and then arithmetic proofs.

At the end of the 19th century, it appeared that the definitions of the basic concepts of mathematics were not accurate enough for avoiding paradoxes (non-Euclidean geometries and Weierstrass function) and contradictions (Russell's paradox). This was solved by the inclusion of axioms with the apodictic inference rules of mathematical theories; the re-introduction of axiomatic method pioneered by the ancient Greeks. It results that "rigor" is no more a relevant concept in mathematics, as a proof is either correct or erroneous, and a "rigorous proof" is simply a pleonasm. Where a special concept of rigor comes into play is in the socialized aspects of a proof, wherein it may be demonstrably refuted by other mathematicians. After a proof has been accepted for many years or even decades, it can then be considered as reliable.

Nevertheless, the concept of "rigor" may remain useful for teaching to beginners what is a mathematical proof.

Training and practice
Education
Main article: Mathematics education
Mathematics has a remarkable ability to cross cultural boundaries and time periods. As a human activity, the practice of mathematics has a social side, which includes education, careers, recognition, popularization, and so on. In education, mathematics is a core part of the curriculum and forms an important element of the STEM academic disciplines. Prominent careers for professional mathematicians include math teacher or professor, statistician, actuary, financial analyst, economist, accountant, commodity trader, or computer consultant.

Archaeological evidence shows that instruction in mathematics occurred as early as the second millennium BCE in ancient Babylonia. Comparable evidence has been unearthed for scribal mathematics training in the ancient Near East and then for the Greco-Roman world starting around 300 BCE. The oldest known mathematics textbook is the Rhind papyrus, dated from c. 1650 BCE in Eygpt. Due to a scarcity of books, mathematical teachings in ancient India were communicated using memorized oral tradition since the Vedic period (c. 1500 – c. 500 BCE). In Imperial China during the Tang dynasty (618–907 CE), a mathematics curriculum was adopted for the civil service exam to join the state bureaucracy.

Following the Dark Ages, mathematics education in Europe was provided by religious schools as part of the Quadrivium. Formal instruction in pedagogy began with Jesuit schools in the 16th and 17th century. Most mathematical curriculum remained at a basic and practical level until the nineteenth century, when it began to flourish in France and Germany. The oldest journal addressing instruction in mathematics was L'Enseignement Mathématique, which began publication in 1899. The Western advancements in science and technology led to the establishment of centralized education systems in many nation-states, with mathematics as a core component—initially for its military applications. While the content of courses varies, in the present day nearly all countries teach mathematics to students for significant amounts of time.

During school, mathematical capabilities and positive expectations have a strong association with career interest in the field. Extrinsic factors such as feedback motivation by teachers, parents, and peer groups can influence the level of interest in mathematics. Some students studying math may develop an apprehension or fear about their performance in the subject. This is known as math anxiety or math phobia, and is considered the most prominent of the disorders impacting academic performance. Math anxiety can develop due to various factors such as parental and teacher attitudes, social stereotypes, and personal traits. Help to counteract the anxiety can come from changes in instructional approaches, by interactions with parents and teachers, and by tailored treatments for the individual.

Psychology (aesthetic, creativity and intuition)
The validity of a mathematical theorem relies only on the rigor of its proof, which could theoretically be done automatically by a computer program. This does not mean that there is no place for creativity in a mathematical work. On the contrary, many important mathematical results (theorems) are solutions of problems that other mathematicians failed to solve, and the invention of a way for solving them may be a fundamental way of the solving process. An extreme example is Apery's theorem: Roger Apery provided only the ideas for a proof, and the formal proof was given only several months later by three other mathematicians.

Creativity and rigor are not the only psychological aspects of the activity of mathematicians. Some mathematicians can see their activity as a game, more specifically as solving puzzles. This aspect of mathematical activity is emphasized in recreational mathematics.

Mathematicians can find an aesthetic value to mathematics. Like beauty, it is hard to define, it is commonly related to elegance, which involves qualities like simplicity, symmetry, completeness, and generality. G. H. Hardy in A Mathematician's Apology expressed the belief that the aesthetic considerations are, in themselves, sufficient to justify the study of pure mathematics. He also identified other criteria such as significance, unexpectedness, and inevitability, which contribute to mathematical aesthetic. Paul Erdős expressed this sentiment more ironically by speaking of "The Book", a supposed divine collection of the most beautiful proofs. The 1998 book Proofs from THE BOOK, inspired by Erdős, is a collection of particularly succinct and revelatory mathematical arguments. Some examples of particularly elegant results included are Euclid's proof that there are infinitely many prime numbers and the fast Fourier transform for harmonic analysis.

Some feel that to consider mathematics a science is to downplay its artistry and history in the seven traditional liberal arts. One way this difference of viewpoint plays out is in the philosophical debate as to whether mathematical results are created (as in art) or discovered (as in science). The popularity of recreational mathematics is another sign of the pleasure many find in solving mathematical questions.

In the 20th century, the mathematician L. E. J. Brouwer even initiated a philosophical perspective known as intuitionism, which primarily identifies mathematics with certain creative processes in the mind. Intuitionism is in turn one flavor of a stance known as constructivism, which only considers a mathematical object valid if it can be directly constructed, not merely guaranteed by logic indirectly. This leads committed constructivists to reject certain results, particularly arguments like existential proofs based on the law of excluded middle.

In the end, neither constructivism nor intuitionism displaced classical mathematics or achieved mainstream acceptance. However, these programs have motivated specific developments, such as intuitionistic logic and other foundational insights, which are appreciated in their own right.

Cultural impact
Globe icon.
The examples and perspective in this section deal primarily with Western culture and do not represent a worldwide view of the subject. You may improve this section, discuss the issue on the talk page, or create a new section, as appropriate. (December 2022) (Learn how and when to remove this template message)
Artistic expression
Main article: Mathematics and art

Cover page of Traité de l'harmonie réduite à ses principes naturels by Jean-Philippe Rameau
Notes that sound well together to a Western ear are sounds whose fundamental frequencies of vibration are in simple ratios. For example, an octave doubles the frequency and a perfect fifth multiplies it by 
3
2
{\frac {3}{2}}.[better source needed]

This link between frequencies and harmony was discussed in Traité de l'harmonie réduite à ses principes naturels by Jean-Philippe Rameau, a French baroque composer and music theoretician. It rests on the analysis of harmonics (noted 2 to 15 in the following figure) of a fundamental Do (noted 1); the first harmonics and their octaves sound well together.


Harmonics on a staff
The curve in red has a logarithmic shape, which reflects the following two phenomena:

The pitch of the sound, which in our auditory system is proportional to the logarithm of the sound's frequency.
The harmonic frequencies, which are integer multiples of the fundamental frequency.

Fractal with a scaling symmetry and a central symmetry
Humans, as well as some other animals, find symmetric patterns to be more beautiful. Mathematically, the symmetries of an object form a group known as the symmetry group.

For example, the group underlying mirror symmetry is the cyclic group of two elements, 
�
/
2
�
\mathbb {Z} /2\mathbb {Z} . A Rorschach test is a figure invariant by this symmetry, as well as a butterfly, and animal bodies more generally (at least on the surface).[citation needed] Waves on the sea surface possess translation symmetry: moving one's viewpoint by the distance between wave crests does not change one's view of the sea.[citation needed] Furthermore, fractals possess (usually approximate[citation needed]) self-similarity.[better source needed]

Popularization
Main article: Popular mathematics
Popular mathematics is the act of presenting mathematics without technical terms. Presenting mathematics may be hard since the general public suffers from mathematical anxiety and mathematical objects are highly abstract. However, popular mathematics writing can overcome this by using applications or cultural links. Despite this, mathematics is rarely the topic of popularization in printed or televised media.

Awards and prize problems
Main category: Mathematics awards

The front side of the Fields Medal with an illustration of the Greek polymath Archimedes
The most prestigious award in mathematics is the Fields Medal, established in 1936 and awarded every four years (except around World War II) to up to four individuals. It is considered the mathematical equivalent of the Nobel Prize.

Other prestigious mathematics awards include:

The Abel Prize, instituted in 2002 and first awarded in 2003
The Chern Medal for lifetime achievement, introduced in 2009 and first awarded in 2010
The AMS Leroy P. Steele Prize, awarded since 1970
The Wolf Prize in Mathematics, also for lifetime achievement, instituted in 1978
A famous list of 23 open problems, called "Hilbert's problems", was compiled in 1900 by German mathematician David Hilbert. This list has achieved great celebrity among mathematicians, and, as of 2022, at least thirteen of the problems (depending how some are interpreted) have been solved.

A new list of seven important problems, titled the "Millennium Prize Problems", was published in 2000. Only one of them, the Riemann hypothesis, duplicates one of Hilbert's problems. A solution to any of these problems carries a 1 million dollar reward. To date, only one of these problems, the Poincaré conjecture, has been solved.

Knowledge is a form of awareness or familiarity. It is often understood as awareness of facts or as practical skills, and may also mean familiarity with objects or situations. Knowledge of facts, also called propositional knowledge, is often defined as true belief that is distinct from opinion or guesswork by virtue of justification. While there is wide agreement among philosophers that propositional knowledge is a form of true belief, many controversies in philosophy focus on justification: whether it is needed at all, how to understand it, and whether something else besides it is needed. These controversies intensified due to a series of thought experiments by Edmund Gettier and have provoked various alternative definitions. Some of them deny that justification is necessary and suggest alternative criteria while others accept that justification is an essential aspect and formulate additional requirements.

Knowledge can be produced in many different ways. The most important source of empirical knowledge is perception, which is the usage of the senses. Many theorists also include introspection as a source of knowledge, not of external physical objects, but of one's own mental states. Other sources often discussed include memory, rational intuition, inference, and testimony. According to foundationalism, some of these sources are basic in the sense that they can justify beliefs without depending on other mental states. This claim is rejected by coherentists, who contend that a sufficient degree of coherence among all the mental states of the believer is necessary for knowledge. According to infinitism, an infinite chain of beliefs is needed.

Many different aspects of knowledge are investigated, and it plays a role in various disciplines. It is the primary subject of the field of epistemology, which studies what someone knows, how they come to know it, and what it means to know something. The problem of the value of knowledge concerns the question of why knowledge is more valuable than mere true belief. Philosophical skepticism is the thesis that humans lack any form of knowledge or that knowledge is impossible. Formal epistemology studies, among other things, the rules governing how knowledge and related states behave and in what relations they stand to each other. Science tries to acquire knowledge using the scientific method, which is based on repeatable experimentation, observation, and measurement. Many religions hold that humans should seek knowledge and that God or the divine is the source of knowledge.

umerous definitions of knowledge have been suggested. Most definitions of knowledge in analytic philosophy recognize three fundamental types. "Knowledge-that", also called propositional knowledge, can be expressed using that-clauses as in "I know that Dave is at home". "Knowledge-how" (know-how) expresses practical competence, as in "she knows how to swim". Finally, "knowledge by acquaintance" refers to a familiarity with the known object based on previous direct experience. Analytical philosophers usually aim to identify the essential features of propositional knowledge in their definitions. There is wide, though not universal, agreement among philosophers that knowledge involves a cognitive success or an epistemic contact with reality, like making a discovery, and that propositional knowledge is a form of true belief.

Despite the agreement about these general characteristics of knowledge, many deep disagreements remain regarding its exact definition. These disagreements relate to the goals and methods within epistemology and other fields, or to differences concerning the standards of knowledge that people intend to uphold, for example, what degree of certainty is required. One approach is to focus on knowledge's most salient features in order to give a practically useful definition. Another is to try to provide a theoretically precise definition by listing the conditions that are individually necessary and jointly sufficient. The term "analysis of knowledge" (or equivalently, "conception of knowledge" or "theory of knowledge") is often used for this approach. It can be understood in analogy to how chemists analyze a sample by seeking a list of all the chemical elements composing it. An example of this approach is characterizing knowledge as justified true belief (JTB), which is seen by many philosophers as the standard definition. Others seek a common core among diverse forms of knowledge, for example, that they all involve some kind of awareness or that they all belong to a special type of successful performance.

Methodological differences concern whether researchers base their inquiry on abstract and general intuitions or on concrete and specific cases, referred to as methodism and particularism, respectively. Another source of disagreement is the role of ordinary language in one's inquiry: the weight given to how the term "knowledge" is used in everyday discourse. According to Ludwig Wittgenstein, for example, there is no clear-cut definition of knowledge since it is just a cluster of concepts related through family resemblance. Different conceptions of the standards of knowledge are also responsible for various disagreements. Some epistemologists, like René Descartes, hold that knowledge demands very high requirements, like certainty, and is therefore quite rare. Others see knowledge as a rather common phenomenon, prevalent in many everyday situations, without excessively high standards.

In analytic philosophy, knowledge is usually understood as a mental state possessed by an individual person, but the term is sometimes used to refer to a characteristic of a group of people as group knowledge, social knowledge, or collective knowledge. In a slightly different sense, it can also mean knowledge stored in documents, as in "knowledge housed in the library" or the knowledge base of an expert system. The English word knowledge is a broad term. It includes various meanings that some other languages distinguish using several words. For example, Latin uses the words cognitio and scientia for "knowledge" while Spanish uses the words conocer and saber for "to know". In ancient Greek, four important terms for knowledge were used: epistēmē (unchanging theoretical knowledge), technē (expert technical knowledge), mētis (strategic knowledge), and gnōsis (personal intellectual knowledge). Knowledge is often contrasted with ignorance, which is associated with a lack of understanding, education, and true beliefs. Epistemology, also referred to as the theory of knowledge, is the philosophical discipline studying knowledge. It investigates topics like the nature of knowledge and justification, how knowledge arises, and what value it has. Further issues include the different types of knowledge and the extent to which the beliefs of most people amount to knowledge as well as the limits of what can be known.

Language is a structured system of communication that consists of grammar and vocabulary. It is the primary means by which humans convey meaning, both in spoken and written forms, and may also be conveyed through sign languages. The vast majority of human languages have developed writing systems that allow for the recording and preservation of the sounds or signs of language. Human language is characterized by its cultural and historical diversity, with significant variations observed between cultures and across time. Human languages possess the properties of productivity and displacement, which enable the creation of an infinite number of sentences, and the ability to refer to objects, events, and ideas that are not immediately present in the discourse. The use of human language relies on social convention and is acquired through learning.

Estimates of the number of human languages in the world vary between 5,000 and 7,000. Precise estimates depend on an arbitrary distinction (dichotomy) established between languages and dialects. Natural languages are spoken, signed, or both; however, any language can be encoded into secondary media using auditory, visual, or tactile stimuli – for example, writing, whistling, signing, or braille. In other words, human language is modality-independent, but written or signed language is the way to inscribe or encode the natural human speech or gestures.

Depending on philosophical perspectives regarding the definition of language and meaning, when used as a general concept, "language" may refer to the cognitive ability to learn and use systems of complex communication, or to describe the set of rules that makes up these systems, or the set of utterances that can be produced from those rules. All languages rely on the process of semiosis to relate signs to particular meanings. Oral, manual and tactile languages contain a phonological system that governs how symbols are used to form sequences known as words or morphemes, and a syntactic system that governs how words and morphemes are combined to form phrases and utterances.

The scientific study of language is called linguistics. Critical examinations of languages, such as philosophy of language, the relationships between language and thought, how words represent experience, etc., have been debated at least since Gorgias and Plato in ancient Greek civilization. Thinkers such as Jean-Jacques Rousseau (1712–1778) have argued that language originated from emotions, while others like Immanuel Kant (1724–1804) have argued that languages originated from rational and logical thought. Twentieth century philosophers such as Ludwig Wittgenstein (1889–1951) argued that philosophy is really the study of language itself. Major figures in contemporary linguistics of these times include Ferdinand de Saussure and Noam Chomsky.

Language is thought to have gradually diverged from earlier primate communication systems when early hominins acquired the ability to form a theory of mind and shared intentionality. This development is sometimes thought to have coincided with an increase in brain volume, and many linguists see the structures of language as having evolved to serve specific communicative and social functions. Language is processed in many different locations in the human brain, but especially in Broca's and Wernicke's areas. Humans acquire language through social interaction in early childhood, and children generally speak fluently by approximately three years old. Language and culture are codependent. Therefore, in addition to its strictly communicative uses, language has social uses such as signifying group identity, social stratification, as well as use for social grooming and entertainment.

Languages evolve and diversify over time, and the history of their evolution can be reconstructed by comparing modern languages to determine which traits their ancestral languages must have had in order for the later developmental stages to occur. A group of languages that descend from a common ancestor is known as a language family; in contrast, a language that has been demonstrated to not have any living or non-living relationship with another language is called a language isolate. There are also many unclassified languages whose relationships have not been established, and spurious languages may have not existed at all. Academic consensus holds that between 50% and 90% of languages spoken at the beginning of the 21st century will probably have become extinct by the year 2100.

The English word language derives ultimately from Proto-Indo-European *dn̥ǵʰwéh₂s "tongue, speech, language" through Latin lingua, "language; tongue", and Old French language. The word is sometimes used to refer to codes, ciphers, and other kinds of artificially constructed communication systems such as formally defined computer languages used for computer programming. Unlike conventional human languages, a formal language in this sense is a system of signs for encoding and decoding information. This article specifically concerns the properties of natural human language as it is studied in the discipline of linguistics.

As an object of linguistic study, "language" has two primary meanings: an abstract concept, and a specific linguistic system, e.g. "French". The Swiss linguist Ferdinand de Saussure, who defined the modern discipline of linguistics, first explicitly formulated the distinction using the French word language for language as a concept, langue as a specific instance of a language system, and parole for the concrete usage of speech in a particular language.

When speaking of language as a general concept, definitions can be used which stress different aspects of the phenomenon. These definitions also entail different approaches and understandings of language, and they also inform different and often incompatible schools of linguistic theory. Debates about the nature and origin of language go back to the ancient world. Greek philosophers such as Gorgias and Plato debated the relation between words, concepts and reality. Gorgias argued that language could represent neither the objective experience nor human experience, and that communication and truth were therefore impossible. Plato maintained that communication is possible because language represents ideas and concepts that exist independently of, and prior to, language.

During the Enlightenment and its debates about human origins, it became fashionable to speculate about the origin of language. Thinkers such as Rousseau and Johann Gottfried Herder argued that language had originated in the instinctive expression of emotions, and that it was originally closer to music and poetry than to the logical expression of rational thought. Rationalist philosophers such as Kant and René Descartes held the opposite view. Around the turn of the 20th century, thinkers began to wonder about the role of language in shaping our experiences of the world – asking whether language simply reflects the objective structure of the world, or whether it creates concepts that in turn impose structure on our experience of the objective world. This led to the question of whether philosophical problems are really firstly linguistic problems. The resurgence of the view that language plays a significant role in the creation and circulation of concepts, and that the study of philosophy is essentially the study of language, is associated with what has been called the linguistic turn and philosophers such as Wittgenstein in 20th-century philosophy. These debates about language in relation to meaning and reference, cognition and consciousness remain active today.

Mental faculty, organ or instinct
One definition sees language primarily as the mental faculty that allows humans to undertake linguistic behaviour: to learn languages and to produce and understand utterances. This definition stresses the universality of language to all humans, and it emphasizes the biological basis for the human capacity for language as a unique development of the human brain. Proponents of the view that the drive to language acquisition is innate in humans argue that this is supported by the fact that all cognitively normal children raised in an environment where language is accessible will acquire language without formal instruction. Languages may even develop spontaneously in environments where people live or grow up together without a common language; for example, creole languages and spontaneously developed sign languages such as Nicaraguan Sign Language. This view, which can be traced back to the philosophers Kant and Descartes, understands language to be largely innate, for example, in Chomsky's theory of Universal Grammar, or American philosopher Jerry Fodor's extreme innatist theory. These kinds of definitions are often applied in studies of language within a cognitive science framework and in neurolinguistics.

Formal symbolic system
Another definition sees language as a formal system of signs governed by grammatical rules of combination to communicate meaning. This definition stresses that human languages can be described as closed structural systems consisting of rules that relate particular signs to particular meanings. This structuralist view of language was first introduced by Ferdinand de Saussure, and his structuralism remains foundational for many approaches to language.

Some proponents of Saussure's view of language have advocated a formal approach which studies language structure by identifying its basic elements and then by presenting a formal account of the rules according to which the elements combine in order to form words and sentences. The main proponent of such a theory is Noam Chomsky, the originator of the generative theory of grammar, who has defined language as the construction of sentences that can be generated using transformational grammars. Chomsky considers these rules to be an innate feature of the human mind and to constitute the rudiments of what language is. By way of contrast, such transformational grammars are also commonly used in formal logic, in formal linguistics, and in applied computational linguistics. In the philosophy of language, the view of linguistic meaning as residing in the logical relations between propositions and reality was developed by philosophers such as Alfred Tarski, Bertrand Russell, and other formal logicians.

Tool for communication

A conversation in American Sign Language
Yet another definition sees language as a system of communication that enables humans to exchange verbal or symbolic utterances. This definition stresses the social functions of language and the fact that humans use it to express themselves and to manipulate objects in their environment. Functional theories of grammar explain grammatical structures by their communicative functions, and understand the grammatical structures of language to be the result of an adaptive process by which grammar was "tailored" to serve the communicative needs of its users.

This view of language is associated with the study of language in pragmatic, cognitive, and interactive frameworks, as well as in sociolinguistics and linguistic anthropology. Functionalist theories tend to study grammar as dynamic phenomena, as structures that are always in the process of changing as they are employed by their speakers. This view places importance on the study of linguistic typology, or the classification of languages according to structural features, as it can be shown that processes of grammaticalization tend to follow trajectories that are partly dependent on typology. In the philosophy of language, the view of pragmatics as being central to language and meaning is often associated with Wittgenstein's later works and with ordinary language philosophers such as J.L. Austin, Paul Grice, John Searle, and W.O. Quine.

Distinctive features of human language
Main articles: Animal language and Great ape language
A number of features, many of which were described by Charles Hockett and called design features set human language apart from communication used by non-human animals.

Communication systems used by other animals such as bees or apes are closed systems that consist of a finite, usually very limited, number of possible ideas that can be expressed. In contrast, human language is open-ended and productive, meaning that it allows humans to produce a vast range of utterances from a finite set of elements, and to create new words and sentences. This is possible because human language is based on a dual code, in which a finite number of elements which are meaningless in themselves (e.g. sounds, letters or gestures) can be combined to form an infinite number of larger units of meaning (words and sentences). However, one study has demonstrated that an Australian bird, the chestnut-crowned babbler, is capable of using the same acoustic elements in different arrangements to create two functionally distinct vocalizations. Additionally, pied babblers have demonstrated the ability to generate two functionally distinct vocalisations composed of the same sound type, which can only be distinguished by the number of repeated elements.

Several species of animals have proved to be able to acquire forms of communication through social learning: for instance a bonobo named Kanzi learned to express itself using a set of symbolic lexigrams. Similarly, many species of birds and whales learn their songs by imitating other members of their species. However, while some animals may acquire large numbers of words and symbols,[note 1] none have been able to learn as many different signs as are generally known by an average 4 year old human, nor have any acquired anything resembling the complex grammar of human language.

Human languages differ from animal communication systems in that they employ grammatical and semantic categories, such as noun and verb, present and past, which may be used to express exceedingly complex meanings. It is distinguished by the property of recursivity: for example, a noun phrase can contain another noun phrase (as in "[[the chimpanzee]'s lips]") or a clause can contain another clause (as in "[I see [the dog is running]]"). Human language is the only known natural communication system whose adaptability may be referred to as modality independent. This means that it can be used not only for communication through one channel or medium, but through several. For example, spoken language uses the auditive modality, whereas sign languages and writing use the visual modality, and braille writing uses the tactile modality.

Human language is unusual in being able to refer to abstract concepts and to imagined or hypothetical events as well as events that took place in the past or may happen in the future. This ability to refer to events that are not at the same time or place as the speech event is called displacement, and while some animal communication systems can use displacement (such as the communication of bees that can communicate the location of sources of nectar that are out of sight), the degree to which it is used in human language is also considered unique.

Origin
Main articles: Origin of language and Origin of speech
See also: Proto-Human language

The Tower of Babel by Pieter Bruegel the Elder. Oil on board, 1563.
Humans have speculated about the origins of language throughout history. The Biblical myth of the Tower of Babel is one such account; other cultures have different stories of how language arose.
Theories about the origin of language differ in regard to their basic assumptions about what language is. Some theories are based on the idea that language is so complex that one cannot imagine it simply appearing from nothing in its final form, but that it must have evolved from earlier pre-linguistic systems among our pre-human ancestors. These theories can be called continuity-based theories. The opposite viewpoint is that language is such a unique human trait that it cannot be compared to anything found among non-humans and that it must therefore have appeared suddenly in the transition from pre-hominids to early man. These theories can be defined as discontinuity-based. Similarly, theories based on the generative view of language pioneered by Noam Chomsky see language mostly as an innate faculty that is largely genetically encoded, whereas functionalist theories see it as a system that is largely cultural, learned through social interaction.

Continuity-based theories are held by a majority of scholars, but they vary in how they envision this development. Those who see language as being mostly innate, such as psychologist Steven Pinker, hold the precedents to be animal cognition, whereas those who see language as a socially learned tool of communication, such as psychologist Michael Tomasello, see it as having developed from animal communication in primates: either gestural or vocal communication to assist in cooperation. Other continuity-based models see language as having developed from music, a view already espoused by Rousseau, Herder, Humboldt, and Charles Darwin. A prominent proponent of this view is archaeologist Steven Mithen. Stephen Anderson states that the age of spoken languages is estimated at 60,000 to 100,000 years and that:

Researchers on the evolutionary origin of language generally find it plausible to suggest that language was invented only once, and that all modern spoken languages are thus in some way related, even if that relation can no longer be recovered ... because of limitations on the methods available for reconstruction.

Because language emerged in the early prehistory of man, before the existence of any written records, its early development has left no historical traces, and it is believed that no comparable processes can be observed today. Theories that stress continuity often look at animals to see if, for example, primates display any traits that can be seen as analogous to what pre-human language must have been like. Early human fossils can be inspected for traces of physical adaptation to language use or pre-linguistic forms of symbolic behaviour. Among the signs in human fossils that may suggest linguistic abilities are: the size of the brain relative to body mass, the presence of a larynx capable of advanced sound production and the nature of tools and other manufactured artifacts.

It was mostly undisputed that pre-human australopithecines did not have communication systems significantly different from those found in great apes in general. However, a 2017 study on Ardipithecus ramidus challenges this belief. Scholarly opinions vary as to the developments since the appearance of the genus Homo some 2.5 million years ago. Some scholars assume the development of primitive language-like systems (proto-language) as early as Homo habilis (2.3 million years ago) while others place the development of primitive symbolic communication only with Homo erectus (1.8 million years ago) or Homo heidelbergensis (0.6 million years ago), and the development of language proper with anatomically modern Homo sapiens with the Upper Paleolithic revolution less than 100,000 years ago.

Chomsky is one prominent proponent of a discontinuity-based theory of human language origins. He suggests that for scholars interested in the nature of language, "talk about the evolution of the language capacity is beside the point." Chomsky proposes that perhaps "some random mutation took place [...] and it reorganized the brain, implanting a language organ in an otherwise primate brain." Though cautioning against taking this story literally, Chomsky insists that "it may be closer to reality than many other fairy tales that are told about evolutionary processes, including language."

Study

William Jones discovered the family relation between Latin and Sanskrit, laying the ground for the discipline of historical linguistics.
Main articles: Linguistics and History of linguistics
The study of language, linguistics, has been developing into a science since the first grammatical descriptions of particular languages in India more than 2000 years ago, after the development of the Brahmi script. Modern linguistics is a science that concerns itself with all aspects of language, examining it from all of the theoretical viewpoints described above.

Subdisciplines
The academic study of language is conducted within many different disciplinary areas and from different theoretical angles, all of which inform modern approaches to linguistics. For example, descriptive linguistics examines the grammar of single languages, theoretical linguistics develops theories on how best to conceptualize and define the nature of language based on data from the various extant human languages, sociolinguistics studies how languages are used for social purposes informing in turn the study of the social functions of language and grammatical description, neurolinguistics studies how language is processed in the human brain and allows the experimental testing of theories, computational linguistics builds on theoretical and descriptive linguistics to construct computational models of language often aimed at processing natural language or at testing linguistic hypotheses, and historical linguistics relies on grammatical and lexical descriptions of languages to trace their individual histories and reconstruct trees of language families by using the comparative method.

Early history

Ferdinand de Saussure developed the structuralist approach to studying language.
The formal study of language is often considered to have started in India with Pāṇini, the 5th century BC grammarian who formulated 3,959 rules of Sanskrit morphology. However, Sumerian scribes already studied the differences between Sumerian and Akkadian grammar around 1900 BC. Subsequent grammatical traditions developed in all of the ancient cultures that adopted writing.

In the 17th century AD, the French Port-Royal Grammarians developed the idea that the grammars of all languages were a reflection of the universal basics of thought, and therefore that grammar was universal. In the 18th century, the first use of the comparative method by British philologist and expert on ancient India William Jones sparked the rise of comparative linguistics. The scientific study of language was broadened from Indo-European to language in general by Wilhelm von Humboldt. Early in the 20th century, Ferdinand de Saussure introduced the idea of language as a static system of interconnected units, defined through the oppositions between them.

By introducing a distinction between diachronic and synchronic analyses of language, he laid the foundation of the modern discipline of linguistics. Saussure also introduced several basic dimensions of linguistic analysis that are still fundamental in many contemporary linguistic theories, such as the distinctions between syntagm and paradigm, and the Langue-parole distinction, distinguishing language as an abstract system (langue), from language as a concrete manifestation of this system (parole).

Modern linguistics

Noam Chomsky is one of the most important linguistic theorists of the 20th century.
In the 1960s, Noam Chomsky formulated the generative theory of language. According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated.

In opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out.[note 2] The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language.

Physiological and neural architecture of language and speech
Speaking is the default modality for language in all cultures. The production of spoken language depends on sophisticated capacities for controlling the lips, tongue and other components of the vocal apparatus, the ability to acoustically decode speech sounds, and the neurological apparatus required for acquiring and producing language. The study of the genetic bases for human language is at an early stage: the only gene that has definitely been implicated in language production is FOXP2, which may cause a kind of congenital language disorder if affected by mutations.

The brain
Main articles: Neurolinguistics and Language processing in the brain

Language Areas of the brain.
  Angular gyrus
  Supramarginal gyrus
  Broca's area
  Wernicke's area
  Primary auditory cortex
The brain is the coordinating center of all linguistic activity; it controls both the production of linguistic cognition and of meaning and the mechanics of speech production. Nonetheless, our knowledge of the neurological bases for language is quite limited, though it has advanced considerably with the use of modern imaging techniques. The discipline of linguistics dedicated to studying the neurological aspects of language is called neurolinguistics.

Early work in neurolinguistics involved the study of language in people with brain lesions, to see how lesions in specific areas affect language and speech. In this way, neuroscientists in the 19th century discovered that two areas in the brain are crucially implicated in language processing. The first area is Wernicke's area, which is in the posterior section of the superior temporal gyrus in the dominant cerebral hemisphere. People with a lesion in this area of the brain develop receptive aphasia, a condition in which there is a major impairment of language comprehension, while speech retains a natural-sounding rhythm and a relatively normal sentence structure. The second area is Broca's area, in the posterior inferior frontal gyrus of the dominant hemisphere. People with a lesion to this area develop expressive aphasia, meaning that they know what they want to say, they just cannot get it out. They are typically able to understand what is being said to them, but unable to speak fluently. Other symptoms that may be present in expressive aphasia include problems with word repetition. The condition affects both spoken and written language. Those with this aphasia also exhibit ungrammatical speech and show inability to use syntactic information to determine the meaning of sentences. Both expressive and receptive aphasia also affect the use of sign language, in analogous ways to how they affect speech, with expressive aphasia causing signers to sign slowly and with incorrect grammar, whereas a signer with receptive aphasia will sign fluently, but make little sense to others and have difficulties comprehending others' signs. This shows that the impairment is specific to the ability to use language, not to the physiology used for speech production.

With technological advances in the late 20th century, neurolinguists have also incorporated non-invasive techniques such as functional magnetic resonance imaging (fMRI) and electrophysiology to study language processing in individuals without impairments.

Anatomy of speech
Main articles: Speech production, Phonetics, and Articulatory phonetics

The human vocal tract

Spectrogram of American English vowels [i, u, ɑ] showing the formants f1 and f2
0:15
Real time MRI scan of a person speaking in Mandarin Chinese
Spoken language relies on human physical ability to produce sound, which is a longitudinal wave propagated through the air at a frequency capable of vibrating the ear drum. This ability depends on the physiology of the human speech organs. These organs consist of the lungs, the voice box (larynx), and the upper vocal tract – the throat, the mouth, and the nose. By controlling the different parts of the speech apparatus, the airstream can be manipulated to produce different speech sounds.

The sound of speech can be analyzed into a combination of segmental and suprasegmental elements. The segmental elements are those that follow each other in sequences, which are usually represented by distinct letters in alphabetic scripts, such as the Roman script. In free flowing speech, there are no clear boundaries between one segment and the next, nor usually are there any audible pauses between them. Segments therefore are distinguished by their distinct sounds which are a result of their different articulations, and can be either vowels or consonants. Suprasegmental phenomena encompass such elements as stress, phonation type, voice timbre, and prosody or intonation, all of which may have effects across multiple segments.

Consonants and vowel segments combine to form syllables, which in turn combine to form utterances; these can be distinguished phonetically as the space between two inhalations. Acoustically, these different segments are characterized by different formant structures, that are visible in a spectrogram of the recorded sound wave. Formants are the amplitude peaks in the frequency spectrum of a specific sound.

Vowels are those sounds that have no audible friction caused by the narrowing or obstruction of some part of the upper vocal tract. They vary in quality according to the degree of lip aperture and the placement of the tongue within the oral cavity. Vowels are called close when the lips are relatively closed, as in the pronunciation of the vowel [i] (English "ee"), or open when the lips are relatively open, as in the vowel [a] (English "ah"). If the tongue is located towards the back of the mouth, the quality changes, creating vowels such as [u] (English "oo"). The quality also changes depending on whether the lips are rounded as opposed to unrounded, creating distinctions such as that between [i] (unrounded front vowel such as English "ee") and [y] (rounded front vowel such as German "ü").

Consonants are those sounds that have audible friction or closure at some point within the upper vocal tract. Consonant sounds vary by place of articulation, i.e. the place in the vocal tract where the airflow is obstructed, commonly at the lips, teeth, alveolar ridge, palate, velum, uvula, or glottis. Each place of articulation produces a different set of consonant sounds, which are further distinguished by manner of articulation, or the kind of friction, whether full closure, in which case the consonant is called occlusive or stop, or different degrees of aperture creating fricatives and approximants. Consonants can also be either voiced or unvoiced, depending on whether the vocal cords are set in vibration by airflow during the production of the sound. Voicing is what separates English [s] in bus (unvoiced sibilant) from [z] in buzz (voiced sibilant).

Some speech sounds, both vowels and consonants, involve release of air flow through the nasal cavity, and these are called nasals or nasalized sounds. Other sounds are defined by the way the tongue moves within the mouth such as the l-sounds (called laterals, because the air flows along both sides of the tongue), and the r-sounds (called rhotics).

By using these speech organs, humans can produce hundreds of distinct sounds: some appear very often in the world's languages, whereas others are much more common in certain language families, language areas, or even specific to a single language.

Modality
Human languages display considerable plasticity  in their deployment of two fundamental modes: oral (speech and mouthing) and manual (sign and gesture).[note 3] For example, it is common for oral language to be accompanied by gesture, and for sign language to be accompanied by mouthing. In addition, some language communities use both modes to convey lexical or grammatical meaning, each mode complementing the other. Such bimodal use of language is especially common in genres such as story-telling (with Plains Indian Sign Language and Australian Aboriginal sign languages used alongside oral language, for example), but also occurs in mundane conversation. For instance, many Australian languages have a rich set of case suffixes that provide details about the instrument used to perform an action. Others lack such grammatical precision in the oral mode, but supplement it with gesture to convey that information in the sign mode. In Iwaidja, for example, 'he went out for fish using a torch' is spoken as simply "he-hunted fish torch", but the word for 'torch' is accompanied by a gesture indicating that it was held. In another example, the ritual language Damin had a heavily reduced oral vocabulary of only a few hundred words, each of which was very general in meaning, but which were supplemented by gesture for greater precision (e.g., the single word for fish, l*i, was accompanied by a gesture to indicate the kind of fish).

Secondary modes of language, by which a fundamental mode is conveyed in a different medium, include writing (including braille), sign (in manually coded language), whistling and drumming. Tertiary modes – such as semaphore, Morse code and spelling alphabets – convey the secondary mode of writing in a different medium. For some extinct languages that are maintained for ritual or liturgical purposes, writing may be the primary mode, with speech secondary.

Structure
When described as a system of symbolic communication, language is traditionally seen as consisting of three parts: signs, meanings, and a code connecting signs with their meanings. The study of the process of semiosis, how signs and meanings are combined, used, and interpreted is called semiotics. Signs can be composed of sounds, gestures, letters, or symbols, depending on whether the language is spoken, signed, or written, and they can be combined into complex signs, such as words and phrases. When used in communication, a sign is encoded and transmitted by a sender through a channel to a receiver who decodes it.


Ancient Tamil inscription at Thanjavur
Some of the properties that define human language as opposed to other communication systems are: the arbitrariness of the linguistic sign, meaning that there is no predictable connection between a linguistic sign and its meaning; the duality of the linguistic system, meaning that linguistic structures are built by combining elements into larger structures that can be seen as layered, e.g. how sounds build words and words build phrases; the discreteness of the elements of language, meaning that the elements out of which linguistic signs are constructed are discrete units, e.g. sounds and words, that can be distinguished from each other and rearranged in different patterns; and the productivity of the linguistic system, meaning that the finite number of linguistic elements can be combined into a theoretically infinite number of combinations.

The rules by which signs can be combined to form words and phrases are called syntax or grammar. The meaning that is connected to individual signs, morphemes, words, phrases, and texts is called semantics. The division of language into separate but connected systems of sign and meaning goes back to the first linguistic studies of de Saussure and is now used in almost all branches of linguistics.

Semantics
Main articles: Semantics, Semiotics, and Meaning (linguistics)
Languages express meaning by relating a sign form to a meaning, or its content. Sign forms must be something that can be perceived, for example, in sounds, images, or gestures, and then related to a specific meaning by social convention. Because the basic relation of meaning for most linguistic signs is based on social convention, linguistic signs can be considered arbitrary, in the sense that the convention is established socially and historically, rather than by means of a natural relation between a specific sign form and its meaning.

Thus, languages must have a vocabulary of signs related to specific meaning. The English sign "dog" denotes, for example, a member of the species Canis familiaris. In a language, the array of arbitrary signs connected to specific meanings is called the lexicon, and a single sign connected to a meaning is called a lexeme. Not all meanings in a language are represented by single words. Often, semantic concepts are embedded in the morphology or syntax of the language in the form of grammatical categories.

All languages contain the semantic structure of predication: a structure that predicates a property, state, or action. Traditionally, semantics has been understood to be the study of how speakers and interpreters assign truth values to statements, so that meaning is understood to be the process by which a predicate can be said to be true or false about an entity, e.g. "[x [is y]]" or "[x [does y]]". Recently, this model of semantics has been complemented with more dynamic models of meaning that incorporate shared knowledge about the context in which a sign is interpreted into the production of meaning. Such models of meaning are explored in the field of pragmatics.

Sounds and symbols
Main articles: Phonology and Writing

A spectrogram showing the sound of the spoken English word "man", which is written phonetically as [mæn]. In flowing speech, there is no clear division between segments, only a smooth transition as the vocal apparatus moves.

The syllable "wi" in the Hangul script

The sign for "wi" in Korean Sign Language (see Korean manual alphabet)
Depending on modality, language structure can be based on systems of sounds (speech), gestures (sign languages), or graphic or tactile symbols (writing). The ways in which languages use sounds or signs to construct meaning are studied in phonology.

Sounds as part of a linguistic system are called phonemes. Phonemes are abstract units of sound, defined as the smallest units in a language that can serve to distinguish between the meaning of a pair of minimally different words, a so-called minimal pair. In English, for example, the words bat [bæt] and pat [pʰæt] form a minimal pair, in which the distinction between /b/ and /p/ differentiates the two words, which have different meanings. However, each language contrasts sounds in different ways. For example, in a language that does not distinguish between voiced and unvoiced consonants, the sounds [p] and [b] (if they both occur) could be considered a single phoneme, and consequently, the two pronunciations would have the same meaning. Similarly, the English language does not distinguish phonemically between aspirated and non-aspirated pronunciations of consonants, as many other languages like Korean and Hindi do: the unaspirated /p/ in spin [spɪn] and the aspirated /p/ in pin [pʰɪn] are considered to be merely different ways of pronouncing the same phoneme (such variants of a single phoneme are called allophones), whereas in Mandarin Chinese, the same difference in pronunciation distinguishes between the words [pʰá] 'crouch' and [pá] 'eight' (the accent above the á means that the vowel is pronounced with a high tone).

All spoken languages have phonemes of at least two different categories, vowels and consonants, that can be combined to form syllables. As well as segments such as consonants and vowels, some languages also use sound in other ways to convey meaning. Many languages, for example, use stress, pitch, duration, and tone to distinguish meaning. Because these phenomena operate outside of the level of single segments, they are called suprasegmental. Some languages have only a few phonemes, for example, Rotokas and Pirahã language with 11 and 10 phonemes respectively, whereas languages like Taa may have as many as 141 phonemes. In sign languages, the equivalent to phonemes (formerly called cheremes) are defined by the basic elements of gestures, such as hand shape, orientation, location, and motion, which correspond to manners of articulation in spoken language.

Writing systems represent language using visual symbols, which may or may not correspond to the sounds of spoken language. The Latin alphabet (and those on which it is based or that have been derived from it) was originally based on the representation of single sounds, so that words were constructed from letters that generally denote a single consonant or vowel in the structure of the word. In syllabic scripts, such as the Inuktitut syllabary, each sign represents a whole syllable. In logographic scripts, each sign represents an entire word, and will generally bear no relation to the sound of that word in spoken language.

Because all languages have a very large number of words, no purely logographic scripts are known to exist. Written language represents the way spoken sounds and words follow one after another by arranging symbols according to a pattern that follows a certain direction. The direction used in a writing system is entirely arbitrary and established by convention. Some writing systems use the horizontal axis (left to right as the Latin script or right to left as the Arabic script), while others such as traditional Chinese writing use the vertical dimension (from top to bottom). A few writing systems use opposite directions for alternating lines, and others, such as the ancient Maya script, can be written in either direction and rely on graphic cues to show the reader the direction of reading.

In order to represent the sounds of the world's languages in writing, linguists have developed the International Phonetic Alphabet, designed to represent all of the discrete sounds that are known to contribute to meaning in human languages.

Grammar
Main article: Grammar
Grammar is the study of how meaningful elements called morphemes within a language can be combined into utterances. Morphemes can either be free or bound. If they are free to be moved around within an utterance, they are usually called words, and if they are bound to other words or morphemes, they are called affixes. The way in which meaningful elements can be combined within a language is governed by rules. The study of the rules for the internal structure of words are called morphology. The rules of the internal structure of phrases and sentences are called syntax.

Grammatical categories
Main article: Grammatical category
Grammar can be described as a system of categories and a set of rules that determine how categories combine to form different aspects of meaning. Languages differ widely in whether they are encoded through the use of categories or lexical units. However, several categories are so common as to be nearly universal. Such universal categories include the encoding of the grammatical relations of participants and predicates by grammatically distinguishing between their relations to a predicate, the encoding of temporal and spatial relations on predicates, and a system of grammatical person governing reference to and distinction between speakers and addressees and those about whom they are speaking.

Word classes
Languages organize their parts of speech into classes according to their functions and positions relative to other parts. All languages, for instance, make a basic distinction between a group of words that prototypically denotes things and concepts and a group of words that prototypically denotes actions and events. The first group, which includes English words such as "dog" and "song", are usually called nouns. The second, which includes "think" and "sing", are called verbs. Another common category is the adjective: words that describe properties or qualities of nouns, such as "red" or "big". Word classes can be "open" if new words can continuously be added to the class, or relatively "closed" if there is a fixed number of words in a class. In English, the class of pronouns is closed, whereas the class of adjectives is open, since an infinite number of adjectives can be constructed from verbs (e.g. "saddened") or nouns (e.g. with the -like suffix, as in "noun-like"). In other languages such as Korean, the situation is the opposite, and new pronouns can be constructed, whereas the number of adjectives is fixed.

Word classes also carry out differing functions in grammar. Prototypically, verbs are used to construct predicates, while nouns are used as arguments of predicates. In a sentence such as "Sally runs", the predicate is "runs", because it is the word that predicates a specific state about its argument "Sally". Some verbs such as "curse" can take two arguments, e.g. "Sally cursed John". A predicate that can only take a single argument is called intransitive, while a predicate that can take two arguments is called transitive.

Many other word classes exist in different languages, such as conjunctions like "and" that serve to join two sentences, articles that introduce a noun, interjections such as "wow!", or ideophones like "splash" that mimic the sound of some event. Some languages have positionals that describe the spatial position of an event or entity. Many languages have classifiers that identify countable nouns as belonging to a particular type or having a particular shape. For instance, in Japanese, the general noun classifier for humans is nin (人), and it is used for counting humans, whatever they are called:

san-nin no gakusei (三人の学生) lit. "3 human-classifier of student" – three students
For trees, it would be:

san-bon no ki (三本の木) lit. "3 classifier-for-long-objects of tree" – three trees
Morphology
In linguistics, the study of the internal structure of complex words and the processes by which words are formed is called morphology. In most languages, it is possible to construct complex words that are built of several morphemes. For instance, the English word "unexpected" can be analyzed as being composed of the three morphemes "un-", "expect" and "-ed".

Morphemes can be classified according to whether they are independent morphemes, so-called roots, or whether they can only co-occur attached to other morphemes. These bound morphemes or affixes can be classified according to their position in relation to the root: prefixes precede the root, suffixes follow the root, and infixes are inserted in the middle of a root. Affixes serve to modify or elaborate the meaning of the root. Some languages change the meaning of words by changing the phonological structure of a word, for example, the English word "run", which in the past tense is "ran". This process is called ablaut. Furthermore, morphology distinguishes between the process of inflection, which modifies or elaborates on a word, and the process of derivation, which creates a new word from an existing one. In English, the verb "sing" has the inflectional forms "singing" and "sung", which are both verbs, and the derivational form "singer", which is a noun derived from the verb with the agentive suffix "-er".

Languages differ widely in how much they rely on morphological processes of word formation. In some languages, for example, Chinese, there are no morphological processes, and all grammatical information is encoded syntactically by forming strings of single words. This type of morpho-syntax is often called isolating, or analytic, because there is almost a full correspondence between a single word and a single aspect of meaning. Most languages have words consisting of several morphemes, but they vary in the degree to which morphemes are discrete units. In many languages, notably in most Indo-European languages, single morphemes may have several distinct meanings that cannot be analyzed into smaller segments. For example, in Latin, the word bonus, or "good", consists of the root bon-, meaning "good", and the suffix -us, which indicates masculine gender, singular number, and nominative case. These languages are called fusional languages, because several meanings may be fused into a single morpheme. The opposite of fusional languages are agglutinative languages which construct words by stringing morphemes together in chains, but with each morpheme as a discrete semantic unit. An example of such a language is Turkish, where for example, the word evlerinizden, or "from your houses", consists of the morphemes, ev-ler-iniz-den with the meanings house-plural-your-from. The languages that rely on morphology to the greatest extent are traditionally called polysynthetic languages. They may express the equivalent of an entire English sentence in a single word. For example, in Persian the single word nafahmidamesh means I didn't understand it consisting of morphemes na-fahm-id-am-esh with the meanings, "negation.understand.past.I.it". As another example with more complexity, in the Yupik word tuntussuqatarniksatengqiggtuq, which means "He had not yet said again that he was going to hunt reindeer", the word consists of the morphemes tuntu-ssur-qatar-ni-ksaite-ngqiggte-uq with the meanings, "reindeer-hunt-future-say-negation-again-third.person.singular.indicative", and except for the morpheme tuntu ("reindeer") none of the other morphemes can appear in isolation.

Many languages use morphology to cross-reference words within a sentence. This is sometimes called agreement. For example, in many Indo-European languages, adjectives must cross-reference the noun they modify in terms of number, case, and gender, so that the Latin adjective bonus, or "good", is inflected to agree with a noun that is masculine gender, singular number, and nominative case. In many polysynthetic languages, verbs cross-reference their subjects and objects. In these types of languages, a single verb may include information that would require an entire sentence in English. For example, in the Basque phrase ikusi nauzu, or "you saw me", the past tense auxiliary verb n-au-zu (similar to English "do") agrees with both the subject (you) expressed by the n- prefix, and with the object (me) expressed by the – zu suffix. The sentence could be directly transliterated as "see you-did-me"

Syntax
Main article: Syntax

In addition to word classes, a sentence can be analyzed in terms of grammatical functions: "The cat" is the subject of the phrase, "on the mat" is a locative phrase, and "sat" is the core of the predicate.
Another way in which languages convey meaning is through the order of words within a sentence. The grammatical rules for how to produce new sentences from words that are already known is called syntax. The syntactical rules of a language determine why a sentence in English such as "I love you" is meaningful, but "*love you I" is not.[note 4] Syntactical rules determine how word order and sentence structure is constrained, and how those constraints contribute to meaning. For example, in English, the two sentences "the slaves were cursing the master" and "the master was cursing the slaves" mean different things, because the role of the grammatical subject is encoded by the noun being in front of the verb, and the role of object is encoded by the noun appearing after the verb. Conversely, in Latin, both Dominus servos vituperabat and Servos vituperabat dominus mean "the master was reprimanding the slaves", because servos, or "slaves", is in the accusative case, showing that they are the grammatical object of the sentence, and dominus, or "master", is in the nominative case, showing that he is the subject.

Latin uses morphology to express the distinction between subject and object, whereas English uses word order. Another example of how syntactic rules contribute to meaning is the rule of inverse word order in questions, which exists in many languages. This rule explains why when in English, the phrase "John is talking to Lucy" is turned into a question, it becomes "Who is John talking to?", and not "John is talking to who?". The latter example may be used as a way of placing special emphasis on "who", thereby slightly altering the meaning of the question. Syntax also includes the rules for how complex sentences are structured by grouping words together in units, called phrases, that can occupy different places in a larger syntactic structure. Sentences can be described as consisting of phrases connected in a tree structure, connecting the phrases to each other at different levels. To the right is a graphic representation of the syntactic analysis of the English sentence "the cat sat on the mat". The sentence is analyzed as being constituted by a noun phrase, a verb, and a prepositional phrase; the prepositional phrase is further divided into a preposition and a noun phrase, and the noun phrases consist of an article and a noun.

The reason sentences can be seen as being composed of phrases is because each phrase would be moved around as a single element if syntactic operations were carried out. For example, "the cat" is one phrase, and "on the mat" is another, because they would be treated as single units if a decision was made to emphasize the location by moving forward the prepositional phrase: "[And] on the mat, the cat sat". There are many different formalist and functionalist frameworks that propose theories for describing syntactic structures, based on different assumptions about what language is and how it should be described. Each of them would analyze a sentence such as this in a different manner.

Typology and universals
Main articles: Linguistic typology and Linguistic universal
Languages can be classified in relation to their grammatical types. Languages that belong to different families nonetheless often have features in common, and these shared features tend to correlate. For example, languages can be classified on the basis of their basic word order, the relative order of the verb, and its constituents in a normal indicative sentence. In English, the basic order is SVO (subject–verb–object): "The snake(S) bit(V) the man(O)", whereas for example, the corresponding sentence in the Australian language Gamilaraay would be d̪uyugu n̪ama d̪ayn yiːy (snake man bit), SOV. Word order type is relevant as a typological parameter, because basic word order type corresponds with other syntactic parameters, such as the relative order of nouns and adjectives, or of the use of prepositions or postpositions. Such correlations are called implicational universals. For example, most (but not all) languages that are of the SOV type have postpositions rather than prepositions, and have adjectives before nouns.

All languages structure sentences into Subject, Verb, and Object, but languages differ in the way they classify the relations between actors and actions. English uses the nominative-accusative word typology: in English transitive clauses, the subjects of both intransitive sentences ("I run") and transitive sentences ("I love you") are treated in the same way, shown here by the nominative pronoun I. Some languages, called ergative, Gamilaraay among them, distinguish instead between Agents and Patients. In ergative languages, the single participant in an intransitive sentence, such as "I run", is treated the same as the patient in a transitive sentence, giving the equivalent of "me run". Only in transitive sentences would the equivalent of the pronoun "I" be used. In this way the semantic roles can map onto the grammatical relations in different ways, grouping an intransitive subject either with Agents (accusative type) or Patients (ergative type) or even making each of the three roles differently, which is called the tripartite type.

The shared features of languages which belong to the same typological class type may have arisen completely independently. Their co-occurrence might be due to universal laws governing the structure of natural languages, "language universals", or they might be the result of languages evolving convergent solutions to the recurring communicative problems that humans use language to solve.

Social contexts of use and transmission

Wall of Love on Montmartre in Paris: "I love you" in 250 languages, by calligraphist Fédéric Baron and artist Claire Kito (2000)
While humans have the ability to learn any language, they only do so if they grow up in an environment in which language exists and is used by others. Language is therefore dependent on communities of speakers in which children learn language from their elders and peers and themselves transmit language to their own children. Languages are used by those who speak them to communicate and to solve a plethora of social tasks. Many aspects of language use can be seen to be adapted specifically to these purposes. Owing to the way in which language is transmitted between generations and within communities, language perpetually changes, diversifying into new languages or converging due to language contact. The process is similar to the process of evolution, where the process of descent with modification leads to the formation of a phylogenetic tree.

However, languages differ from biological organisms in that they readily incorporate elements from other languages through the process of diffusion, as speakers of different languages come into contact. Humans also frequently speak more than one language, acquiring their first language or languages as children, or learning new languages as they grow up. Because of the increased language contact in the globalizing world, many small languages are becoming endangered as their speakers shift to other languages that afford the possibility to participate in larger and more influential speech communities.

Usage and meaning
Main article: Pragmatics
When studying the way in which words and signs are used, it is often the case that words have different meanings, depending on the social context of use. An important example of this is the process called deixis, which describes the way in which certain words refer to entities through their relation between a specific point in time and space when the word is uttered. Such words are, for example, the word, "I" (which designates the person speaking), "now" (which designates the moment of speaking), and "here" (which designates the position of speaking). Signs also change their meanings over time, as the conventions governing their usage gradually change. The study of how the meaning of linguistic expressions changes depending on context is called pragmatics. Deixis is an important part of the way that we use language to point out entities in the world. Pragmatics is concerned with the ways in which language use is patterned and how these patterns contribute to meaning. For example, in all languages, linguistic expressions can be used not just to transmit information, but to perform actions. Certain actions are made only through language, but nonetheless have tangible effects, e.g. the act of "naming", which creates a new name for some entity, or the act of "pronouncing someone man and wife", which creates a social contract of marriage. These types of acts are called speech acts, although they can also be carried out through writing or hand signing.

The form of linguistic expression often does not correspond to the meaning that it actually has in a social context. For example, if at a dinner table a person asks, "Can you reach the salt?", that is, in fact, not a question about the length of the arms of the one being addressed, but a request to pass the salt across the table. This meaning is implied by the context in which it is spoken; these kinds of effects of meaning are called conversational implicatures. These social rules for which ways of using language are considered appropriate in certain situations and how utterances are to be understood in relation to their context vary between communities, and learning them is a large part of acquiring communicative competence in a language.

Acquisition
Main articles: Language acquisition, Second-language acquisition, Second language, and Language education
All healthy, normally developing human beings learn to use language. Children acquire the language or languages used around them: whichever languages they receive sufficient exposure to during childhood. The development is essentially the same for children acquiring sign or oral languages. This learning process is referred to as first-language acquisition, since unlike many other kinds of learning, it requires no direct teaching or specialized study. In The Descent of Man, naturalist Charles Darwin called this process "an instinctive tendency to acquire an art".


A lesson at Kituwah Academy, a school where English and the Cherokee language are mediums of instruction
First language acquisition proceeds in a fairly regular sequence, though there is a wide degree of variation in the timing of particular stages among normally developing infants. Studies published in 2013 have indicated that unborn fetuses are capable of language acquisition to some degree. From birth, newborns respond more readily to human speech than to other sounds. Around one month of age, babies appear to be able to distinguish between different speech sounds. Around six months of age, a child will begin babbling, producing the speech sounds or handshapes of the languages used around them. Words appear around the age of 12 to 18 months; the average vocabulary of an eighteen-month-old child is around 50 words. A child's first utterances are holophrases (literally "whole-sentences"), utterances that use just one word to communicate some idea. Several months after a child begins producing words, he or she will produce two-word utterances, and within a few more months will begin to produce telegraphic speech, or short sentences that are less grammatically complex than adult speech, but that do show regular syntactic structure. From roughly the age of three to five years, a child's ability to speak or sign is refined to the point that it resembles adult language.

Acquisition of second and additional languages can come at any age, through exposure in daily life or courses. Children learning a second language are more likely to achieve native-like fluency than adults, but in general, it is very rare for someone speaking a second language to pass completely for a native speaker. An important difference between first language acquisition and additional language acquisition is that the process of additional language acquisition is influenced by languages that the learner already knows.

Culture
See also: Culture and Speech community

Arnold Lakhovsky, The Conversation (c. 1935)
Languages, understood as the particular set of speech norms of a particular community, are also a part of the larger culture of the community that speaks them. Languages differ not only in pronunciation, vocabulary, and grammar, but also through having different "cultures of speaking." Humans use language as a way of signalling identity with one cultural group as well as difference from others. Even among speakers of one language, several different ways of using the language exist, and each is used to signal affiliation with particular subgroups within a larger culture. Linguists and anthropologists, particularly sociolinguists, ethnolinguists, and linguistic anthropologists have specialized in studying how ways of speaking vary between speech communities.

Linguists use the term "varieties" to refer to the different ways of speaking a language. This term includes geographically or socioculturally defined dialects as well as the jargons or styles of subcultures. Linguistic anthropologists and sociologists of language define communicative style as the ways that language is used and understood within a particular culture.

Because norms for language use are shared by members of a specific group, communicative style also becomes a way of displaying and constructing group identity. Linguistic differences may become salient markers of divisions between social groups, for example, speaking a language with a particular accent may imply membership of an ethnic minority or social class, one's area of origin, or status as a second language speaker. These kinds of differences are not part of the linguistic system, but are an important part of how people use language as a social tool for constructing groups.

However, many languages also have grammatical conventions that signal the social position of the speaker in relation to others through the use of registers that are related to social hierarchies or divisions. In many languages, there are stylistic or even grammatical differences between the ways men and women speak, between age groups, or between social classes, just as some languages employ different words depending on who is listening. For example, in the Australian language Dyirbal, a married man must use a special set of words to refer to everyday items when speaking in the presence of his mother-in-law. Some cultures, for example, have elaborate systems of "social deixis", or systems of signalling social distance through linguistic means. In English, social deixis is shown mostly through distinguishing between addressing some people by first name and others by surname, and in titles such as "Mrs.", "boy", "Doctor", or "Your Honor", but in other languages, such systems may be highly complex and codified in the entire grammar and vocabulary of the language. For instance, in languages of east Asia such as Thai, Burmese, and Javanese, different words are used according to whether a speaker is addressing someone of higher or lower rank than oneself in a ranking system with animals and children ranking the lowest and gods and members of royalty as the highest.

Writing, literacy and technology
Main articles: Writing and Literacy

An inscription of Swampy Cree using Canadian Aboriginal syllabics, an abugida developed by Christian missionaries for Indigenous Canadian languages
Throughout history a number of different ways of representing language in graphic media have been invented. These are called writing systems.

The use of writing has made language even more useful to humans. It makes it possible to store large amounts of information outside of the human body and retrieve it again, and it allows communication across physical distances and timespans that would otherwise be impossible. Many languages conventionally employ different genres, styles, and registers in written and spoken language, and in some communities, writing traditionally takes place in an entirely different language than the one spoken. There is some evidence that the use of writing also has effects on the cognitive development of humans, perhaps because acquiring literacy generally requires explicit and formal education.

The invention of the first writing systems is roughly contemporary with the beginning of the Bronze Age in the late 4th millennium BC. The Sumerian archaic cuneiform script and the Egyptian hieroglyphs are generally considered to be the earliest writing systems, both emerging out of their ancestral proto-literate symbol systems from 3400 to 3200 BC with the earliest coherent texts from about 2600 BC. It is generally agreed that Sumerian writing was an independent invention; however, it is debated whether Egyptian writing was developed completely independently of Sumerian, or was a case of cultural diffusion. A similar debate exists for the Chinese script, which developed around 1200 BC. The pre-Columbian Mesoamerican writing systems (including among others Olmec and Maya scripts) are generally believed to have had independent origins.

Change
Main articles: Language change and Grammaticalization

The first page of the poem Beowulf, written in Old English in the early medieval period (800–1100 AD). Although Old English is the direct ancestor of modern English, it is unintelligible to contemporary English speakers.
All languages change as speakers adopt or invent new ways of speaking and pass them on to other members of their speech community. Language change happens at all levels from the phonological level to the levels of vocabulary, morphology, syntax, and discourse. Even though language change is often initially evaluated negatively by speakers of the language who often consider changes to be "decay" or a sign of slipping norms of language usage, it is natural and inevitable.

Changes may affect specific sounds or the entire phonological system. Sound change can consist of the replacement of one speech sound or phonetic feature by another, the complete loss of the affected sound, or even the introduction of a new sound in a place where there had been none. Sound changes can be conditioned in which case a sound is changed only if it occurs in the vicinity of certain other sounds. Sound change is usually assumed to be regular, which means that it is expected to apply mechanically whenever its structural conditions are met, irrespective of any non-phonological factors. On the other hand, sound changes can sometimes be sporadic, affecting only one particular word or a few words, without any seeming regularity. Sometimes a simple change triggers a chain shift in which the entire phonological system is affected. This happened in the Germanic languages when the sound change known as Grimm's law affected all the stop consonants in the system. The original consonant *bʰ became /b/ in the Germanic languages, the previous *b in turn became /p/, and the previous *p became /f/. The same process applied to all stop consonants and explains why Italic languages such as Latin have p in words like pater and pisces, whereas Germanic languages, like English, have father and fish.

Another example is the Great Vowel Shift in English, which is the reason that the spelling of English vowels do not correspond well to their current pronunciation. This is because the vowel shift brought the already established orthography out of synchronization with pronunciation. Another source of sound change is the erosion of words as pronunciation gradually becomes increasingly indistinct and shortens words, leaving out syllables or sounds. This kind of change caused Latin mea domina to eventually become the French madame and American English ma'am.

Change also happens in the grammar of languages as discourse patterns such as idioms or particular constructions become grammaticalized. This frequently happens when words or morphemes erode and the grammatical system is unconsciously rearranged to compensate for the lost element. For example, in some varieties of Caribbean Spanish the final /s/ has eroded away. Since Standard Spanish uses final /s/ in the morpheme marking the second person subject "you" in verbs, the Caribbean varieties now have to express the second person using the pronoun tú. This means that the sentence "what's your name" is ¿como te llamas? [ˈkomo te ˈjamas] in Standard Spanish, but [ˈkomo ˈtu te ˈjama] in Caribbean Spanish. The simple sound change has affected both morphology and syntax. Another common cause of grammatical change is the gradual petrification of idioms into new grammatical forms, for example, the way the English "going to" construction lost its aspect of movement and in some varieties of English has almost become a full-fledged future tense (e.g. I'm gonna).

Language change may be motivated by "language internal" factors, such as changes in pronunciation motivated by certain sounds being difficult to distinguish aurally or to produce, or through patterns of change that cause some rare types of constructions to drift towards more common types. Other causes of language change are social, such as when certain pronunciations become emblematic of membership in certain groups, such as social classes, or with ideologies, and therefore are adopted by those who wish to identify with those groups or ideas. In this way, issues of identity and politics can have profound effects on language structure.

Contact
Main article: Language contact

Multi-lingual sign outside the mayor's office in Novi Sad, written in the four official languages of the city: Serbian, Hungarian, Slovak, and Pannonian Rusyn
One important source of language change is contact and resulting diffusion of linguistic traits between languages. Language contact occurs when speakers of two or more languages or varieties interact on a regular basis. Multilingualism is likely to have been the norm throughout human history and most people in the modern world are multilingual. Before the rise of the concept of the ethno-national state, monolingualism was characteristic mainly of populations inhabiting small islands. But with the ideology that made one people, one state, and one language the most desirable political arrangement, monolingualism started to spread throughout the world. Nonetheless, there are only 250 countries in the world corresponding to some 6000 languages, which means that most countries are multilingual and most languages therefore exist in close contact with other languages.

When speakers of different languages interact closely, it is typical for their languages to influence each other. Through sustained language contact over long periods, linguistic traits diffuse between languages, and languages belonging to different families may converge to become more similar. In areas where many languages are in close contact, this may lead to the formation of language areas in which unrelated languages share a number of linguistic features. A number of such language areas have been documented, among them, the Balkan language area, the Mesoamerican language area, and the Ethiopian language area. Also, larger areas such as South Asia, Europe, and Southeast Asia have sometimes been considered language areas, because of widespread diffusion of specific areal features.


Multilingualism is also common in the Indian Republic. The signboard is displayed in the Imphal International Airport in Meitei, Hindi and English, some of the official languages of the Indian Republic.
Language contact may also lead to a variety of other linguistic phenomena, including language convergence, borrowing, and relexification (replacement of much of the native vocabulary with that of another language). In situations of extreme and sustained language contact, it may lead to the formation of new mixed languages that cannot be considered to belong to a single language family. One type of mixed language called pidgins occurs when adult speakers of two different languages interact on a regular basis, but in a situation where neither group learns to speak the language of the other group fluently. In such a case, they will often construct a communication form that has traits of both languages, but which has a simplified grammatical and phonological structure. The language comes to contain mostly the grammatical and phonological categories that exist in both languages. Pidgin languages are defined by not having any native speakers, but only being spoken by people who have another language as their first language. But if a Pidgin language becomes the main language of a speech community, then eventually children will grow up learning the pidgin as their first language. As the generation of child learners grow up, the pidgin will often be seen to change its structure and acquire a greater degree of complexity. This type of language is generally called a creole language. An example of such mixed languages is Tok Pisin, the official language of Papua New-Guinea, which originally arose as a Pidgin based on English and Austronesian languages; others are Kreyòl ayisyen, the French-based creole language spoken in Haiti, and Michif, a mixed language of Canada, based on the Native American language Cree and French.

Linguistic diversity
See also: Lists of languages and List of languages by total number of speakers
Language	Native speakers
(millions)
Mandarin	848
Spanish	329 [note 5]
English	328
Portuguese	250
Arabic	221
Hindi	182
Bengali	181
Russian	144
Japanese	122
Javanese	84.3
SIL Ethnologue defines a "living language" as "one that has at least one speaker for whom it is their first language". The exact number of known living languages varies from 6,000 to 7,000, depending on the precision of one's definition of "language", and in particular, on how one defines the distinction between a "language" and a "dialect". As of 2016, Ethnologue cataloged 7,097 living human languages. The Ethnologue establishes linguistic groups based on studies of mutual intelligibility, and therefore often includes more categories than more conservative classifications. For example, the Danish language that most scholars consider a single language with several dialects is classified as two distinct languages (Danish and Jutish) by the Ethnologue.

According to the Ethnologue, 389 languages (nearly 6%) have more than a million speakers. These languages together account for 94% of the world's population, whereas 94% of the world's languages account for the remaining 6% of the global population.

Languages and dialects
Main article: Dialect § Dialect or language
There is no clear distinction between a language and a dialect, notwithstanding a famous aphorism attributed to linguist Max Weinreich that "a language is a dialect with an army and navy". For example, national boundaries frequently override linguistic difference in determining whether two linguistic varieties are languages or dialects. Hakka, Cantonese and Mandarin are, for example, often classified as "dialects" of Chinese, even though they are more different from each other than Swedish is from Norwegian. Before the Yugoslav Wars, Serbo-Croatian was generally considered a single language with two normative variants, but due to sociopolitical reasons, Croatian and Serbian are now often treated as separate languages and employ different writing systems. In other words, the distinction may hinge on political considerations as much as on cultural differences, distinctive writing systems, or degree of mutual intelligibility.

Language families of the world
Main articles: Language family, Dialectology, Historical linguistics, and List of language families

Principal language families of the world (and in some cases geographic groups of families). For greater detail, see Distribution of languages in the world.
The world's languages can be grouped into language families consisting of languages that can be shown to have common ancestry. Linguists recognize many hundreds of language families, although some of them can possibly be grouped into larger units as more evidence becomes available and in-depth studies are carried out. At present, there are also dozens of language isolates: languages that cannot be shown to be related to any other languages in the world. Among them are Basque, spoken in Europe, Zuni of New Mexico, Purépecha of Mexico, Ainu of Japan, Burushaski of Pakistan, and many others.

The language family of the world that has the most speakers is the Indo-European languages, spoken by 46% of the world's population. This family includes major world languages like English, Spanish, French, German, Russian, and Hindustani (Hindi/Urdu). The Indo-European family achieved prevalence first during the Eurasian Migration Period (c. 400–800 AD),[citation needed] and subsequently through the European colonial expansion, which brought the Indo-European languages to a politically and often numerically dominant position in the Americas and much of Africa. The Sino-Tibetan languages are spoken by 20% of the world's population and include many of the languages of East Asia, including Hakka, Mandarin Chinese, Cantonese, and hundreds of smaller languages.

Africa is home to a large number of language families, the largest of which is the Niger-Congo language family, which includes such languages as Swahili, Shona, and Yoruba. Speakers of the Niger-Congo languages account for 6.9% of the world's population. A similar number of people speak the Afroasiatic languages, which include the populous Semitic languages such as Arabic, Hebrew language, and the languages of the Sahara region, such as the Berber languages and Hausa.

The Austronesian languages are spoken by 5.5% of the world's population and stretch from Madagascar to maritime Southeast Asia all the way to Oceania. It includes such languages as Malagasy, Māori, Samoan, and many of the indigenous languages of Indonesia and Taiwan. The Austronesian languages are considered to have originated in Taiwan around 3000 BC and spread through the Oceanic region through island-hopping, based on an advanced nautical technology. Other populous language families are the Dravidian languages of South Asia (among them Kannada, Tamil, and Telugu), the Turkic languages of Central Asia (such as Turkish), the Austroasiatic (among them Khmer), and Tai–Kadai languages of Southeast Asia (including Thai).

The areas of the world in which there is the greatest linguistic diversity, such as the Americas, Papua New Guinea, West Africa, and South-Asia, contain hundreds of small language families. These areas together account for the majority of the world's languages, though not the majority of speakers. In the Americas, some of the largest language families include the Quechumaran, Arawak, and Tupi-Guarani families of South America, the Uto-Aztecan, Oto-Manguean, and Mayan of Mesoamerica, and the Na-Dene, Iroquoian, and Algonquian language families of North America. In Australia, most indigenous languages belong to the Pama-Nyungan family, whereas New Guinea is home to a large number of small families and isolates, as well as a number of Austronesian languages. Due to its remoteness and geographical fragmentation, Papua New Guinea emerges in fact as the leading location worldwide for both species (8% of world total) and linguistic richness – with 830 living tongues (12% of world total).

Language endangerment
Main articles: Endangered language, Language loss, Language shift, and Language death

  Together, these eight countries contain more than 50% of the world's languages.
  These areas are the most linguistically diverse in the world, and the locations of most of the world's endangered languages.
Language endangerment occurs when a language is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers, and becomes a dead language. If eventually no one speaks the language at all, it becomes an extinct language. While languages have always gone extinct throughout human history, they have been disappearing at an accelerated rate in the 20th and 21st centuries due to the processes of globalization and neo-colonialism, where the economically powerful languages dominate other languages.

The more commonly spoken languages dominate the less commonly spoken languages, so the less commonly spoken languages eventually disappear from populations. Of the between 6,000 and 7,000 languages spoken as of 2010, between 50 and 90% of those are expected to have become extinct by the year 2100. The top 20 languages, those spoken by more than 50 million speakers each, are spoken by 50% of the world's population, whereas many of the other languages are spoken by small communities, most of them with less than 10,000 speakers.


UNESCO's five levels of language endangerment
The United Nations Educational, Scientific and Cultural Organization (UNESCO) operates with five levels of language endangerment: "safe", "vulnerable" (not spoken by children outside the home), "definitely endangered" (not spoken by children), "severely endangered" (only spoken by the oldest generations), and "critically endangered" (spoken by few members of the oldest generation, often semi-speakers). Notwithstanding claims that the world would be better off if most adopted a single common lingua franca, such as English or Esperanto, there is a consensus that the loss of languages harms the cultural diversity of the world. It is a common belief, going back to the biblical narrative of the tower of Babel in the Old Testament, that linguistic diversity causes political conflict, but this is contradicted by the fact that many of the world's major episodes of violence have taken place in situations with low linguistic diversity, such as the Yugoslav and American Civil War, or the genocide of Rwanda, whereas many of the most stable political units have been highly multilingual.

Many projects aim to prevent or slow this loss by revitalizing endangered languages and promoting education and literacy in minority languages. Across the world, many countries have enacted specific legislation to protect and stabilize the language of indigenous speech communities. A minority of linguists have argued that language loss is a natural process that should not be counteracted, and that documenting endangered languages for posterity is sufficient.

The University of Waikato are using the Welsh language as a model for their Māori language revitalisation programme as they deem Welsh to be the world's leading example for the survival of languages. In 2019 a Hawaiian TV company Oiwi visited a Welsh language centre in Nant Gwrtheyrn, North Wales to help find ways of preserving their Ōlelo Hawaiʻi language.

Art is a diverse range of human activity, and resulting product, that involves creative or imaginative talent expressive of technical proficiency, beauty, emotional power, or conceptual ideas.

There is no generally agreed definition of what constitutes art, and its interpretation has varied greatly throughout history and across cultures. In the Western tradition, the three classical branches of visual art are painting, sculpture, and architecture. Theatre, dance, and other performing arts, as well as literature, music, film and other media such as interactive media, are included in a broader definition of the arts. Until the 17th century, art referred to any skill or mastery and was not differentiated from crafts or sciences. In modern usage after the 17th century, where aesthetic considerations are paramount, the fine arts are separated and distinguished from acquired skills in general, such as the decorative or applied arts.

The nature of art and related concepts, such as creativity and interpretation, are explored in a branch of philosophy known as aesthetics. The resulting artworks are studied in the professional fields of art criticism and the history of art.

In the perspective of the history of art, artistic works have existed for almost as long as humankind: from early prehistoric art to contemporary art; however, some theorists think that the typical concept of "artistic works" does not fit well outside modern Western societies. One early sense of the definition of art is closely related to the older Latin meaning, which roughly translates to "skill" or "craft", as associated with words such as "artisan". English words derived from this meaning include artifact, artificial, artifice, medical arts, and military arts. However, there are many other colloquial uses of the word, all with some relation to its etymology.


20th-century bottle, Twa peoples, Rwanda. Artistic works may serve practical functions, in addition to their decorative value.
Over time, philosophers like Plato, Aristotle, Socrates and Immanuel Kant, among others, questioned the meaning of art. Several dialogues in Plato tackle questions about art: Socrates says that poetry is inspired by the muses, and is not rational. He speaks approvingly of this, and other forms of divine madness (drunkenness, eroticism, and dreaming) in the Phaedrus (265a–c), and yet in the Republic wants to outlaw Homer's great poetic art, and laughter as well. In Ion, Socrates gives no hint of the disapproval of Homer that he expresses in the Republic. The dialogue Ion suggests that Homer's Iliad functioned in the ancient Greek world as the Bible does today in the modern Christian world: as divinely inspired literary art that can provide moral guidance, if only it can be properly interpreted.

With regards to the literary art and the musical arts, Aristotle considered epic poetry, tragedy, comedy, Dithyrambic poetry and music to be mimetic or imitative art, each varying in imitation by medium, object, and manner. For example, music imitates with the media of rhythm and harmony, whereas dance imitates with rhythm alone, and poetry with language. The forms also differ in their object of imitation. Comedy, for instance, is a dramatic imitation of men worse than average; whereas tragedy imitates men slightly better than average. Lastly, the forms differ in their manner of imitation—through narrative or character, through change or no change, and through drama or no drama. Aristotle believed that imitation is natural to mankind and constitutes one of mankind's advantages over animals.

The more recent and specific sense of the word art as an abbreviation for creative art or fine art emerged in the early 17th century. Fine art refers to a skill used to express the artist's creativity, or to engage the audience's aesthetic sensibilities, or to draw the audience towards consideration of more refined or finer works of art.

Within this latter sense, the word art may refer to several things: (i) a study of a creative skill, (ii) a process of using the creative skill, (iii) a product of the creative skill, or (iv) the audience's experience with the creative skill. The creative arts (art as discipline) are a collection of disciplines which produce artworks (art as objects) that are compelled by a personal drive (art as activity) and convey a message, mood, or symbolism for the perceiver to interpret (art as experience). Art is something that stimulates an individual's thoughts, emotions, beliefs, or ideas through the senses. Works of art can be explicitly made for this purpose or interpreted on the basis of images or objects. For some scholars, such as Kant, the sciences and the arts could be distinguished by taking science as representing the domain of knowledge and the arts as representing the domain of the freedom of artistic expression.


Back of a Renaissance oval basin or dish, in the Metropolitan Museum of Art
Often, if the skill is being used in a common or practical way, people will consider it a craft instead of art. Likewise, if the skill is being used in a commercial or industrial way, it may be considered commercial art instead of fine art. On the other hand, crafts and design are sometimes considered applied art. Some art followers have argued that the difference between fine art and applied art has more to do with value judgments made about the art than any clear definitional difference. However, even fine art often has goals beyond pure creativity and self-expression. The purpose of works of art may be to communicate ideas, such as in politically, spiritually, or philosophically motivated art; to create a sense of beauty (see aesthetics); to explore the nature of perception; for pleasure; or to generate strong emotions. The purpose may also be seemingly nonexistent.

The nature of art has been described by philosopher Richard Wollheim as "one of the most elusive of the traditional problems of human culture". Art has been defined as a vehicle for the expression or communication of emotions and ideas, a means for exploring and appreciating formal elements for their own sake, and as mimesis or representation. Art as mimesis has deep roots in the philosophy of Aristotle. Leo Tolstoy identified art as a use of indirect means to communicate from one person to another. Benedetto Croce and R. G. Collingwood advanced the idealist view that art expresses emotions, and that the work of art therefore essentially exists in the mind of the creator. The theory of art as form has its roots in the philosophy of Kant, and was developed in the early 20th century by Roger Fry and Clive Bell. More recently, thinkers influenced by Martin Heidegger have interpreted art as the means by which a community develops for itself a medium for self-expression and interpretation. George Dickie has offered an institutional theory of art that defines a work of art as any artifact upon which a qualified person or persons acting on behalf of the social institution commonly referred to as "the art world" has conferred "the status of candidate for appreciation". Larry Shiner has described fine art as "not an essence or a fate but something we have made. Art as we have generally understood it is a European invention barely two hundred years old."

Art may be characterized in terms of mimesis (its representation of reality), narrative (storytelling), expression, communication of emotion, or other qualities. During the Romantic period, art came to be seen as "a special faculty of the human mind to be classified with religion and science".

History
Main article: History of art

Löwenmensch figurine, between 35,000 and 41,000 years old. One of the oldest-known examples of an artistic representation and the oldest confirmed statue ever discovered.
A shell engraved by Homo erectus was determined to be between 430,000 and 540,000 years old. A set of eight 130,000 years old white-tailed eagle talons bear cut marks and abrasion that indicate manipulation by neanderthals, possibly for using it as jewelry. A series of tiny, drilled snail shells about 75,000 years old—were discovered in a South African cave. Containers that may have been used to hold paints have been found dating as far back as 100,000 years.

The oldest piece of art found in Europe is the Riesenhirschknochen der Einhornhöhle, dating back 51,000 years and made by Neanderthals.

Sculptures, cave paintings, rock paintings and petroglyphs from the Upper Paleolithic dating to roughly 40,000 years ago have been found, but the precise meaning of such art is often disputed because so little is known about the cultures that produced them.

The first undisputed sculptures and similar art pieces, like the Venus of Hohle Fels, are the numerous objects found at the Caves and Ice Age Art in the Swabian Jura UNESCO World Heritage Site, where the oldest non-stationary works of human art yet discovered were found, in the form of carved animal and humanoid figurines, in addition to the oldest musical instruments unearthed so far, with the artifacts dating between 43.000 and 35.000 BC, so being the first centre of human art.


Cave painting of a horse from the Lascaux caves, c. 16,000 BP
Many great traditions in art have a foundation in the art of one of the great ancient civilizations: Ancient Egypt, Mesopotamia, Persia, India, China, Ancient Greece, Rome, as well as Inca, Maya, and Olmec. Each of these centers of early civilization developed a unique and characteristic style in its art. Because of the size and duration of these civilizations, more of their art works have survived and more of their influence has been transmitted to other cultures and later times. Some also have provided the first records of how artists worked. For example, this period of Greek art saw a veneration of the human physical form and the development of equivalent skills to show musculature, poise, beauty, and anatomically correct proportions.

In Byzantine and Medieval art of the Western Middle Ages, much art focused on the expression of subjects about biblical and religious culture, and used styles that showed the higher glory of a heavenly world, such as the use of gold in the background of paintings, or glass in mosaics or windows, which also presented figures in idealized, patterned (flat) forms. Nevertheless, a classical realist tradition persisted in small Byzantine works, and realism steadily grew in the art of Catholic Europe.

Renaissance art had a greatly increased emphasis on the realistic depiction of the material world, and the place of humans in it, reflected in the corporeality of the human body, and development of a systematic method of graphical perspective to depict recession in a three-dimensional picture space.


The stylized signature of Sultan Mahmud II of the Ottoman Empire was written in Islamic calligraphy. It reads "Mahmud Khan son of Abdulhamid is forever victorious".

The Great Mosque of Kairouan in Tunisia, also called the Mosque of Uqba, is one of the finest, most significant and best preserved artistic and architectural examples of early great mosques. Dated in its present state from the 9th century, it is the ancestor and model of all the mosques in the western Islamic lands.
In the east, Islamic art's rejection of iconography led to emphasis on geometric patterns, calligraphy, and architecture. Further east, religion dominated artistic styles and forms too. India and Tibet saw emphasis on painted sculptures and dance, while religious painting borrowed many conventions from sculpture and tended to bright contrasting colors with emphasis on outlines. China saw the flourishing of many art forms: jade carving, bronzework, pottery (including the stunning terracotta army of Emperor Qin), poetry, calligraphy, music, painting, drama, fiction, etc. Chinese styles vary greatly from era to era and each one is traditionally named after the ruling dynasty. So, for example, Tang dynasty paintings are monochromatic and sparse, emphasizing idealized landscapes, but Ming dynasty paintings are busy and colorful, and focus on telling stories via setting and composition. Japan names its styles after imperial dynasties too, and also saw much interplay between the styles of calligraphy and painting. Woodblock printing became important in Japan after the 17th century.


Chinese painting by Song dynasty artist Ma Lin, c. 1250. 24.8 × 25.2 cm
The western Age of Enlightenment in the 18th century saw artistic depictions of physical and rational certainties of the clockwork universe, as well as politically revolutionary visions of a post-monarchist world, such as Blake's portrayal of Newton as a divine geometer, or David's propagandistic paintings. This led to Romantic rejections of this in favor of pictures of the emotional side and individuality of humans, exemplified in the novels of Goethe. The late 19th century then saw a host of artistic movements, such as academic art, Symbolism, impressionism and fauvism among others.

The history of 20th-century art is a narrative of endless possibilities and the search for new standards, each being torn down in succession by the next. Thus the parameters of Impressionism, Expressionism, Fauvism, Cubism, Dadaism, Surrealism, etc. cannot be maintained very much beyond the time of their invention. Increasing global interaction during this time saw an equivalent influence of other cultures into Western art. Thus, Japanese woodblock prints (themselves influenced by Western Renaissance draftsmanship) had an immense influence on impressionism and subsequent development. Later, African sculptures were taken up by Picasso and to some extent by Matisse. Similarly, in the 19th and 20th centuries the West has had huge impacts on Eastern art with originally western ideas like Communism and Post-Modernism exerting a powerful influence.

Modernism, the idealistic search for truth, gave way in the latter half of the 20th century to a realization of its unattainability. Theodor W. Adorno said in 1970, "It is now taken for granted that nothing which concerns art can be taken for granted any more: neither art itself, nor art in relationship to the whole, nor even the right of art to exist." Relativism was accepted as an unavoidable truth, which led to the period of contemporary art and postmodern criticism, where cultures of the world and of history are seen as changing forms, which can be appreciated and drawn from only with skepticism and irony. Furthermore, the separation of cultures is increasingly blurred and some argue it is now more appropriate to think in terms of a global culture, rather than of regional ones.

In The Origin of the Work of Art, Martin Heidegger, a German philosopher and a seminal thinker, describes the essence of art in terms of the concepts of being and truth. He argues that art is not only a way of expressing the element of truth in a culture, but the means of creating it and providing a springboard from which "that which is" can be revealed. Works of art are not merely representations of the way things are, but actually produce a community's shared understanding. Each time a new artwork is added to any culture, the meaning of what it is to exist is inherently changed.

Historically, art and artistic skills and ideas have often been spread through trade. An example of this is the Silk Road, where Hellenistic, Iranian, Indian and Chinese influences could mix. Greco Buddhist art is one of the most vivid examples of this interaction. The meeting of different cultures and worldviews also influenced artistic creation. An example of this is the multicultural port metropolis of Trieste at the beginning of the 20th century, where James Joyce met writers from Central Europe and the artistic development of New York City as a cultural melting pot.

Forms, genres, media, and styles

Napoleon I on his Imperial Throne by Ingres (French, 1806), oil on canvas
Main article: The arts
The creative arts are often divided into more specific categories, typically along perceptually distinguishable categories such as media, genre, styles, and form. Art form refers to the elements of art that are independent of its interpretation or significance. It covers the methods adopted by the artist and the physical composition of the artwork, primarily non-semantic aspects of the work (i.e., figurae), such as color, contour, dimension, medium, melody, space, texture, and value. Form may also include visual design principles, such as arrangement, balance, contrast, emphasis, harmony, proportion, proximity, and rhythm.

In general there are three schools of philosophy regarding art, focusing respectively on form, content, and context. Extreme Formalism is the view that all aesthetic properties of art are formal (that is, part of the art form). Philosophers almost universally reject this view and hold that the properties and aesthetics of art extend beyond materials, techniques, and form. Unfortunately, there is little consensus on terminology for these informal properties. Some authors refer to subject matter and content—i.e., denotations and connotations—while others prefer terms like meaning and significance.

Extreme Intentionalism holds that authorial intent plays a decisive role in the meaning of a work of art, conveying the content or essential main idea, while all other interpretations can be discarded. It defines the subject as the persons or idea represented, and the content as the artist's experience of that subject. For example, the composition of Napoleon I on his Imperial Throne is partly borrowed from the Statue of Zeus at Olympia. As evidenced by the title, the subject is Napoleon, and the content is Ingres's representation of Napoleon as "Emperor-God beyond time and space". Similarly to extreme formalism, philosophers typically reject extreme intentionalism, because art may have multiple ambiguous meanings and authorial intent may be unknowable and thus irrelevant. Its restrictive interpretation is "socially unhealthy, philosophically unreal, and politically unwise".

Finally, the developing theory of post-structuralism studies art's significance in a cultural context, such as the ideas, emotions, and reactions prompted by a work. The cultural context often reduces to the artist's techniques and intentions, in which case analysis proceeds along lines similar to formalism and intentionalism. However, in other cases historical and material conditions may predominate, such as religious and philosophical convictions, sociopolitical and economic structures, or even climate and geography. Art criticism continues to grow and develop alongside art.

Skill and craft
See also: Conceptual art and artistic skill

The Creation of Adam, detail from Michelangelo's fresco in the Sistine Chapel (1511)
Art can connote a sense of trained ability or mastery of a medium. Art can also refer to the developed and efficient use of a language to convey meaning with immediacy or depth. Art can be defined as an act of expressing feelings, thoughts, and observations.

There is an understanding that is reached with the material as a result of handling it, which facilitates one's thought processes. A common view is that the epithet art, particular in its elevated sense, requires a certain level of creative expertise by the artist, whether this be a demonstration of technical ability, an originality in stylistic approach, or a combination of these two. Traditionally skill of execution was viewed as a quality inseparable from art and thus necessary for its success; for Leonardo da Vinci, art, neither more nor less than his other endeavors, was a manifestation of skill. Rembrandt's work, now praised for its ephemeral virtues, was most admired by his contemporaries for its virtuosity. At the turn of the 20th century, the adroit performances of John Singer Sargent were alternately admired and viewed with skepticism for their manual fluency, yet at nearly the same time the artist who would become the era's most recognized and peripatetic iconoclast, Pablo Picasso, was completing a traditional academic training at which he excelled.


Detail of Leonardo da Vinci's Mona Lisa, c. 1503–1506, showing the painting technique of sfumato
A common contemporary criticism of some modern art occurs along the lines of objecting to the apparent lack of skill or ability required in the production of the artistic object. In conceptual art, Marcel Duchamp's Fountain is among the first examples of pieces wherein the artist used found objects ("ready-made") and exercised no traditionally recognised set of skills. Tracey Emin's My Bed, or Damien Hirst's The Physical Impossibility of Death in the Mind of Someone Living follow this example and also manipulate the mass media. Emin slept (and engaged in other activities) in her bed before placing the result in a gallery as work of art. Hirst came up with the conceptual design for the artwork but has left most of the eventual creation of many works to employed artisans. Hirst's celebrity is founded entirely on his ability to produce shocking concepts. The actual production in many conceptual and contemporary works of art is a matter of assembly of found objects. However, there are many modernist and contemporary artists who continue to excel in the skills of drawing and painting and in creating hands-on works of art.

Purpose

A Navajo rug made c. 1880

Mozarabic Beatus miniature. Spain, late 10th century
Art has had a great number of different functions throughout its history, making its purpose difficult to abstract or quantify to any single concept. This does not imply that the purpose of art is "vague", but that it has had many unique, different reasons for being created. Some of these functions of art are provided in the following outline. The different purposes of art may be grouped according to those that are non-motivated, and those that are motivated (Lévi-Strauss).

Non-motivated functions
The non-motivated purposes of art are those that are integral to being human, transcend the individual, or do not fulfill a specific external purpose. In this sense, Art, as creativity, is something humans must do by their very nature (i.e., no other species creates art), and is therefore beyond utility.

Basic human instinct for harmony, balance, rhythm. Art at this level is not an action or an object, but an internal appreciation of balance and harmony (beauty), and therefore an aspect of being human beyond utility.
Imitation, then, is one instinct of our nature. Next, there is the instinct for 'harmony' and rhythm, meters being manifestly sections of rhythm. Persons, therefore, starting with this natural gift developed by degrees their special aptitudes, till their rude improvisations gave birth to Poetry. – Aristotle

Experience of the mysterious. Art provides a way to experience one's self in relation to the universe. This experience may often come unmotivated, as one appreciates art, music or poetry.
The most beautiful thing we can experience is the mysterious. It is the source of all true art and science. – Albert Einstein

Expression of the imagination. Art provides a means to express the imagination in non-grammatic ways that are not tied to the formality of spoken or written language. Unlike words, which come in sequences and each of which have a definite meaning, art provides a range of forms, symbols and ideas with meanings that are malleable.
Jupiter's eagle [as an example of art] is not, like logical (aesthetic) attributes of an object, the concept of the sublimity and majesty of creation, but rather something else—something that gives the imagination an incentive to spread its flight over a whole host of kindred representations that provoke more thought than admits of expression in a concept determined by words. They furnish an aesthetic idea, which serves the above rational idea as a substitute for logical presentation, but with the proper function, however, of animating the mind by opening out for it a prospect into a field of kindred representations stretching beyond its ken. – Immanuel Kant

Ritualistic and symbolic functions. In many cultures, art is used in rituals, performances and dances as a decoration or symbol. While these often have no specific utilitarian (motivated) purpose, anthropologists know that they often serve a purpose at the level of meaning within a particular culture. This meaning is not furnished by any one individual, but is often the result of many generations of change, and of a cosmological relationship within the culture.
Most scholars who deal with rock paintings or objects recovered from prehistoric contexts that cannot be explained in utilitarian terms and are thus categorized as decorative, ritual or symbolic, are aware of the trap posed by the term 'art'. – Silva Tomaskova

Motivated functions
Motivated purposes of art refer to intentional, conscious actions on the part of the artists or creator. These may be to bring about political change, to comment on an aspect of society, to convey a specific emotion or mood, to address personal psychology, to illustrate another discipline, to (with commercial arts) sell a product, or used as a form of communication.

Communication. Art, at its simplest, is a form of communication. As most forms of communication have an intent or goal directed toward another individual, this is a motivated purpose. Illustrative arts, such as scientific illustration, are a form of art as communication. Maps are another example. However, the content need not be scientific. Emotions, moods and feelings are also communicated through art.
[Art is a set of] artefacts or images with symbolic meanings as a means of communication. – Steve Mithen

Art as entertainment. Art may seek to bring about a particular emotion or mood, for the purpose of relaxing or entertaining the viewer. This is often the function of the art industries of motion pictures and video games.
The Avant-Garde. Art for political change. One of the defining functions of early 20th-century art has been to use visual images to bring about political change. Art movements that had this goal—Dadaism, Surrealism, Russian constructivism, and Abstract Expressionism, among others—are collectively referred to as the avant-garde arts.
By contrast, the realistic attitude, inspired by positivism, from Saint Thomas Aquinas to Anatole France, clearly seems to me to be hostile to any intellectual or moral advancement. I loathe it, for it is made up of mediocrity, hate, and dull conceit. It is this attitude which today gives birth to these ridiculous books, these insulting plays. It constantly feeds on and derives strength from the newspapers and stultifies both science and art by assiduously flattering the lowest of tastes; clarity bordering on stupidity, a dog's life. – André Breton (Surrealism)

Art as a "free zone", removed from the action of the social censure. Unlike the avant-garde movements, which wanted to erase cultural differences in order to produce new universal values, contemporary art has enhanced its tolerance towards cultural differences as well as its critical and liberating functions (social inquiry, activism, subversion, deconstruction, etc.), becoming a more open place for research and experimentation.
Art for social inquiry, subversion or anarchy. While similar to art for political change, subversive or deconstructivist art may seek to question aspects of society without any specific political goal. In this case, the function of art may be used to criticize some aspect of society.

Spray-paint graffiti on a wall in Rome
Graffiti art and other types of street art are graphics and images that are spray-painted or stencilled on publicly viewable walls, buildings, buses, trains, and bridges, usually without permission. Certain art forms, such as graffiti, may also be illegal when they break laws (in this case vandalism).
Art for social causes. Art can be used to raise awareness for a large variety of causes. A number of art activities were aimed at raising awareness of autism, cancer, human trafficking, and a variety of other topics, such as ocean conservation, human rights in Darfur, murdered and missing Aboriginal women, elder abuse, and pollution. Trashion, using trash to make fashion, practiced by artists such as Marina DeBris is one example of using art to raise awareness about pollution.
Art for psychological and healing purposes. Art is also used by art therapists, psychotherapists and clinical psychologists as art therapy. The Diagnostic Drawing Series, for example, is used to determine the personality and emotional functioning of a patient. The end product is not the principal goal in this case, but rather a process of healing, through creative acts, is sought. The resultant piece of artwork may also offer insight into the troubles experienced by the subject and may suggest suitable approaches to be used in more conventional forms of psychiatric therapy.
Art for propaganda, or commercialism. Art is often used as a form of propaganda, and thus can be used to subtly influence popular conceptions or mood. In a similar way, art that tries to sell a product also influences mood and emotion. In both cases, the purpose of art here is to subtly manipulate the viewer into a particular emotional or psychological response toward a particular idea or object.
Art as a fitness indicator. It has been argued that the ability of the human brain by far exceeds what was needed for survival in the ancestral environment. One evolutionary psychology explanation for this is that the human brain and associated traits (such as artistic ability and creativity) are the human equivalent of the peacock's tail. The purpose of the male peacock's extravagant tail has been argued to be to attract females (see also Fisherian runaway and handicap principle). According to this theory superior execution of art was evolutionarily important because it attracted mates.
The functions of art described above are not mutually exclusive, as many of them may overlap. For example, art for the purpose of entertainment may also seek to sell a product, i.e. the movie or video game.

Steps
Art can be divided into any number of steps one can make an argument for. This section divides the creative process into broad three steps, but there is no consensus on an exact number.

Preparation

The Thinker in The Gates of Hell at the Musée Rodin
In the first step, the artist envisions the art in their mind. By imagining what their art would look like, the artist begins the process of bringing the art into existence. Preparation of art may involve approaching and researching the subject matter. Artistic inspiration is one of the main drivers of art, and may be considered to stem from instinct, impressions, and feelings.

Creation

The Great Wave off Kanagawa, the first in Hokusai's series Thirty-six Views of Mount Fuji
In the second step, the artist executes the creation of their work. The creation of a piece can be affected by factors such as the artist's mood, surroundings, and mental state. For example, The Black Paintings by Francisco de Goya, created in the elder years of his life, are thought to be so bleak because he was in isolation and because of his experience with war. He painted them directly on the walls of his apartment in Spain, and most likely never discussed them with anyone. The Beatles stated drugs such as LSD and cannabis influenced some of their greatest hits, such as Revolver. Trial and error are considered an integral part of the creation process.

Appreciation
The last step is art appreciation, which has the sub-topic of critique. In one study, over half of visual arts student agreed that reflection is an essential step of the art process. According to education journals, the reflection of art is considered an essential part of the experience. However an important aspect of art is that others may view and appreciate it as well. While many focus on whether those viewing/listening/etc. believe the art to be good/successful or not, art has profound value beyond its commercial success as a provider of information and health in society. Art enjoyment can bring about a wide spectrum of emotion due to beauty. Some art is meant to be practical, with its analysis studious, meant to stimulate discourse.

Public access

The Metropolitan Museum of Art in Manhattan. Museums are important forums for the display of visual art.
Since ancient times, much of the finest art has represented a deliberate display of wealth or power, often achieved by using massive scale and expensive materials. Much art has been commissioned by political rulers or religious establishments, with more modest versions only available to the most wealthy in society.

Nevertheless, there have been many periods where art of very high quality was available, in terms of ownership, across large parts of society, above all in cheap media such as pottery, which persists in the ground, and perishable media such as textiles and wood. In many different cultures, the ceramics of indigenous peoples of the Americas are found in such a wide range of graves that they were clearly not restricted to a social elite, though other forms of art may have been. Reproductive methods such as moulds made mass-production easier, and were used to bring high-quality Ancient Roman pottery and Greek Tanagra figurines to a very wide market. Cylinder seals were both artistic and practical, and very widely used by what can be loosely called the middle class in the Ancient Near East. Once coins were widely used, these also became an art form that reached the widest range of society.

Another important innovation came in the 15th century in Europe, when printmaking began with small woodcuts, mostly religious, that were often very small and hand-colored, and affordable even by peasants who glued them to the walls of their homes. Printed books were initially very expensive, but fell steadily in price until by the 19th century even the poorest could afford some with printed illustrations. Popular prints of many different sorts have decorated homes and other places for centuries.


Kunstmuseum Basel, the Museum of Art in Basel, Switzerland, is the oldest public museum of art in the world.
In 1661, the city of Basel, in Switzerland, opened the first public museum of art in the world, the Kunstmuseum Basel. Today, its collection is distinguished by an impressively wide historic span, from the early 15th century up to the immediate present. Its various areas of emphasis give it international standing as one of the most significant museums of its kind. These encompass: paintings and drawings by artists active in the Upper Rhine region between 1400 and 1600, and on the art of the 19th to 21st centuries.

Public buildings and monuments, secular and religious, by their nature normally address the whole of society, and visitors as viewers, and display to the general public has long been an important factor in their design. Egyptian temples are typical in that the most largest and most lavish decoration was placed on the parts that could be seen by the general public, rather than the areas seen only by the priests. Many areas of royal palaces, castles and the houses of the social elite were often generally accessible, and large parts of the art collections of such people could often be seen, either by anybody, or by those able to pay a small price, or those wearing the correct clothes, regardless of who they were, as at the Palace of Versailles, where the appropriate extra accessories (silver shoe buckles and a sword) could be hired from shops outside.

Special arrangements were made to allow the public to see many royal or private collections placed in galleries, as with the Orleans Collection mostly housed in a wing of the Palais Royal in Paris, which could be visited for most of the 18th century. In Italy the art tourism of the Grand Tour became a major industry from the Renaissance onwards, and governments and cities made efforts to make their key works accessible. The British Royal Collection remains distinct, but large donations such as the Old Royal Library were made from it to the British Museum, established in 1753. The Uffizi in Florence opened entirely as a gallery in 1765, though this function had been gradually taking the building over from the original civil servants' offices for a long time before. The building now occupied by the Prado in Madrid was built before the French Revolution for the public display of parts of the royal art collection, and similar royal galleries open to the public existed in Vienna, Munich and other capitals. The opening of the Musée du Louvre during the French Revolution (in 1793) as a public museum for much of the former French royal collection certainly marked an important stage in the development of public access to art, transferring ownership to a republican state, but was a continuation of trends already well established.

Most modern public museums and art education programs for children in schools can be traced back to this impulse to have art available to everyone. However, museums do not only provide availability to art, but do also influence the way art is being perceived by the audience, as studies found. Thus, the museum itself is not only a blunt stage for the presentation of art, but plays an active and vital role in the overall perception of art in modern society.

Museums in the United States tend to be gifts from the very rich to the masses. (The Metropolitan Museum of Art in New York City, for example, was created by John Taylor Johnston, a railroad executive whose personal art collection seeded the museum.) But despite all this, at least one of the important functions of art in the 21st century remains as a marker of wealth and social status.

There have been attempts by artists to create art that can not be bought by the wealthy as a status object. One of the prime original motivators of much of the art of the late 1960s and 1970s was to create art that could not be bought and sold. It is "necessary to present something more than mere objects" said the major post war German artist Joseph Beuys. This time period saw the rise of such things as performance art, video art, and conceptual art. The idea was that if the artwork was a performance that would leave nothing behind, or was an idea, it could not be bought and sold. "Democratic precepts revolving around the idea that a work of art is a commodity impelled the aesthetic innovation which germinated in the mid-1960s and was reaped throughout the 1970s. Artists broadly identified under the heading of Conceptual art ... substituting performance and publishing activities for engagement with both the material and materialistic concerns of painted or sculptural form ... [have] endeavored to undermine the art object qua object."


Versailles: Louis Le Vau opened up the interior court to create the expansive entrance cour d'honneur, later copied all over Europe.
In the decades since, these ideas have been somewhat lost as the art market has learned to sell limited edition DVDs of video works, invitations to exclusive performance art pieces, and the objects left over from conceptual pieces. Many of these performances create works that are only understood by the elite who have been educated as to why an idea or video or piece of apparent garbage may be considered art. The marker of status becomes understanding the work instead of necessarily owning it, and the artwork remains an upper-class activity. "With the widespread use of DVD recording technology in the early 2000s, artists, and the gallery system that derives its profits from the sale of artworks, gained an important means of controlling the sale of video and computer artworks in limited editions to collectors."

Controversies

Théodore Géricault's Raft of the Medusa, c. 1820
Art has long been controversial, that is to say disliked by some viewers, for a wide variety of reasons, though most pre-modern controversies are dimly recorded, or completely lost to a modern view. Iconoclasm is the destruction of art that is disliked for a variety of reasons, including religious ones. Aniconism is a general dislike of either all figurative images, or often just religious ones, and has been a thread in many major religions. It has been a crucial factor in the history of Islamic art, where depictions of Muhammad remain especially controversial. Much art has been disliked purely because it depicted or otherwise stood for unpopular rulers, parties or other groups. Artistic conventions have often been conservative and taken very seriously by art critics, though often much less so by a wider public. The iconographic content of art could cause controversy, as with late medieval depictions of the new motif of the Swoon of the Virgin in scenes of the Crucifixion of Jesus. The Last Judgment by Michelangelo was controversial for various reasons, including breaches of decorum through nudity and the Apollo-like pose of Christ.

The content of much formal art through history was dictated by the patron or commissioner rather than just the artist, but with the advent of Romanticism, and economic changes in the production of art, the artists' vision became the usual determinant of the content of his art, increasing the incidence of controversies, though often reducing their significance. Strong incentives for perceived originality and publicity also encouraged artists to court controversy. Théodore Géricault's Raft of the Medusa (c. 1820), was in part a political commentary on a recent event. Édouard Manet's Le Déjeuner sur l'Herbe (1863), was considered scandalous not because of the nude woman, but because she is seated next to men fully dressed in the clothing of the time, rather than in robes of the antique world. John Singer Sargent's Madame Pierre Gautreau (Madam X) (1884), caused a controversy over the reddish pink used to color the woman's ear lobe, considered far too suggestive and supposedly ruining the high-society model's reputation. The gradual abandonment of naturalism and the depiction of realistic representations of the visual appearance of subjects in the 19th and 20th centuries led to a rolling controversy lasting for over a century.


Performance by Joseph Beuys, 1978: Everyone an artist – On the way to the libertarian form of the social organism
In the 20th century, Pablo Picasso's Guernica (1937) used arresting cubist techniques and stark monochromatic oils, to depict the harrowing consequences of a contemporary bombing of a small, ancient Basque town. Leon Golub's Interrogation III (1981), depicts a female nude, hooded detainee strapped to a chair, her legs open to reveal her sexual organs, surrounded by two tormentors dressed in everyday clothing. Andres Serrano's Piss Christ (1989) is a photograph of a crucifix, sacred to the Christian religion and representing Christ's sacrifice and final suffering, submerged in a glass of the artist's own urine. The resulting uproar led to comments in the United States Senate about public funding of the arts.

Theory
Main article: Aesthetics
Before Modernism, aesthetics in Western art was greatly concerned with achieving the appropriate balance between different aspects of realism or truth to nature and the ideal; ideas as to what the appropriate balance is have shifted to and fro over the centuries. This concern is largely absent in other traditions of art. The aesthetic theorist John Ruskin, who championed what he saw as the naturalism of J. M. W. Turner, saw art's role as the communication by artifice of an essential truth that could only be found in nature.

The definition and evaluation of art has become especially problematic since the 20th century. Richard Wollheim distinguishes three approaches to assessing the aesthetic value of art: the Realist, whereby aesthetic quality is an absolute value independent of any human view; the Objectivist, whereby it is also an absolute value, but is dependent on general human experience; and the Relativist position, whereby it is not an absolute value, but depends on, and varies with, the human experience of different humans.

Arrival of Modernism

Composition with Red Blue and Yellow (1930) by Piet Mondrian (Dutch, 1872–1944)
The arrival of Modernism in the late 19th century lead to a radical break in the conception of the function of art, and then again in the late 20th century with the advent of postmodernism. Clement Greenberg's 1960 article "Modernist Painting" defines modern art as "the use of characteristic methods of a discipline to criticize the discipline itself". Greenberg originally applied this idea to the Abstract Expressionist movement and used it as a way to understand and justify flat (non-illusionistic) abstract painting:

Realistic, naturalistic art had dissembled the medium, using art to conceal art; modernism used art to call attention to art. The limitations that constitute the medium of painting—the flat surface, the shape of the support, the properties of the pigment—were treated by the Old Masters as negative factors that could be acknowledged only implicitly or indirectly. Under Modernism these same limitations came to be regarded as positive factors, and were acknowledged openly.

After Greenberg, several important art theorists emerged, such as Michael Fried, T. J. Clark, Rosalind Krauss, Linda Nochlin and Griselda Pollock among others. Though only originally intended as a way of understanding a specific set of artists, Greenberg's definition of modern art is important to many of the ideas of art within the various art movements of the 20th century and early 21st century.

Pop artists like Andy Warhol became both noteworthy and influential through work including and possibly critiquing popular culture, as well as the art world. Artists of the 1980s, 1990s, and 2000s expanded this technique of self-criticism beyond high art to all cultural image-making, including fashion images, comics, billboards and pornography.

Duchamp once proposed that art is any activity of any kind-everything. However, the way that only certain activities are classified today as art is a social construction. There is evidence that there may be an element of truth to this. In The Invention of Art: A Cultural History, Larry Shiner examines the construction of the modern system of the arts, i.e. fine art. He finds evidence that the older system of the arts before our modern system (fine art) held art to be any skilled human activity; for example, Ancient Greek society did not possess the term art, but techne. Techne can be understood neither as art or craft, the reason being that the distinctions of art and craft are historical products that came later on in human history. Techne included painting, sculpting and music, but also cooking, medicine, horsemanship, geometry, carpentry, prophecy, and farming, etc.

New Criticism and the "intentional fallacy"
Following Duchamp during the first half of the 20th century, a significant shift to general aesthetic theory took place which attempted to apply aesthetic theory between various forms of art, including the literary arts and the visual arts, to each other. This resulted in the rise of the New Criticism school and debate concerning the intentional fallacy. At issue was the question of whether the aesthetic intentions of the artist in creating the work of art, whatever its specific form, should be associated with the criticism and evaluation of the final product of the work of art, or, if the work of art should be evaluated on its own merits independent of the intentions of the artist.

In 1946, William K. Wimsatt and Monroe Beardsley published a classic and controversial New Critical essay entitled "The Intentional Fallacy", in which they argued strongly against the relevance of an author's intention, or "intended meaning" in the analysis of a literary work. For Wimsatt and Beardsley, the words on the page were all that mattered; importation of meanings from outside the text was considered irrelevant, and potentially distracting.

In another essay, "The Affective Fallacy", which served as a kind of sister essay to "The Intentional Fallacy" Wimsatt and Beardsley also discounted the reader's personal/emotional reaction to a literary work as a valid means of analyzing a text. This fallacy would later be repudiated by theorists from the reader-response school of literary theory. Ironically, one of the leading theorists from this school, Stanley Fish, was himself trained by New Critics. Fish criticizes Wimsatt and Beardsley in his 1970 essay "Literature in the Reader".

As summarized by Berys Gaut and Paisley Livingston in their essay "The Creation of Art": "Structuralist and post-structuralists theorists and critics were sharply critical of many aspects of New Criticism, beginning with the emphasis on aesthetic appreciation and the so-called autonomy of art, but they reiterated the attack on biographical criticisms' assumption that the artist's activities and experience were a privileged critical topic." These authors contend that: "Anti-intentionalists, such as formalists, hold that the intentions involved in the making of art are irrelevant or peripheral to correctly interpreting art. So details of the act of creating a work, though possibly of interest in themselves, have no bearing on the correct interpretation of the work."

Gaut and Livingston define the intentionalists as distinct from formalists stating that: "Intentionalists, unlike formalists, hold that reference to intentions is essential in fixing the correct interpretation of works." They quote Richard Wollheim as stating that, "The task of criticism is the reconstruction of the creative process, where the creative process must in turn be thought of as something not stopping short of, but terminating on, the work of art itself."

"Linguistic turn" and its debate
The end of the 20th century fostered an extensive debate known as the linguistic turn controversy, or the "innocent eye debate" in the philosophy of art. This debate discussed the encounter of the work of art as being determined by the relative extent to which the conceptual encounter with the work of art dominates over the perceptual encounter with the work of art.

Decisive for the linguistic turn debate in art history and the humanities were the works of yet another tradition, namely the structuralism of Ferdinand de Saussure and the ensuing movement of poststructuralism. In 1981, the artist Mark Tansey created a work of art titled The Innocent Eye as a criticism of the prevailing climate of disagreement in the philosophy of art during the closing decades of the 20th century. Influential theorists include Judith Butler, Luce Irigaray, Julia Kristeva, Michel Foucault and Jacques Derrida. The power of language, more specifically of certain rhetorical tropes, in art history and historical discourse was explored by Hayden White. The fact that language is not a transparent medium of thought had been stressed by a very different form of philosophy of language which originated in the works of Johann Georg Hamann and Wilhelm von Humboldt. Ernst Gombrich and Nelson Goodman in his book Languages of Art: An Approach to a Theory of Symbols came to hold that the conceptual encounter with the work of art predominated exclusively over the perceptual and visual encounter with the work of art during the 1960s and 1970s. He was challenged on the basis of research done by the Nobel prize winning psychologist Roger Sperry who maintained that the human visual encounter was not limited to concepts represented in language alone (the linguistic turn) and that other forms of psychological representations of the work of art were equally defensible and demonstrable. Sperry's view eventually prevailed by the end of the 20th century with aesthetic philosophers such as Nick Zangwill strongly defending a return to moderate aesthetic formalism among other alternatives.

Classification disputes
Main article: Classificatory disputes about art

The original Fountain by Marcel Duchamp, 1917, photographed by Alfred Stieglitz at the 291 after the 1917 Society of Independent Artists exhibit. Stieglitz used a backdrop of The Warriors by Marsden Hartley to photograph the urinal. The exhibition entry tag can be clearly seen.
Disputes as to whether or not to classify something as a work of art are referred to as classificatory disputes about art. Classificatory disputes in the 20th century have included cubist and impressionist paintings, Duchamp's Fountain, the movies, J. S. G. Boggs' superlative imitations of banknotes, conceptual art, and video games. Philosopher David Novitz has argued that disagreement about the definition of art are rarely the heart of the problem. Rather, "the passionate concerns and interests that humans vest in their social life" are "so much a part of all classificatory disputes about art." According to Novitz, classificatory disputes are more often disputes about societal values and where society is trying to go than they are about theory proper. For example, when the Daily Mail criticized Hirst's and Emin's work by arguing "For 1,000 years art has been one of our great civilising forces. Today, pickled sheep and soiled beds threaten to make barbarians of us all" they are not advancing a definition or theory about art, but questioning the value of Hirst's and Emin's work. In 1998, Arthur Danto, suggested a thought experiment showing that "the status of an artifact as work of art results from the ideas a culture applies to it, rather than its inherent physical or perceptible qualities. Cultural interpretation (an art theory of some kind) is therefore constitutive of an object's arthood."

Anti-art is a label for art that intentionally challenges the established parameters and values of art; it is a term associated with Dadaism and attributed to Marcel Duchamp just before World War I, when he was making art from found objects. One of these, Fountain (1917), an ordinary urinal, has achieved considerable prominence and influence on art. Anti-art is a feature of work by Situationist International, the lo-fi Mail art movement, and the Young British Artists, though it is a form still rejected by the Stuckists, who describe themselves as anti-anti-art.

Architecture is often included as one of the visual arts; however, like the decorative arts, or advertising, it involves the creation of objects where the practical considerations of use are essential in a way that they usually are not in a painting, for example.

Value judgment

Aboriginal hollow log tombs. National Gallery, Canberra, Australia.
Somewhat in relation to the above, the word art is also used to apply judgments of value, as in such expressions as "that meal was a work of art" (the cook is an artist), or "the art of deception" (the highly attained level of skill of the deceiver is praised). It is this use of the word as a measure of high quality and high value that gives the term its flavor of subjectivity. Making judgments of value requires a basis for criticism. At the simplest level, a way to determine whether the impact of the object on the senses meets the criteria to be considered art is whether it is perceived to be attractive or repulsive. Though perception is always colored by experience, and is necessarily subjective, it is commonly understood that what is not somehow aesthetically satisfying cannot be art. However, "good" art is not always or even regularly aesthetically appealing to a majority of viewers. In other words, an artist's prime motivation need not be the pursuit of the aesthetic. Also, art often depicts terrible images made for social, moral, or thought-provoking reasons. For example, Francisco Goya's painting depicting the Spanish shootings of 3 May 1808 is a graphic depiction of a firing squad executing several pleading civilians. Yet at the same time, the horrific imagery demonstrates Goya's keen artistic ability in composition and execution and produces fitting social and political outrage. Thus, the debate continues as to what mode of aesthetic satisfaction, if any, is required to define 'art'.

The assumption of new values or the rebellion against accepted notions of what is aesthetically superior need not occur concurrently with a complete abandonment of the pursuit of what is aesthetically appealing. Indeed, the reverse is often true, that the revision of what is popularly conceived of as being aesthetically appealing allows for a re-invigoration of aesthetic sensibility, and a new appreciation for the standards of art itself. Countless schools have proposed their own ways to define quality, yet they all seem to agree in at least one point: once their aesthetic choices are accepted, the value of the work of art is determined by its capacity to transcend the limits of its chosen medium to strike some universal chord by the rarity of the skill of the artist or in its accurate reflection in what is termed the zeitgeist. Art is often intended to appeal to and connect with human emotion. It can arouse aesthetic or moral feelings, and can be understood as a way of communicating these feelings. Artists express something so that their audience is aroused to some extent, but they do not have to do so consciously. Art may be considered an exploration of the human condition; that is, what it is to be human. By extension, it has been argued by Emily L. Spratt that the development of artificial intelligence, especially in regard to its uses with images, necessitates a re-evaluation of aesthetic theory in art history today and a reconsideration of the limits of human creativity.

Art and law
An essential legal issue are art forgeries, plagiarism, replicas and works that are strongly based on other works of art.

The trade in works of art or the export from a country may be subject to legal regulations. Internationally there are also extensive efforts to protect the works of art created. The UN, UNESCO and Blue Shield International try to ensure effective protection at the national level and to intervene directly in the event of armed conflicts or disasters. This can particularly affect museums, archives, art collections and excavation sites. This should also secure the economic basis of a country, especially because works of art are often of tourist importance. The founding president of Blue Shield International, Karl von Habsburg, explained an additional connection between the destruction of cultural property and the cause of flight during a mission in Lebanon in April 2019: “Cultural goods are part of the identity of the people who live in a certain place. If you destroy their culture, you also destroy their identity. Many people are uprooted, often no longer have any prospects and as a result flee from their homeland.” In order to preserve the diversity of cultural identity, UNESCO protects the living human treasure through the Convention for the Safeguarding of the Intangible Cultural Heritage.

Culture

Article
Talk
Read
View source
View history

Tools
Page semi-protected
From Wikipedia, the free encyclopedia
This article is about culture as used in the social sciences and humanities. For uses in the natural sciences, see Cell culture and Tissue culture. For other uses, see Culture (disambiguation).

It has been suggested that Cultural activities be merged into this article. (Discuss) Proposed since April 2023.

Human symbolic expression developed as prehistoric humans reached behavioral modernity.

Religion and expressive art are important aspects of human culture.

Germans marching during a folk culture celebration
Culture (/ˈkʌltʃər/) is an umbrella term which encompasses the social behavior, institutions, and norms found in human societies, as well as the knowledge, beliefs, arts, laws, customs, capabilities, and habits of the individuals in these groups. Culture is often originated from or attributed to a specific region or location.

Humans acquire culture through the learning processes of enculturation and socialization, which is shown by the diversity of cultures across societies.

A cultural norm codifies acceptable conduct in society; it serves as a guideline for behavior, dress, language, and demeanor in a situation, which serves as a template for expectations in a social group. Accepting only a monoculture in a social group can bear risks, just as a single species can wither in the face of environmental change, for lack of functional responses to the change. Thus in military culture, valor is counted a typical behavior for an individual and duty, honor, and loyalty to the social group are counted as virtues or functional responses in the continuum of conflict. In the practice of religion, analogous attributes can be identified in a social group.

Cultural change, or repositioning, is the reconstruction of a cultural concept of a society. Cultures are internally affected by both forces encouraging change and forces resisting change. Cultures are externally affected via contact between societies.

Organizations like UNESCO attempt to preserve culture and cultural heritage.

Description

Pygmy music has been polyphonic well before their discovery by non-African explorers of the Baka, Aka, Efe, and other foragers of the Central African forests, in the 1200s, which is at least 200 years before polyphony developed in Europe. Note the multiple lines of singers and dancers. The motifs are independent, with theme and variation interweaving. This type of music is thought to be the first expression of polyphony in world music.
Culture is considered a central concept in anthropology, encompassing the range of phenomena that are transmitted through social learning in human societies. Cultural universals are found in all human societies. These include expressive forms like art, music, dance, ritual, religion, and technologies like tool usage, cooking, shelter, and clothing. The concept of material culture covers the physical expressions of culture, such as technology, architecture and art, whereas the immaterial aspects of culture such as principles of social organization (including practices of political organization and social institutions), mythology, philosophy, literature (both written and oral), and science comprise the intangible cultural heritage of a society.

In the humanities, one sense of culture as an attribute of the individual has been the degree to which they have cultivated a particular level of sophistication in the arts, sciences, education, or manners. The level of cultural sophistication has also sometimes been used to distinguish civilizations from less complex societies. Such hierarchical perspectives on culture are also found in class-based distinctions between a high culture of the social elite and a low culture, popular culture, or folk culture of the lower classes, distinguished by the stratified access to cultural capital. In common parlance, culture is often used to refer specifically to the symbolic markers used by ethnic groups to distinguish themselves visibly from each other such as body modification, clothing or jewelry. Mass culture refers to the mass-produced and mass mediated forms of consumer culture that emerged in the 20th century. Some schools of philosophy, such as Marxism and critical theory, have argued that culture is often used politically as a tool of the elites to manipulate the proletariat and create a false consciousness. Such perspectives are common in the discipline of cultural studies. In the wider social sciences, the theoretical perspective of cultural materialism holds that human symbolic culture arises from the material conditions of human life, as humans create the conditions for physical survival, and that the basis of culture is found in evolved biological dispositions.

When used as a count noun, a "culture" is the set of customs, traditions, and values of a society or community, such as an ethnic group or nation. Culture is the set of knowledge acquired over time. In this sense, multiculturalism values the peaceful coexistence and mutual respect between different cultures inhabiting the same planet. Sometimes "culture" is also used to describe specific practices within a subgroup of a society, a subculture (e.g. "bro culture"), or a counterculture. Within cultural anthropology, the ideology and analytical stance of cultural relativism hold that cultures cannot easily be objectively ranked or evaluated because any evaluation is necessarily situated within the value system of a given culture.

Etymology
The modern term "culture" is based on a term used by the ancient Roman orator Cicero in his Tusculanae Disputationes, where he wrote of a cultivation of the soul or "cultura animi," using an agricultural metaphor for the development of a philosophical soul, understood teleologically as the highest possible ideal for human development. Samuel Pufendorf took over this metaphor in a modern context, meaning something similar, but no longer assuming that philosophy was man's natural perfection. His use, and that of many writers after him, "refers to all the ways in which human beings overcome their original barbarism, and through artifice, become fully human."

In 1986, philosopher Edward S. Casey wrote, "The very word culture meant 'place tilled' in Middle English, and the same word goes back to Latin colere, 'to inhabit, care for, till, worship' and cultus, 'A cult, especially a religious one.' To be cultural, to have a culture, is to inhabit a place sufficiently intensely to cultivate it—to be responsible for it, to respond to it, to attend to it caringly."

Culture described by Richard Velkley:

... originally meant the cultivation of the soul or mind, acquires most of its later modern meaning in the writings of the 18th-century German thinkers, who were on various levels developing Rousseau's criticism of "modern liberalism and Enlightenment." Thus a contrast between "culture" and "civilization" is usually implied in these authors, even when not expressed as such.

In the words of anthropologist E.B. Tylor, it is "that complex whole which includes knowledge, belief, art, morals, law, custom and any other capabilities and habits acquired by man as a member of society." Alternatively, in a contemporary variant, "Culture is defined as a social domain that emphasizes the practices, discourses and material expressions, which, over time, express the continuities and discontinuities of social meaning of a life held in common.

The Cambridge English Dictionary states that culture is "the way of life, especially the general customs and beliefs, of a particular group of people at a particular time." Terror management theory posits that culture is a series of activities and worldviews that provide humans with the basis for perceiving themselves as "person[s] of worth within the world of meaning"—raising themselves above the merely physical aspects of existence, in order to deny the animal insignificance and death that Homo sapiens became aware of when they acquired a larger brain.

The word is used in a general sense as the evolved ability to categorize and represent experiences with symbols and to act imaginatively and creatively. This ability arose with the evolution of behavioral modernity in humans around 50,000 years ago and is often thought to be unique to humans. However, some other species have demonstrated similar, though much less complicated, abilities for social learning. It is also used to denote the complex networks of practices and accumulated knowledge and ideas that are transmitted through social interaction and exist in specific human groups, or cultures, using the plural form.[citation needed]

Change
Main article: Culture change

The Beatles exemplified changing cultural dynamics, not only in music, but fashion and lifestyle. Over a half century after their emergence, they continue to have a worldwide cultural impact.
Raimon Panikkar identified 29 ways in which cultural change can be brought about, including growth, development, evolution, involution, renovation, reconception, reform, innovation, revivalism, revolution, mutation, progress, diffusion, osmosis, borrowing, eclecticism, syncretism, modernization, indigenization, and transformation. In this context, modernization could be viewed as adoption of Enlightenment era beliefs and practices, such as science, rationalism, industry, commerce, democracy, and the notion of progress. Rein Raud, building on the work of Umberto Eco, Pierre Bourdieu and Jeffrey C. Alexander, has proposed a model of cultural change based on claims and bids, which are judged by their cognitive adequacy and endorsed or not endorsed by the symbolic authority of the cultural community in question.


A 19th-century engraving showing Australian natives opposing the arrival of Captain James Cook in 1770

An Assyrian child wearing traditional clothing
Cultural invention has come to mean any innovation that is new and found to be useful to a group of people and expressed in their behavior but which does not exist as a physical object. Humanity is in a global "accelerating culture change period," driven by the expansion of international commerce, the mass media, and above all, the human population explosion, among other factors. Culture repositioning means the reconstruction of the cultural concept of a society.


Full-length profile portrait of a Turkmen woman, standing on a carpet at the entrance to a yurt, dressed in traditional clothing and jewelry
Cultures are internally affected by both forces encouraging change and forces resisting change. These forces are related to both social structures and natural events, and are involved in the perpetuation of cultural ideas and practices within current structures, which themselves are subject to change.

Social conflict and the development of technologies can produce changes within a society by altering social dynamics and promoting new cultural models, and spurring or enabling generative action. These social shifts may accompany ideological shifts and other types of cultural change. For example, the U.S. feminist movement involved new practices that produced a shift in gender relations, altering both gender and economic structures. Environmental conditions may also enter as factors. For example, after tropical forests returned at the end of the last ice age, plants suitable for domestication were available, leading to the invention of agriculture, which in turn brought about many cultural innovations and shifts in social dynamics.

Cultures are externally affected via contact between societies, which may also produce—or inhibit—social shifts and changes in cultural practices. War or competition over resources may impact technological development or social dynamics. Additionally, cultural ideas may transfer from one society to another, through diffusion or acculturation. In diffusion, the form of something (though not necessarily its meaning) moves from one culture to another. For example, Western restaurant chains and culinary brands sparked curiosity and fascination to the Chinese as China opened its economy to international trade in the late 20th-century. "Stimulus diffusion" (the sharing of ideas) refers to an element of one culture leading to an invention or propagation in another. "Direct borrowing," on the other hand, tends to refer to technological or tangible diffusion from one culture to another. Diffusion of innovations theory presents a research-based model of why and when individuals and cultures adopt new ideas, practices, and products.

Acculturation has different meanings. Still, in this context, it refers to the replacement of traits of one culture with another, such as what happened to certain Native American tribes and many indigenous peoples across the globe during the process of colonization. Related processes on an individual level include assimilation (adoption of a different culture by an individual) and transculturation. The transnational flow of culture has played a major role in merging different cultures and sharing thoughts, ideas, and beliefs.

Early modern discourses
German Romanticism

Johann Herder called attention to national cultures.
Immanuel Kant (1724–1804) formulated an individualist definition of "enlightenment" similar to the concept of bildung: "Enlightenment is man's emergence from his self-incurred immaturity." He argued that this immaturity comes not from a lack of understanding, but from a lack of courage to think independently. Against this intellectual cowardice, Kant urged: "Sapere Aude" ("Dare to be wise!"). In reaction to Kant, German scholars such as Johann Gottfried Herder (1744–1803) argued that human creativity, which necessarily takes unpredictable and highly diverse forms, is as important as human rationality. Moreover, Herder proposed a collective form of Bildung: "For Herder, Bildung was the totality of experiences that provide a coherent identity, and sense of common destiny, to a people."


Adolf Bastian developed a universal model of culture.
In 1795, the Prussian linguist and philosopher Wilhelm von Humboldt (1767–1835) called for an anthropology that would synthesize Kant's and Herder's interests. During the Romantic era, scholars in Germany, especially those concerned with nationalist movements—such as the nationalist struggle to create a "Germany" out of diverse principalities, and the nationalist struggles by ethnic minorities against the Austro-Hungarian Empire—developed a more inclusive notion of culture as "worldview" (Weltanschauung). According to this school of thought, each ethnic group has a distinct worldview that is incommensurable with the worldviews of other groups. Although more inclusive than earlier views, this approach to culture still allowed for distinctions between "civilized" and "primitive" or "tribal" cultures.

In 1860, Adolf Bastian (1826–1905) argued for "the psychic unity of mankind." He proposed that a scientific comparison of all human societies would reveal that distinct worldviews consisted of the same basic elements. According to Bastian, all human societies share a set of "elementary ideas" (Elementargedanken); different cultures, or different "folk ideas" (Völkergedanken), are local modifications of the elementary ideas. This view paved the way for the modern understanding of culture. Franz Boas (1858–1942) was trained in this tradition, and he brought it with him when he left Germany for the United States.

English Romanticism

British poet and critic Matthew Arnold viewed "culture" as the cultivation of the humanist ideal.
In the 19th century, humanists such as English poet and essayist Matthew Arnold (1822–1888) used the word "culture" to refer to an ideal of individual human refinement, of "the best that has been thought and said in the world." This concept of culture is also comparable to the German concept of bildung: "...culture being a pursuit of our total perfection by means of getting to know, on all the matters which most concern us, the best which has been thought and said in the world."

In practice, culture referred to an elite ideal and was associated with such activities as art, classical music, and haute cuisine. As these forms were associated with urban life, "culture" was identified with "civilization" (from Latin: civitas, lit. 'city'). Another facet of the Romantic movement was an interest in folklore, which led to identifying a "culture" among non-elites. This distinction is often characterized as that between high culture, namely that of the ruling social group, and low culture. In other words, the idea of "culture" that developed in Europe during the 18th and early 19th centuries reflected inequalities within European societies.


British anthropologist Edward Tylor was one of the first English-speaking scholars to use the term culture in an inclusive and universal sense.
Matthew Arnold contrasted "culture" with anarchy; other Europeans, following philosophers Thomas Hobbes and Jean-Jacques Rousseau, contrasted "culture" with "the state of nature." According to Hobbes and Rousseau, the Native Americans who were being conquered by Europeans from the 16th centuries on were living in a state of nature; this opposition was expressed through the contrast between "civilized" and "uncivilized." According to this way of thinking, one could classify some countries and nations as more civilized than others and some people as more cultured than others. This contrast led to Herbert Spencer's theory of Social Darwinism and Lewis Henry Morgan's theory of cultural evolution. Just as some critics have argued that the distinction between high and low cultures is an expression of the conflict between European elites and non-elites, other critics have argued that the distinction between civilized and uncivilized people is an expression of the conflict between European colonial powers and their colonial subjects.

Other 19th-century critics, following Rousseau, have accepted this differentiation between higher and lower culture, but have seen the refinement and sophistication of high culture as corrupting and unnatural developments that obscure and distort people's essential nature. These critics considered folk music (as produced by "the folk," i.e., rural, illiterate, peasants) to honestly express a natural way of life, while classical music seemed superficial and decadent. Equally, this view often portrayed indigenous peoples as "noble savages" living authentic and unblemished lives, uncomplicated and uncorrupted by the highly stratified capitalist systems of the West.

In 1870 the anthropologist Edward Tylor (1832–1917) applied these ideas of higher versus lower culture to propose a theory of the evolution of religion. According to this theory, religion evolves from more polytheistic to more monotheistic forms. In the process, he redefined culture as a diverse set of activities characteristic of all human societies. This view paved the way for the modern understanding of religion.

Anthropology

Petroglyphs in modern-day Gobustan, Azerbaijan, dating back to 10,000 BCE and indicating a thriving culture
Main article: American anthropology
Although anthropologists worldwide refer to Tylor's definition of culture, in the 20th century "culture" emerged as the central and unifying concept of American anthropology, where it most commonly refers to the universal human capacity to classify and encode human experiences symbolically, and to communicate symbolically encoded experiences socially. American anthropology is organized into four fields, each of which plays an important role in research on culture: biological anthropology, linguistic anthropology, cultural anthropology, and in the United States and Canada, archaeology. The term Kulturbrille, or "culture glasses," coined by German American anthropologist Franz Boas, refers to the "lenses" through which a person sees their own culture. Martin Lindstrom asserts that Kulturbrille, which allow a person to make sense of the culture they inhabit, "can blind us to things outsiders pick up immediately."

Sociology
Main article: Sociology of culture

An example of folkloric dancing in Colombia
The sociology of culture concerns culture as manifested in society. For sociologist Georg Simmel (1858–1918), culture referred to "the cultivation of individuals through the agency of external forms which have been objectified in the course of history." As such, culture in the sociological field can be defined as the ways of thinking, the ways of acting, and the material objects that together shape a people's way of life. Culture can be either of two types, non-material culture or material culture. Non-material culture refers to the non-physical ideas that individuals have about their culture, including values, belief systems, rules, norms, morals, language, organizations, and institutions, while material culture is the physical evidence of a culture in the objects and architecture they make or have made. The term tends to be relevant only in archeological and anthropological studies, but it specifically means all material evidence which can be attributed to culture, past or present.

Cultural sociology first emerged in Weimar Germany (1918–1933), where sociologists such as Alfred Weber used the term Kultursoziologie ('cultural sociology'). Cultural sociology was then reinvented in the English-speaking world as a product of the cultural turn of the 1960s, which ushered in structuralist and postmodern approaches to social science. This type of cultural sociology may be loosely regarded as an approach incorporating cultural analysis and critical theory. Cultural sociologists tend to reject scientific methods, instead hermeneutically focusing on words, artifacts and symbols. Culture has since become an important concept across many branches of sociology, including resolutely scientific fields like social stratification and social network analysis. As a result, there has been a recent influx of quantitative sociologists to the field. Thus, there is now a growing group of sociologists of culture who are, confusingly, not cultural sociologists. These scholars reject the abstracted postmodern aspects of cultural sociology, and instead, look for a theoretical backing in the more scientific vein of social psychology and cognitive science.


Nowruz is a good sample of popular and folklore culture that is celebrated by people in more than 22 countries with different nations and religions, at the 1st day of spring. It has been celebrated by diverse communities for over 7,000 years.
Early researchers and development of cultural sociology
The sociology of culture grew from the intersection between sociology (as shaped by early theorists like Marx, Durkheim, and Weber) with the growing discipline of anthropology, wherein researchers pioneered ethnographic strategies for describing and analyzing a variety of cultures around the world. Part of the legacy of the early development of the field lingers in the methods (much of cultural, sociological research is qualitative), in the theories (a variety of critical approaches to sociology are central to current research communities), and in the substantive focus of the field. For instance, relationships between popular culture, political control, and social class were early and lasting concerns in the field.

Cultural studies
Main article: Cultural studies
In the United Kingdom, sociologists and other scholars influenced by Marxism such as Stuart Hall (1932–2014) and Raymond Williams (1921–1988) developed cultural studies. Following nineteenth-century Romantics, they identified culture with consumption goods and leisure activities (such as art, music, film, food, sports, and clothing). They saw patterns of consumption and leisure as determined by relations of production, which led them to focus on class relations and the organization of production.

In the United Kingdom, cultural studies focuses largely on the study of popular culture; that is, on the social meanings of mass-produced consumer and leisure goods. Richard Hoggart coined the term in 1964 when he founded the Birmingham Centre for Contemporary Cultural Studies or CCCS. It has since become strongly associated with Stuart Hall, who succeeded Hoggart as Director. Cultural studies in this sense, then, can be viewed as a limited concentration scoped on the intricacies of consumerism, which belongs to a wider culture sometimes referred to as Western civilization or globalism.


The Metropolitan Museum of Art in Manhattan. Visual art is one expression of culture.
From the 1970s onward, Stuart Hall's pioneering work, along with that of his colleagues Paul Willis, Dick Hebdige, Tony Jefferson, and Angela McRobbie, created an international intellectual movement. As the field developed, it began to combine political economy, communication, sociology, social theory, literary theory, media theory, film/video studies, cultural anthropology, philosophy, museum studies, and art history to study cultural phenomena or cultural texts. In this field researchers often concentrate on how particular phenomena relate to matters of ideology, nationality, ethnicity, social class, and/or gender. Cultural studies is concerned with the meaning and practices of everyday life. These practices comprise the ways people do particular things (such as watching television or eating out) in a given culture. It also studies the meanings and uses people attribute to various objects and practices. Specifically, culture involves those meanings and practices held independently of reason. Watching television to view a public perspective on a historical event should not be thought of as culture unless referring to the medium of television itself, which may have been selected culturally; however, schoolchildren watching television after school with their friends to "fit in" certainly qualifies since there is no grounded reason for one's participation in this practice.

In the context of cultural studies, a text includes not only written language, but also films, photographs, fashion or hairstyles: the texts of cultural studies comprise all the meaningful artifacts of culture. Similarly, the discipline widens the concept of culture. Culture, for a cultural-studies researcher, not only includes traditional high culture (the culture of ruling social groups) and popular culture, but also everyday meanings and practices. The last two, in fact, have become the main focus of cultural studies. A further and recent approach is comparative cultural studies, based on the disciplines of comparative literature and cultural studies.

Scholars in the United Kingdom and the United States developed somewhat different versions of cultural studies after the late 1970s. The British version of cultural studies had originated in the 1950s and 1960s, mainly under the influence of Richard Hoggart, E.P. Thompson, and Raymond Williams, and later that of Stuart Hall and others at the Centre for Contemporary Cultural Studies at the University of Birmingham. This included overtly political, left-wing views, and criticisms of popular culture as "capitalist" mass culture; it absorbed some of the ideas of the Frankfurt School critique of the "culture industry" (i.e. mass culture). This emerges in the writings of early British cultural-studies scholars and their influences: see the work of (for example) Raymond Williams, Stuart Hall, Paul Willis, and Paul Gilroy.

In the United States, Lindlof and Taylor write, "cultural studies [were] grounded in a pragmatic, liberal-pluralist tradition." The American version of cultural studies initially concerned itself more with understanding the subjective and appropriative side of audience reactions to, and uses of, mass culture; for example, American cultural-studies advocates wrote about the liberatory aspects of fandom.[citation needed] The distinction between American and British strands, however, has faded.[citation needed] Some researchers, especially in early British cultural studies, apply a Marxist model to the field. This strain of thinking has some influence from the Frankfurt School, but especially from the structuralist Marxism of Louis Althusser and others. The main focus of an orthodox Marxist approach concentrates on the production of meaning. This model assumes a mass production of culture and identifies power as residing with those producing cultural artifacts. In a Marxist view, the mode and relations of production form the economic base of society, which constantly interacts and influences superstructures, such as culture. Other approaches to cultural studies, such as feminist cultural studies and later American developments of the field, distance themselves from this view. They criticize the Marxist assumption of a single, dominant meaning, shared by all, for any cultural product. The non-Marxist approaches suggest that different ways of consuming cultural artifacts affect the meaning of the product. This view comes through in the book Doing Cultural Studies: The Story of the Sony Walkman (by Paul du Gay et al.), which seeks to challenge the notion that those who produce commodities control the meanings that people attribute to them. Feminist cultural analyst, theorist, and art historian Griselda Pollock contributed to cultural studies from viewpoints of art history and psychoanalysis. The writer Julia Kristeva is among influential voices at the turn of the century, contributing to cultural studies from the field of art and psychoanalytical French feminism.

Petrakis and Kostis (2013) divide cultural background variables into two main groups:

The first group covers the variables that represent the "efficiency orientation" of the societies: performance orientation, future orientation, assertiveness, power distance, and uncertainty avoidance.
The second covers the variables that represent the "social orientation" of societies, i.e., the attitudes and lifestyles of their members. These variables include gender egalitarianism, institutional collectivism, in-group collectivism, and human orientation.
In 2016, a new approach to culture was suggested by Rein Raud, who defines culture as the sum of resources available to human beings for making sense of their world and proposes a two-tiered approach, combining the study of texts (all reified meanings in circulation) and cultural practices (all repeatable actions that involve the production, dissemination or transmission of purposes), thus making it possible to re-link anthropological and sociological study of culture with the tradition of textual theory.

Psychology
See also: Social psychology, Cultural psychology, and Cross-cultural psychology

Cognitive tools suggest a way for people from certain culture to deal with real-life problems, like Suanpan for Chinese to perform mathematical calculation.
Starting in the 1990s,: 31  psychological research on culture influence began to grow and challenge the universality assumed in general psychology.: 158–168  Culture psychologists began to try to explore the relationship between emotions and culture, and answer whether the human mind is independent from culture. For example, people from collectivistic cultures, such as the Japanese, suppress their positive emotions more than their American counterparts. Culture may affect the way that people experience and express emotions. On the other hand, some researchers try to look for differences between people's personalities across cultures. As different cultures dictate distinctive norms, culture shock is also studied to understand how people react when they are confronted with other cultures. Cognitive tools may not be accessible or they may function differently cross culture.: 19  For example, people who are raised in a culture with an abacus are trained with distinctive reasoning style. Cultural lenses may also make people view the same outcome of events differently. Westerners are more motivated by their successes than their failures, while East Asians are better motivated by the avoidance of failure. Culture is important for psychologists to consider when understanding the human mental operation.

Protection of culture

Restoration of an ancient Egyptian monument
There are a number of international agreements and national laws relating to the protection of culture and cultural heritage. UNESCO and its partner organizations such as Blue Shield International coordinate international protection and local implementation. The Hague Convention for the Protection of Cultural Property in the Event of Armed Conflict and the UNESCO Convention on the Protection and Promotion of the Diversity of Cultural Expressions deal with the protection of culture. Article 27 of the Universal Declaration of Human Rights deals with cultural heritage in two ways: it gives people the right to participate in cultural life on the one hand and the right to the protection of their contributions to cultural life on the other.

In the 21st century, the protection of culture has been the focus of increasing activity by national and international organizations. The UN and UNESCO promote cultural preservation and cultural diversity through declarations and legally-binding conventions or treaties. The aim is not to protect a person's property, but rather to preserve the cultural heritage of humanity, especially in the event of war and armed conflict. According to Karl von Habsburg, President of Blue Shield International, the destruction of cultural assets is also part of psychological warfare. The target of the attack is the identity of the opponent, which is why symbolic cultural assets become a main target. It is also intended to affect the particularly sensitive cultural memory, the growing cultural diversity and the economic basis (such as tourism) of a state, region or municipality.

Tourism is having an increasing impact on the various forms of culture. On the one hand, this can be physical impact on individual objects or the destruction caused by increasing environmental pollution and, on the other hand, socio-cultural effects on society.

Religion is a range of social-cultural systems, including designated behaviors and practices, morals, beliefs, worldviews, texts, sanctified places, prophecies, ethics, or organizations, that generally relate humanity to supernatural, transcendental, and spiritual elements—although there is no scholarly consensus over what precisely constitutes a religion. Different religions may or may not contain various elements ranging from the divine, sacredness, faith, and a supernatural being or beings.

Religious practices may include rituals, sermons, commemoration or veneration (of deities or saints), sacrifices, festivals, feasts, trances, initiations, matrimonial and funerary services, meditation, prayer, music, art, dance or public service. Religions have sacred histories and narratives, which may be preserved in sacred texts, symbols and holy places, that primarily aim to give life meaning. Religions may contain symbolic tales that may attempt to explain the origin of life, the universe, and other phenomena; some followers believe these to be true stories. Traditionally, both faith and reason have been considered sources of religious beliefs.

There are an estimated 10,000 distinct religions worldwide, though nearly all of them have regionally based, relatively small followings. Four religions—Christianity, Islam, Hinduism, and Buddhism—account for over 77% of the world's population, and 92% of the world either follows one of those four religions or identifies as nonreligious, meaning that the remaining 9,000+ faiths account for only 8% of the population combined. The religiously unaffiliated demographic includes those who do not identify with any particular religion, atheists, and agnostics, although many in the demographic still have various religious beliefs. A portion of the population, mostly located in Africa and Asia, are members of new religious movements. Scholars have indicated that global religiosity may be increasing due to religious countries having generally higher birth rates.

The study of religion comprises a wide variety of academic disciplines, including theology, philosophy of religion, comparative religion, and social scientific studies. Theories of religion offer various explanations for its origins and workings, including the ontological foundations of religious being and belief.

Etymology and history of concept

The Buddha, Laozi, and Confucius in a Ming dynasty painting

"Three laughs at Tiger Brook", a Song dynasty (12th century) painting portraying three men representing Confucianism, Taoism (Daoism), and Buddhism laughing together
Etymology
See also: History of Religion
The term religion comes from both Old French and Anglo-Norman (1200s AD) and means respect for sense of right, moral obligation, sanctity, what is sacred, reverence for the gods. It is ultimately derived from the Latin word religiō. According to Roman philosopher Cicero, religiō comes from relegere: re (meaning "again") + lego (meaning "read"), where lego is in the sense of "go over", "choose", or "consider carefully". Contrarily, some modern scholars such as Tom Harpur and Joseph Campbell have argued that religiō is derived from religare: re (meaning "again") + ligare ("bind" or "connect"), which was made prominent by St. Augustine following the interpretation given by Lactantius in Divinae institutiones, IV, 28. The medieval usage alternates with order in designating bonded communities like those of monastic orders: "we hear of the 'religion' of the Golden Fleece, of a knight 'of the religion of Avys'".

Religiō
Main article: Religio
In classic antiquity, religiō broadly meant conscientiousness, sense of right, moral obligation, or duty to anything. In the ancient and medieval world, the etymological Latin root religiō was understood as an individual virtue of worship in mundane contexts; never as doctrine, practice, or actual source of knowledge. In general, religiō referred to broad social obligations towards anything including family, neighbors, rulers, and even towards God. Religiō was most often used by the ancient Romans not in the context of a relation towards gods, but as a range of general emotions which arose from heightened attention in any mundane context such as hesitation, caution, anxiety, or fear, as well as feelings of being bound, restricted, or inhibited. The term was also closely related to other terms like scrupulus (which meant "very precisely"), and some Roman authors related the term superstitio (which meant too much fear or anxiety or shame) to religiō at times. When religiō came into English around the 1200s as religion, it took the meaning of "life bound by monastic vows" or monastic orders. The compartmentalized concept of religion, where religious and worldly things were separated, was not used before the 1500s. The concept of religion was first used in the 1500s to distinguish the domain of the church and the domain of civil authorities; the Peace of Augsburg marks such instance, which has been described by Christian Reus-Smit as "the first step on the road toward a European system of sovereign states."

Roman general Julius Caesar used religiō to mean "obligation of an oath" when discussing captured soldiers making an oath to their captors. Roman naturalist Pliny the Elder used the term religiō to describe the apparent respect given by elephants to the night sky. Cicero used religiō as being related to cultum deorum (worship of the gods).

Threskeia
In Ancient Greece, the Greek term threskeia (θρησκεία) was loosely translated into Latin as religiō in late antiquity. Threskeia was sparsely used in classical Greece but became more frequently used in the writings of Josephus in the 1st century AD. It was used in mundane contexts and could mean multiple things from respectful fear to excessive or harmfully distracting practices of others, to cultic practices. It was often contrasted with the Greek word deisidaimonia, which meant too much fear.

History of the concept of the "religion"
See also: Timeline of religion
Religion is modern concept. The concept was invented recently in the English language and is found texts from the 17th century due to events such as the splitting of Christendom during the Protestant Reformation and globalization in the Age of Exploration, which involved contact with numerous foreign cultures with non-European languages. Some argue that regardless of its definition, it is not appropriate to apply the term religion to non-Western cultures, while some followers of various faiths rebuke using the word to describe their own belief system.

The concept of religion was formed in the 16th and 17th centuries, despite the fact that ancient sacred texts like the Bible, the Quran, and others did not have a word or even a concept of religion in the original languages and neither did the people or the cultures in which these sacred texts were written. For example, there is no precise equivalent of religion in Hebrew, and Judaism does not distinguish clearly between religious, national, racial, or ethnic identities. One of its central concepts is halakha, meaning the walk or path sometimes translated as law, which guides religious practice and belief and many aspects of daily life. Even though the beliefs and traditions of Judaism are found in the ancient world, ancient Jews saw Jewish identity as being about an ethnic or national identity and did not entail a compulsory belief system or regulated rituals. In the 1st century AD, Josephus had used the Greek term ioudaismos (Judaism) as an ethnic term and was not linked to modern abstract concepts of religion or a set of beliefs. The very concept of "Judaism" was invented by the Christian Church, and it was in the 19th century that Jews began to see their ancestral culture as a religion analogous to Christianity. The Greek word threskeia, which was used by Greek writers such as Herodotus and Josephus, is found in the New Testament. Threskeia is sometimes translated as "religion" in today's translations, but the term was understood as generic "worship" well into the medieval period. In the Quran, the Arabic word din is often translated as religion in modern translations, but up to the mid-1600s translators expressed din as "law".

The Sanskrit word dharma, sometimes translated as religion, also means law. Throughout classical South Asia, the study of law consisted of concepts such as penance through piety and ceremonial as well as practical traditions. Medieval Japan at first had a similar union between imperial law and universal or Buddha law, but these later became independent sources of power.

Though traditions, sacred texts, and practices have existed throughout time, most cultures did not align with Western conceptions of religion since they did not separate everyday life from the sacred. In the 18th and 19th centuries, the terms Buddhism, Hinduism, Taoism, Confucianism, and world religions first entered the English language. Native Americans were also thought of as not having religions and also had no word for religion in their languages either. No one self-identified as a Hindu or Buddhist or other similar terms before the 1800s. "Hindu" has historically been used as a geographical, cultural, and later religious identifier for people indigenous to the Indian subcontinent. Throughout its long history, Japan had no concept of religion since there was no corresponding Japanese word, nor anything close to its meaning, but when American warships appeared off the coast of Japan in 1853 and forced the Japanese government to sign treaties demanding, among other things, freedom of religion, the country had to contend with this idea.

According to the philologist Max Müller in the 19th century, the root of the English word religion, the Latin religiō, was originally used to mean only reverence for God or the gods, careful pondering of divine things, piety (which Cicero further derived to mean diligence). Müller characterized many other cultures around the world, including Egypt, Persia, and India, as having a similar power structure at this point in history. What is called ancient religion today, they would have only called law.

Definition
Main article: Definition of religion

Religious symbols from left to right, top to bottom: Christianity, Islam, Hinduism, Buddhism, Judaism, the Baháʼí Faith, Eckankar, Sikhism, Jainism, Wicca, Unitarian Universalism, Shinto, Taoism, Thelema, Tenrikyo, and Zoroastrianism
Scholars have failed to agree on a definition of religion. There are, however, two general definition systems: the sociological/functional and the phenomenological/philosophical.

Modern Western
The concept of religion originated in the modern era in the West. Parallel concepts are not found in many current and past cultures; there is no equivalent term for religion in many languages. Scholars have found it difficult to develop a consistent definition, with some giving up on the possibility of a definition. Others argue that regardless of its definition, it is not appropriate to apply it to non-Western cultures.

An increasing number of scholars have expressed reservations about ever defining the essence of religion. They observe that the way the concept today is used is a particularly modern construct that would not have been understood through much of history and in many cultures outside the West (or even in the West until after the Peace of Westphalia). The MacMillan Encyclopedia of Religions states:

The very attempt to define religion, to find some distinctive or possibly unique essence or set of qualities that distinguish the religious from the remainder of human life, is primarily a Western concern. The attempt is a natural consequence of the Western speculative, intellectualistic, and scientific disposition. It is also the product of the dominant Western religious mode, what is called the Judeo-Christian climate or, more accurately, the theistic inheritance from Judaism, Christianity, and Islam. The theistic form of belief in this tradition, even when downgraded culturally, is formative of the dichotomous Western view of religion. That is, the basic structure of theism is essentially a distinction between a transcendent deity and all else, between the creator and his creation, between God and man.

The anthropologist Clifford Geertz defined religion as a

... system of symbols which acts to establish powerful, pervasive, and long-lasting moods and motivations in men by formulating conceptions of a general order of existence and clothing these conceptions with such an aura of factuality that the moods and motivations seem uniquely realistic."

Alluding perhaps to Tylor's "deeper motive", Geertz remarked that

... we have very little idea of how, in empirical terms, this particular miracle is accomplished. We just know that it is done, annually, weekly, daily, for some people almost hourly; and we have an enormous ethnographic literature to demonstrate it.

The theologian Antoine Vergote took the term supernatural simply to mean whatever transcends the powers of nature or human agency. He also emphasized the cultural reality of religion, which he defined as

... the entirety of the linguistic expressions, emotions and, actions and signs that refer to a supernatural being or supernatural beings.

Peter Mandaville and Paul James intended to get away from the modernist dualisms or dichotomous understandings of immanence/transcendence, spirituality/materialism, and sacredness/secularity. They define religion as

... a relatively-bounded system of beliefs, symbols and practices that addresses the nature of existence, and in which communion with others and Otherness is lived as if it both takes in and spiritually transcends socially-grounded ontologies of time, space, embodiment and knowing.

According to the MacMillan Encyclopedia of Religions, there is an experiential aspect to religion which can be found in almost every culture:

... almost every known culture [has] a depth dimension in cultural experiences ... toward some sort of ultimacy and transcendence that will provide norms and power for the rest of life. When more or less distinct patterns of behavior are built around this depth dimension in a culture, this structure constitutes religion in its historically recognizable form. Religion is the organization of life around the depth dimensions of experience—varied in form, completeness, and clarity in accordance with the environing culture.

Classical

Budazhap Shiretorov (Будажап Цыреторов), the head shaman of the religious community Altan Serge (Алтан Сэргэ) in Buryatia
Friedrich Schleiermacher in the late 18th century defined religion as das schlechthinnige Abhängigkeitsgefühl, commonly translated as "the feeling of absolute dependence".

His contemporary Georg Wilhelm Friedrich Hegel disagreed thoroughly, defining religion as "the Divine Spirit becoming conscious of Himself through the finite spirit."

Edward Burnett Tylor defined religion in 1871 as "the belief in spiritual beings". He argued that narrowing the definition to mean the belief in a supreme deity or judgment after death or idolatry and so on, would exclude many peoples from the category of religious, and thus "has the fault of identifying religion rather with particular developments than with the deeper motive which underlies them". He also argued that the belief in spiritual beings exists in all known societies.

In his book The Varieties of Religious Experience, the psychologist William James defined religion as "the feelings, acts, and experiences of individual men in their solitude, so far as they apprehend themselves to stand in relation to whatever they may consider the divine". By the term divine James meant "any object that is godlike, whether it be a concrete deity or not" to which the individual feels impelled to respond with solemnity and gravity.

Sociologist Émile Durkheim, in his seminal book The Elementary Forms of the Religious Life, defined religion as a "unified system of beliefs and practices relative to sacred things". By sacred things he meant things "set apart and forbidden—beliefs and practices which unite into one single moral community called a Church, all those who adhere to them". Sacred things are not, however, limited to gods or spirits.[note 1] On the contrary, a sacred thing can be "a rock, a tree, a spring, a pebble, a piece of wood, a house, in a word, anything can be sacred". Religious beliefs, myths, dogmas and legends are the representations that express the nature of these sacred things, and the virtues and powers which are attributed to them.

Echoes of James' and Durkheim's definitions are to be found in the writings of, for example, Frederick Ferré who defined religion as "one's way of valuing most comprehensively and intensively". Similarly, for the theologian Paul Tillich, faith is "the state of being ultimately concerned", which "is itself religion. Religion is the substance, the ground, and the depth of man's spiritual life."

When religion is seen in terms of sacred, divine, intensive valuing, or ultimate concern, then it is possible to understand why scientific findings and philosophical criticisms (e.g., those made by Richard Dawkins) do not necessarily disturb its adherents.

Aspects
Beliefs
Main article: Religious beliefs
Traditionally, faith, in addition to reason, has been considered a source of religious beliefs. The interplay between faith and reason, and their use as perceived support for religious beliefs, have been a subject of interest to philosophers and theologians. The origin of religious belief as such is an open question, with possible explanations including awareness of individual death, a sense of community, and dreams.

Mythology
Main article: Mythology
The word myth has several meanings.

A traditional story of ostensibly historical events that serves to unfold part of the world view of a people or explain a practice, belief, or natural phenomenon;
A person or thing having only an imaginary or unverifiable existence; or
A metaphor for the spiritual potentiality in the human being.
Ancient polytheistic religions, such as those of Greece, Rome, and Scandinavia, are usually categorized under the heading of mythology. Religions of pre-industrial peoples, or cultures in development, are similarly called myths in the anthropology of religion. The term myth can be used pejoratively by both religious and non-religious people. By defining another person's religious stories and beliefs as mythology, one implies that they are less real or true than one's own religious stories and beliefs. Joseph Campbell remarked, "Mythology is often thought of as other people's religions, and religion can be defined as misinterpreted mythology."

In sociology, however, the term myth has a non-pejorative meaning. There, myth is defined as a story that is important for the group, whether or not it is objectively or provably true. Examples include the resurrection of their real-life founder Jesus, which, to Christians, explains the means by which they are freed from sin, is symbolic of the power of life over death, and is also said to be a historical event. But from a mythological outlook, whether or not the event actually occurred is unimportant. Instead, the symbolism of the death of an old life and the start of a new life is most significant. Religious believers may or may not accept such symbolic interpretations.

Practices
Main articles: Religious behaviour and Cult (religious practice)
The practices of a religion may include rituals, sermons, commemoration or veneration of a deity (god or goddess), sacrifices, festivals, feasts, trances, initiations, funerary services, matrimonial services, meditation, prayer, religious music, religious art, sacred dance, public service, or other aspects of human culture.

Social organisation
Religions have a societal basis, either as a living tradition which is carried by lay participants, or with an organized clergy, and a definition of what constitutes adherence or membership.

Academic study
Main articles: Religious studies and Classifications of religious movements
A number of disciplines study the phenomenon of religion: theology, comparative religion, history of religion, evolutionary origin of religions, anthropology of religion, psychology of religion (including neuroscience of religion and evolutionary psychology of religion), law and religion, and sociology of religion.

Daniel L. Pals mentions eight classical theories of religion, focusing on various aspects of religion: animism and magic, by E.B. Tylor and J.G. Frazer; the psycho-analytic approach of Sigmund Freud; and further Émile Durkheim, Karl Marx, Max Weber, Mircea Eliade, E.E. Evans-Pritchard, and Clifford Geertz.

Michael Stausberg gives an overview of contemporary theories of religion, including cognitive and biological approaches.

Theories
Main article: Theories of religion
Sociological and anthropological theories of religion generally attempt to explain the origin and function of religion. These theories define what they present as universal characteristics of religious belief and practice.

Origins and development
Main article: History of religion

The Yazılıkaya sanctuary in Turkey, with the twelve gods of the underworld
The origin of religion is uncertain. There are a number of theories regarding the subsequent origins of religious practices.

According to anthropologists John Monaghan and Peter Just, "Many of the great world religions appear to have begun as revitalization movements of some sort, as the vision of a charismatic prophet fires the imaginations of people seeking a more comprehensive answer to their problems than they feel is provided by everyday beliefs. Charismatic individuals have emerged at many times and places in the world. It seems that the key to long-term success—and many movements come and go with little long-term effect—has relatively little to do with the prophets, who appear with surprising regularity, but more to do with the development of a group of supporters who are able to institutionalize the movement."

The development of religion has taken different forms in different cultures. Some religions place an emphasis on belief, while others emphasize practice. Some religions focus on the subjective experience of the religious individual, while others consider the activities of the religious community to be most important. Some religions claim to be universal, believing their laws and cosmology to be binding for everyone, while others are intended to be practiced only by a closely defined or localized group. In many places, religion has been associated with public institutions such as education, hospitals, the family, government, and political hierarchies.

Anthropologists John Monoghan and Peter Just state that, "it seems apparent that one thing religion or belief helps us do is deal with problems of human life that are significant, persistent, and intolerable. One important way in which religious beliefs accomplish this is by providing a set of ideas about how and why the world is put together that allows people to accommodate anxieties and deal with misfortune."

Cultural system
While religion is difficult to define, one standard model of religion, used in religious studies courses, was proposed by Clifford Geertz, who simply called it a "cultural system". A critique of Geertz's model by Talal Asad categorized religion as "an anthropological category". Richard Niebuhr's (1894–1962) five-fold classification of the relationship between Christ and culture, however, indicates that religion and culture can be seen as two separate systems, though with some interplay.

Social constructionism
Main article: Social constructionism
One modern academic theory of religion, social constructionism, says that religion is a modern concept that suggests all spiritual practice and worship follows a model similar to the Abrahamic religions as an orientation system that helps to interpret reality and define human beings. Among the main proponents of this theory of religion are Daniel Dubuisson, Timothy Fitzgerald, Talal Asad, and Jason Ānanda Josephson. The social constructionists argue that religion is a modern concept that developed from Christianity and was then applied inappropriately to non-Western cultures.

Cognitive science
Main article: Cognitive science of religion
Further information: Religion and schizophrenia
Cognitive science of religion is the study of religious thought and behavior from the perspective of the cognitive and evolutionary sciences. The field employs methods and theories from a very broad range of disciplines, including: cognitive psychology, evolutionary psychology, cognitive anthropology, artificial intelligence, cognitive neuroscience, neurobiology, zoology, and ethology. Scholars in this field seek to explain how human minds acquire, generate, and transmit religious thoughts, practices, and schemas by means of ordinary cognitive capacities.

Hallucinations and delusions related to religious content occurs in about 60% of people with schizophrenia. While this number varies across cultures, this had led to theories about a number of influential religious phenomena and possible relation to psychotic disorders. A number of prophetic experiences are consistent with psychotic symptoms, although retrospective diagnoses are practically impossible. Schizophrenic episodes are also experienced by people who do not have belief in gods.

Religious content is also common in temporal lobe epilepsy, and obsessive–compulsive disorder. Atheistic content is also found to be common with temporal lobe epilepsy.

Comparativism
Main article: Comparative religion
Comparative religion is the branch of the study of religions concerned with the systematic comparison of the doctrines and practices of the world's religions. In general, the comparative study of religion yields a deeper understanding of the fundamental philosophical concerns of religion such as ethics, metaphysics, and the nature and form of salvation. Studying such material is meant to give one a richer and more sophisticated understanding of human beliefs and practices regarding the sacred, numinous, spiritual and divine.

In the field of comparative religion, a common geographical classification of the main world religions includes Middle Eastern religions (including Zoroastrianism and Iranian religions), Indian religions, East Asian religions, African religions, American religions, Oceanic religions, and classical Hellenistic religions.

Classification
Main article: History of religion

A map of major denominations and religions of the world
In the 19th and 20th centuries, the academic practice of comparative religion divided religious belief into philosophically defined categories called world religions. Some academics studying the subject have divided religions into three broad categories:

world religions, a term which refers to transcultural, international religions;
indigenous religions, which refers to smaller, culture-specific or nation-specific religious groups; and
new religious movements, which refers to recently developed religions.
Some recent scholarship has argued that not all types of religion are necessarily separated by mutually exclusive philosophies, and furthermore that the utility of ascribing a practice to a certain philosophy, or even calling a given practice religious, rather than cultural, political, or social in nature, is limited. The current state of psychological study about the nature of religiousness suggests that it is better to refer to religion as a largely invariant phenomenon that should be distinguished from cultural norms (i.e. religions).[clarification needed]

Morphological classification
Some scholars classify religions as either universal religions that seek worldwide acceptance and actively look for new converts, such as Christianity, Islam, Buddhism and Jainism, while ethnic religions are identified with a particular ethnic group and do not seek converts. Others reject the distinction, pointing out that all religious practices, whatever their philosophical origin, are ethnic because they come from a particular culture.

Demographic classification
Main articles: Major religious groups and List of religious populations
The five largest religious groups by world population, estimated to account for 5.8 billion people and 84% of the population, are Christianity, Islam, Buddhism, Hinduism (with the relative numbers for Buddhism and Hinduism dependent on the extent of syncretism) and traditional folk religion.

Five largest religions	2015 (billion)	2015 (%)	Demographics
Christianity	2.3	31.2%	Christianity by country
Islam	1.8	24.1%	Islam by country
Hinduism	1.1	15.1%	Hinduism by country
Buddhism	0.5	6.9%	Buddhism by country
Folk Religion	0.4	5.7%	
Total	6.1	83%	Religions by country
A global poll in 2012 surveyed 57 countries and reported that 59% of the world's population identified as religious, 23% as not religious, 13% as convinced atheists, and also a 9% decrease in identification as religious when compared to the 2005 average from 39 countries. A follow-up poll in 2015 found that 63% of the globe identified as religious, 22% as not religious, and 11% as convinced atheists. On average, women are more religious than men. Some people follow multiple religions or multiple religious principles at the same time, regardless of whether or not the religious principles they follow traditionally allow for syncretism. A 2017 Pew projection suggests that Islam will overtake Christianity as the plurality religion by 2075. Unaffiliated populations are projected to drop, even when taking disaffiliation rates into account, due to differences in birth rates.

Scholars have indicated that global religiosity may be increasing due to religious countries having higher birth rates in general.

Specific religions
Main article: List of religions and spiritual traditions
Abrahamic

The patriarch Abraham (by József Molnár)
Abrahamic religions are monotheistic religions which believe they descend from Abraham.

Judaism
Main article: Judaism

The Torah is the primary sacred text of Judaism.
Judaism is the oldest Abrahamic religion, originating in the people of ancient Israel and Judah. The Torah is its foundational text, and is part of the larger text known as the Tanakh or Hebrew Bible. It is supplemented by oral tradition, set down in written form in later texts such as the Midrash and the Talmud. Judaism includes a wide corpus of texts, practices, theological positions, and forms of organization. Within Judaism there are a variety of movements, most of which emerged from Rabbinic Judaism, which holds that God revealed his laws and commandments to Moses on Mount Sinai in the form of both the Written and Oral Torah; historically, this assertion was challenged by various groups. The Jewish people were scattered after the destruction of the Temple in Jerusalem in 70 CE. Today there are about 13 million Jews, about 40 per cent living in Israel and 40 per cent in the United States. The largest Jewish religious movements are Orthodox Judaism (Haredi Judaism and Modern Orthodox Judaism), Conservative Judaism and Reform Judaism.

Christianity

Jesus is the central figure of Christianity.
Christianity is based on the life and teachings of Jesus of Nazareth (1st century) as presented in the New Testament. The Christian faith is essentially faith in Jesus as the Christ, the Son of God, and as Savior and Lord. Almost all Christians believe in the Trinity, which teaches the unity of Father, Son (Jesus Christ), and Holy Spirit as three persons in one Godhead. Most Christians can describe their faith with the Nicene Creed. As the religion of Byzantine Empire in the first millennium and of Western Europe during the time of colonization, Christianity has been propagated throughout the world via missionary work. It is the world's largest religion, with about 2.3 billion followers as of 2015. The main divisions of Christianity are, according to the number of adherents:

The Catholic Church, led by the Bishop of Rome and the bishops worldwide in communion with him, is a communion of 24 Churches sui iuris, including the Latin Church and 23 Eastern Catholic churches, such as the Maronite Catholic Church.
Eastern Christianity, which include Eastern Orthodoxy, Oriental Orthodoxy, and the Church of the East.
Protestantism, separated from the Catholic Church in the 16th-century Protestant Reformation and is split into thousands of denominations. Major branches of Protestantism include Anglicanism, Baptists, Calvinism, Lutheranism, and Methodism, though each of these contain many different denominations or groups.
There are also smaller groups, including:

Restorationism, the belief that Christianity should be restored (as opposed to reformed) along the lines of what is known about the apostolic early church.
Latter-day Saint movement, founded by Joseph Smith in the late 1820s.
Jehovah's Witnesses, founded in the late 1870s by Charles Taze Russell.
Islam

Muslims circumambulating the Kaaba, the most sacred site in Islam
Islam is a monotheistic religion based on the Quran, one of the holy books considered by Muslims to be revealed by God, and on the teachings (hadith) of the Islamic prophet Muhammad, a major political and religious figure of the 7th century CE. Islam is based on the unity of all religious philosophies and accepts all of the Abrahamic prophets of Judaism, Christianity and other Abrahamic religions before Muhammad. It is the most widely practiced religion of Southeast Asia, North Africa, Western Asia, and Central Asia, while Muslim-majority countries also exist in parts of South Asia, Sub-Saharan Africa, and Southeast Europe. There are also several Islamic republics, including Iran, Pakistan, Mauritania, and Afghanistan.

Sunni Islam is the largest denomination within Islam and follows the Qur'an, the ahadith (ar: plural of Hadith) which record the sunnah, whilst placing emphasis on the sahabah.
Shia Islam is the second largest denomination of Islam and its adherents believe that Ali succeeded Muhammad and further places emphasis on Muhammad's family.
There are also Muslim revivalist movements such as Muwahhidism and Salafism.
Other denominations of Islam include Nation of Islam, Ibadi, Sufism, Quranism, Mahdavia, and non-denominational Muslims. Wahhabism is the dominant Muslim schools of thought in the Kingdom of Saudi Arabia.

Other
Whilst Judaism, Christianity and Islam are commonly seen as the only three Abrahamic faiths, there are smaller and newer traditions which lay claim to the designation as well.


The Baháʼí Lotus Temple in Delhi
For example, the Baháʼí Faith is a new religious movement that has links to the major Abrahamic religions as well as other religions (e.g. of Eastern philosophy). Founded in 19th-century Iran, it teaches the unity of all religious philosophies and accepts all of the prophets of Judaism, Christianity, and Islam as well as additional prophets (Buddha, Mahavira), including its founder Bahá'u'lláh. It is an offshoot of Bábism. One of its divisions is the Orthodox Baháʼí Faith.: 48–49 

Even smaller regional Abrahamic groups also exist, including Samaritanism (primarily in Israel and the State of Palestine), the Rastafari movement (primarily in Jamaica), and Druze (primarily in Syria, Lebanon, and Israel). The Druze faith originally developed out of Isma'ilism, and it has sometimes been considered an Islamic school by some Islamic authorities, but Druze themselves do not identify as Muslims. Mandaeism, sometimes also known as Sabianism (after the mysterious Sabians mentioned in the Quran, a name historically claimed by several religious groups), is a Gnostic, monotheistic and ethnic religion.: 4 : 1  Its adherents, the Mandaeans, consider John the Baptist to be their chief prophet. Mandaeans are the last surviving Gnostics from antiquity.

East Asian
Main article: East Asian religions
East Asian religions (also known as Far Eastern religions or Taoic religions) consist of several religions of East Asia which make use of the concept of Tao (in Chinese), Dō (in Japanese or Korean) or Đạo (in Vietnamese). They include:

Taoism and Confucianism

The Temple of Heaven, a Taoist temple complex in Beijing
Taoism and Confucianism, as well as Korean, Vietnamese, and Japanese religion influenced by Chinese thought.
Folk religions
Chinese folk religion: the indigenous religions of the Han Chinese, or, by metonymy, of all the populations of the Chinese cultural sphere. It includes the syncretism of Confucianism, Taoism and Buddhism, Wuism, as well as many new religious movements such as Chen Tao, Falun Gong and Yiguandao.
Other folk and new religions of East Asia and Southeast Asia such as Korean shamanism, Chondogyo, and Jeung San Do in Korea; indigenous Philippine folk religions in the Philippines; Shinto, Shugendo, Ryukyuan religion, and Japanese new religions in Japan; Satsana Phi in Laos; Vietnamese folk religion, and Cao Đài, Hòa Hảo in Vietnam.
Indian religions
Indian religions are practiced or were founded in the Indian subcontinent. They are sometimes classified as the dharmic religions, as they all feature dharma, the specific law of reality and duties expected according to the religion.

Hinduism

Folk depiction of Ganesha in Bharatiya Lok Kala Mandal, Udaipur, India
Hinduism is also called Vaidika Dharma, the dharma of the Vedas. It is a synecdoche describing the similar philosophies of Vaishnavism, Shaivism, and related groups practiced or founded in the Indian subcontinent. Concepts most of them share in common include karma, caste, reincarnation, mantras, yantras, and darśana.[note 2] Hinduism is one of the most ancient of still-active religious belief systems, with origins perhaps as far back as prehistoric times.

The Padmanabhaswamy Temple houses the Padmanabhaswamy Temple treasure.
Jainism

The 10th century Gommateshwara statue in Karnataka
Jainism, taught primarily by Rishabhanatha (the founder of ahimsa) is an ancient Indian religion that prescribes a path of non-violence, truth and anekantavada for all forms of living beings in this universe; which helps them to eliminate all the Karmas, and hence to attain freedom from the cycle of birth and death (saṃsāra), that is, achieving nirvana. Jains are found mostly in India. According to Dundas, outside of the Jain tradition, historians date the Mahavira as about contemporaneous with the Buddha in the 5th-century BCE, and accordingly the historical Parshvanatha, based on the c. 250-year gap, is placed in 8th or 7th century BCE.
Digambara Jainism (or sky-clad) is mainly practiced in South India. Their holy books are Pravachanasara and Samayasara written by their Prophets Kundakunda and Amritchandra as their original canon is lost.
Shwetambara Jainism (or white-clad) is mainly practiced in Western India. Their holy books are Jain Agamas, written by their Prophet Sthulibhadra.
Buddhism

Wat Mixay Buddhist shrine in Vientiane, Laos
Buddhism was founded by Siddhartha Gautama in the 5th century BCE. Buddhists generally agree that Gotama aimed to help sentient beings end their suffering (dukkha) by understanding the true nature of phenomena, thereby escaping the cycle of suffering and rebirth (saṃsāra), that is, achieving nirvana.
Theravada Buddhism, which is practiced mainly in Sri Lanka and Southeast Asia alongside folk religion, shares some characteristics of Indian religions. It is based in a large collection of texts called the Pali Canon.
Mahayana Buddhism (or the Great Vehicle) under which are a multitude of doctrines that became prominent in China and are still relevant in Vietnam, Korea, Japan and to a lesser extent in Europe and the United States. Mahayana Buddhism includes such disparate teachings as Zen, Pure Land, and Soka Gakkai.
Vajrayana Buddhism first appeared in India in the 3rd century CE. It is currently most prominent in the Himalaya regions and extends across all of Asia (cf. Mikkyō).
Two notable new Buddhist sects are Hòa Hảo and the Navayana (Dalit Buddhist movement), which were developed separately in the 20th century.
Sikhism

An 1840 miniature of Guru Nanak
Sikhism is a panentheistic religion founded on the teachings of Guru Nanak and ten successive Sikh gurus in 15th-century Punjab. It is the fifth-largest organized religion in the world, with approximately 30 million Sikhs. Sikhs are expected to embody the qualities of a Sant-Sipāhī—a saint-soldier, have control over one's internal vices and be able to be constantly immersed in virtues clarified in the Guru Granth Sahib. The principal beliefs of Sikhi are faith in Waheguru—represented by the phrase ik ōaṅkār, meaning one God, who prevails in everything, along with a praxis in which the Sikh is enjoined to engage in social reform through the pursuit of justice for all human beings.
Indigenous and folk

Chickasaw Native cultural/religious dancing

Peyotists with their ceremonial tools

Altay shaman in Siberia

Temple to the city god of Wenao in Magong, Taiwan
Indigenous religions or folk religions refers to a broad category of traditional religions that can be characterised by shamanism, animism and ancestor worship, where traditional means "indigenous, that which is aboriginal or foundational, handed down from generation to generation…". These are religions that are closely associated with a particular group of people, ethnicity or tribe; they often have no formal creeds or sacred texts. Some faiths are syncretic, fusing diverse religious beliefs and practices.

Australian Aboriginal religions.
Folk religions of the Americas: Native American religions
Folk religions are often omitted as a category in surveys even in countries where they are widely practiced, e.g. in China.

Traditional African

Shango, the Orisha of fire, lightning, and thunder, in the Yoruba religion, depicted on horseback
Main article: Traditional African religion
Further information: African diasporic religions
African traditional religion encompasses the traditional religious beliefs of people in Africa. In West Africa, these religions include the Akan religion, Dahomey (Fon) mythology, Efik mythology, Odinani, Serer religion (A ƭat Roog), and Yoruba religion, while Bushongo mythology, Mbuti (Pygmy) mythology, Lugbara mythology, Dinka religion, and Lotuko mythology come from central Africa. Southern African traditions include Akamba mythology, Masai mythology, Malagasy mythology, San religion, Lozi mythology, Tumbuka mythology, and Zulu mythology. Bantu mythology is found throughout central, southeast, and southern Africa. In north Africa, these traditions include Berber and ancient Egyptian.

There are also notable African diasporic religions practiced in the Americas, such as Santeria, Candomble, Vodun, Lucumi, Umbanda, and Macumba.


Sacred flame at the Ateshgah of Baku
Iranian
Iranian religions are ancient religions whose roots predate the Islamization of Greater Iran. Nowadays these religions are practiced only by minorities.

Zoroastrianism is based on the teachings of prophet Zoroaster in the 6th century BCE. Zoroastrians worship the creator Ahura Mazda. In Zoroastrianism, good and evil have distinct sources, with evil trying to destroy the creation of Mazda, and good trying to sustain it.

Kurdish religions include the traditional beliefs of the Yazidi, Alevi, and Ahl-e Haqq. Sometimes these are labeled Yazdânism.

New religious movements
Main article: New religious movement
See also: List of new religious movements
The Baháʼí Faith teaches the unity of all religious philosophies.
Cao Đài is a syncretistic, monotheistic religion, established in Vietnam in 1926.
Eckankar is a pantheistic religion with the purpose of making God an everyday reality in one's life.
Epicureanism is a Hellenistic philosophy that is considered by many of its practitioners as a type of (sometimes non-theistic) religious identity. It has its own scriptures, a monthly "feast of reason" on the Twentieth, and considers friendship to be holy.
Hindu reform movements, such as Ayyavazhi, Swaminarayan Faith and Ananda Marga, are examples of new religious movements within Indian religions.
Japanese new religions (shinshukyo) is a general category for a wide variety of religious movements founded in Japan since the 19th century. These movements share almost nothing in common except the place of their founding. The largest religious movements centered in Japan include Soka Gakkai, Tenrikyo, and Seicho-No-Ie among hundreds of smaller groups.
Jehovah's Witnesses, a non-trinitarian Christian Reformist movement sometimes described as millenarian.
Neo-Druidism is a religion promoting harmony with nature, named after but not necessarily connected to the Iron Age druids.
Modern pagan movements attempting to reconstruct or revive ancient pagan practices, such as Heathenry, Hellenism, and Kemeticism
Noahidism is a monotheistic ideology based on the Seven Laws of Noah, and on their traditional interpretations within Rabbinic Judaism.
Some forms of parody religion or fiction-based religion like Jediism, Pastafarianism, Dudeism, "Tolkien religion", and others often develop their own writings, traditions, and cultural expressions, and end up behaving like traditional religions.
Satanism is a broad category of religions that, for example, worship Satan as a deity (Theistic Satanism) or use Satan as a symbol of carnality and earthly values (LaVeyan Satanism and The Satanic Temple).
Scientology is a religious movement that teaches that people are immortal beings who have forgotten their true nature. Its method of spiritual rehabilitation is a type of counseling known as auditing, in which practitioners aim to consciously re-experience and understand painful or traumatic events and decisions in their past in order to free themselves of their limiting effects.
UFO Religions in which extraterrestrial entities are an element of belief, such as Raëlism, Aetherius Society, and Marshall Vian Summers's New Message from God
Unitarian Universalism is a religion characterized by support for a free and responsible search for truth and meaning, and has no accepted creed or theology.
Wicca is a neo-pagan religion first popularised in 1954 by British civil servant Gerald Gardner, involving the worship of a God and Goddess.
Related aspects
Law
Main article: Law and religion
The study of law and religion is a relatively new field, with several thousand scholars involved in law schools, and academic departments including political science, religion, and history since 1980. Scholars in the field are not only focused on strictly legal issues about religious freedom or non-establishment, but also study religions as they are qualified through judicial discourses or legal understanding of religious phenomena. Exponents look at canon law, natural law, and state law, often in a comparative perspective. Specialists have explored themes in Western history regarding Christianity and justice and mercy, rule and equity, and discipline and love. Common topics of interest include marriage and the family and human rights. Outside of Christianity, scholars have looked at law and religion links in the Muslim Middle East and pagan Rome.

Studies have focused on secularization. In particular, the issue of wearing religious symbols in public, such as headscarves that are banned in French schools, have received scholarly attention in the context of human rights and feminism.

Science
Main articles: Faith and rationality, Relationship between religion and science, and Epistemology
Science acknowledges reason and empirical evidence; and religions include revelation, faith and sacredness whilst also acknowledging philosophical and metaphysical explanations with regard to the study of the universe. Both science and religion are not monolithic, timeless, or static because both are complex social and cultural endeavors that have changed through time across languages and cultures.

The concepts of science and religion are a recent invention: the term religion emerged in the 17th century in the midst of colonization and globalization and the Protestant Reformation. The term science emerged in the 19th century out of natural philosophy in the midst of attempts to narrowly define those who studied nature (natural science), and the phrase religion and science emerged in the 19th century due to the reification of both concepts. It was in the 19th century that the terms Buddhism, Hinduism, Taoism, and Confucianism first emerged. In the ancient and medieval world, the etymological Latin roots of both science (scientia) and religion (religio) were understood as inner qualities of the individual or virtues, never as doctrines, practices, or actual sources of knowledge.

In general the scientific method gains knowledge by testing hypotheses to develop theories through elucidation of facts or evaluation by experiments and thus only answers cosmological questions about the universe that can be observed and measured. It develops theories of the world which best fit physically observed evidence. All scientific knowledge is subject to later refinement, or even rejection, in the face of additional evidence. Scientific theories that have an overwhelming preponderance of favorable evidence are often treated as de facto verities in general parlance, such as the theories of general relativity and natural selection to explain respectively the mechanisms of gravity and evolution.

Religion does not have a method per se partly because religions emerge through time from diverse cultures and it is an attempt to find meaning in the world, and to explain humanity's place in it and relationship to it and to any posited entities. In terms of Christian theology and ultimate truths, people rely on reason, experience, scripture, and tradition to test and gauge what they experience and what they should believe. Furthermore, religious models, understanding, and metaphors are also revisable, as are scientific models.

Regarding religion and science, Albert Einstein states (1940): "For science can only ascertain what is, but not what should be, and outside of its domain value judgments of all kinds remain necessary. Religion, on the other hand, deals only with evaluations of human thought and action; it cannot justifiably speak of facts and relationships between facts…Now, even though the realms of religion and science in themselves are clearly marked off from each other, nevertheless there exist between the two strong reciprocal relationships and dependencies. Though religion may be that which determine the goals, it has, nevertheless, learned from science, in the broadest sense, what means will contribute to the attainment of the goals it has set up."

Morality
Main article: Morality and religion
Many religions have value frameworks regarding personal behavior meant to guide adherents in determining between right and wrong. These include the Triple Jems of Jainism, Judaism's Halacha, Islam's Sharia, Catholicism's Canon Law, Buddhism's Eightfold Path, and Zoroastrianism's good thoughts, good words, and good deeds concept, among others.

Religion and morality are not synonymous. While it is "an almost automatic assumption," in Christianity, morality can have a secular basis.

The study of religion and morality can be contentious due to ethnocentric views on morality, failure to distinguish between in group and out group altruism, and inconsistent definitions of religiosity.

Politics
Impact
Main article: Religion in politics
Religion has had a significant impact on the political system in many countries. Notably, most Muslim-majority countries adopt various aspects of sharia, the Islamic law. Some countries even define themselves in religious terms, such as The Islamic Republic of Iran. The sharia thus affects up to 23% of the global population, or 1.57 billion people who are Muslims. However, religion also affects political decisions in many western countries. For instance, in the United States, 51% of voters would be less likely to vote for a presidential candidate who did not believe in God, and only 6% more likely. Christians make up 92% of members of the US Congress, compared with 71% of the general public (as of 2014). At the same time, while 23% of U.S. adults are religiously unaffiliated, only one member of Congress (Kyrsten Sinema, D-Arizona), or 0.2% of that body, claims no religious affiliation. In most European countries, however, religion has a much smaller influence on politics although it used to be much more important. For instance, same-sex marriage and abortion were illegal in many European countries until recently, following Christian (usually Catholic) doctrine. Several European leaders are atheists (e.g. France's former president Francois Hollande or Greece's prime minister Alexis Tsipras). In Asia, the role of religion differs widely between countries. For instance, India is still one of the most religious countries and religion still has a strong impact on politics, given that Hindu nationalists have been targeting minorities like the Muslims and the Christians, who historically[when?] belonged to the lower castes. By contrast, countries such as China or Japan are largely secular and thus religion has a much smaller impact on politics.

Secularism
Main articles: Secularism and Secularization

Ranjit Singh established secular rule over Punjab in the early 19th century.
Secularization is the transformation of the politics of a society from close identification with a particular religion's values and institutions toward nonreligious values and secular institutions. The purpose of this is frequently modernization or protection of the population's religious diversity.

Economics
Main article: Economics of religion
Further information: Religion and business and Wealth and religion

Average income correlates negatively with (self-defined) religiosity.
One study has found there is a negative correlation between self-defined religiosity and the wealth of nations. In other words, the richer a nation is, the less likely its inhabitants to call themselves religious, whatever this word means to them (Many people identify themselves as part of a religion (not irreligion) but do not self-identify as religious).

Sociologist and political economist Max Weber has argued that Protestant Christian countries are wealthier because of their Protestant work ethic. According to a study from 2015, Christians hold the largest amount of wealth (55% of the total world wealth), followed by Muslims (5.8%), Hindus (3.3%) and Jews (1.1%). According to the same study it was found that adherents under the classification Irreligion or other religions hold about 34.8% of the total global wealth (while making up only about 20% of the world population, see section on classification).

Health
Main article: Impacts of religion on health
Mayo Clinic researchers examined the association between religious involvement and spirituality, and physical health, mental health, health-related quality of life, and other health outcomes. The authors reported that: "Most studies have shown that religious involvement and spirituality are associated with better health outcomes, including greater longevity, coping skills, and health-related quality of life (even during terminal illness) and less anxiety, depression, and suicide."

The authors of a subsequent study concluded that the influence of religion on health is largely beneficial, based on a review of related literature. According to academic James W. Jones, several studies have discovered "positive correlations between religious belief and practice and mental and physical health and longevity."

An analysis of data from the 1998 US General Social Survey, whilst broadly confirming that religious activity was associated with better health and well-being, also suggested that the role of different dimensions of spirituality/religiosity in health is rather more complicated. The results suggested "that it may not be appropriate to generalize findings about the relationship between spirituality/religiosity and health from one form of spirituality/religiosity to another, across denominations, or to assume effects are uniform for men and women.

Violence
Main article: Religious violence
See also: Islam and violence, Christianity and violence, and Judaism and violence
Critics such as Hector Avalos, Regina Schwartz, Christopher Hitchens,[page needed] and Richard Dawkins[page needed] have argued that religions are inherently violent and harmful to society by using violence to promote their goals, in ways that are endorsed and exploited by their leaders.

Anthropologist Jack David Eller asserts that religion is not inherently violent, arguing "religion and violence are clearly compatible, but they are not identical." He asserts that "violence is neither essential to nor exclusive to religion" and that "virtually every form of religious violence has its nonreligious corollary."

Animal sacrifice
Main article: Animal sacrifice
Some (but not all) religions practise animal sacrifice, the ritual killing and offering of an animal to appease or maintain favour with a deity. It has been banned in India.

Superstition
Further information: Superstition, Magical thinking, and Magic and religion
Greek and Roman pagans, who saw their relations with the gods in political and social terms, scorned the man who constantly trembled with fear at the thought of the gods (deisidaimonia), as a slave might fear a cruel and capricious master. The Romans called such fear of the gods superstitio. Ancient Greek historian Polybius described superstition in ancient Rome as an instrumentum regni, an instrument of maintaining the cohesion of the Empire.

Superstition has been described as the non-rational establishment of cause and effect. Religion is more complex and is often composed of social institutions and has a moral aspect. Some religions may include superstitions or make use of magical thinking. Adherents of one religion sometimes think of other religions as superstition. Some atheists, deists, and skeptics regard religious belief as superstition.

The Roman Catholic Church considers superstition to be sinful in the sense that it denotes a lack of trust in the divine providence of God and, as such, is a violation of the first of the Ten Commandments. The Catechism of the Catholic Church states that superstition "in some sense represents a perverse excess of religion" (para. #2110). "Superstition," it says, "is a deviation of religious feeling and of the practices this feeling imposes. It can even affect the worship we offer the true God, e.g., when one attributes an importance in some way magical to certain practices otherwise lawful or necessary. To attribute the efficacy of prayers or of sacramental signs to their mere external performance, apart from the interior dispositions that they demand is to fall into superstition. Cf. Matthew 23:16–22" (para. #2111)

Agnosticism and atheism
Main articles: Atheism, Agnosticism, Irreligion, Antireligion, and Humanism
See also: Criticism of atheism
The terms atheist (lack of belief in any gods) and agnostic (belief in the unknowability of the existence of gods), though specifically contrary to theistic (e.g. Christian, Jewish, and Muslim) religious teachings, do not by definition mean the opposite of religious. There are religions (including Buddhism, Taoism, and Hinduism), in fact, that classify some of their followers as agnostic, atheistic, or nontheistic. The true opposite of religious is the word irreligious. Irreligion describes an absence of any religion; antireligion describes an active opposition or aversion toward religions in general.

Interfaith cooperation
Main article: Interfaith dialogue
Because religion continues to be recognized in Western thought as a universal impulse, many religious practitioners[who?] have aimed to band together in interfaith dialogue, cooperation, and religious peacebuilding. The first major dialogue was the Parliament of the World's Religions at the 1893 Chicago World's Fair, which affirmed universal values and recognition of the diversity of practices among different cultures. The 20th century has been especially fruitful in use of interfaith dialogue as a means of solving ethnic, political, or even religious conflict, with Christian–Jewish reconciliation representing a complete reverse in the attitudes of many Christian communities towards Jews.

Recent interfaith initiatives include A Common Word, launched in 2007 and focused on bringing Muslim and Christian leaders together, the "C1 World Dialogue", the Common Ground initiative between Islam and Buddhism, and a United Nations sponsored "World Interfaith Harmony Week".

Culture
Culture and religion have usually been seen as closely related. Paul Tillich looked at religion as the soul of culture and culture as the form or framework of religion. In his own words:

Religion as ultimate concern is the meaning-giving substance of culture, and culture is the totality of forms in which the basic concern of religion expresses itself. In abbreviation: religion is the substance of culture, culture is the form of religion. Such a consideration definitely prevents the establishment of a dualism of religion and culture. Every religious act, not only in organized religion, but also in the most intimate movement of the soul, is culturally formed.

Ernst Troeltsch, similarly, looked at culture as the soil of religion and thought that, therefore, transplanting a religion from its original culture to a foreign culture would actually kill it in the same manner that transplanting a plant from its natural soil to an alien soil would kill it. However, there have been many attempts in the modern pluralistic situation to distinguish culture from religion. Domenic Marbaniang has argued that elements grounded on beliefs of a metaphysical nature (religious) are distinct from elements grounded on nature and the natural (cultural). For instance, language (with its grammar) is a cultural element while sacralization of language in which a particular religious scripture is written is more often a religious practice. The same applies to music and the arts.

Criticism
Main article: Criticism of religion
Criticism of religion is criticism of the ideas, the truth, or the practice of religion, including its political and social implications.

A cuisine is a style of cooking characterized by distinctive ingredients, techniques and dishes, and usually associated with a specific culture or geographic region. Regional food preparation techniques, customs, and ingredients combine to enable dishes unique to a region.

A cuisine is partly determined by ingredients that are available locally or through trade. Regional ingredients are developed and commonly contribute to a regional or national cuisine, such as Japanese rice in Japanese cuisine or New Mexico chile in New Mexican cuisine. Likewise, national dishes have variations, such as gyros in Greek cuisine and hamburger in American cuisine.

Religious food laws can also exercise an influence on cuisine, such as Hinduism in Indian cuisine, Sikhism in Punjabi cuisine, Buddhism in East Asian cuisine, Christianity in European cuisine, Islam in Middle Eastern cuisine, and Judaism in Jewish and Israeli cuisine.

Etymology
Used in English since the late 18th century, the word cuisine – meaning manner or style of cooking – is borrowed from the French for "style of cooking," as originally derived from Latin coquere "to cook".

Factors that affect a cuisine
Some factors that have an influence on a region's cuisine include the area's climate, the trade among different countries, religious or sumptuary laws and culinary culture exchange. For example, a tropical diet may be based more on fruits and vegetables, while a polar diet might rely more on meat and fish.

The area's climate, in large measure, determines the native foods that are available. In addition, climate influences food preservation. For example, foods preserved for winter consumption by smoking, curing, and pickling have remained significant in world cuisines for their altered gustatory properties.

The trade among different countries also largely affects a region's cuisine. Dating back to the ancient spice trade, seasonings such as cinnamon, cassia, cardamom, ginger, and turmeric were important items of commerce in the earliest evolution of trade, and India was a global market for this. Cinnamon and cassia found their way to the Middle East at least 4,000 years ago.

Certain foods and food preparations are required or proscribed by the religiousness or sumptuary laws, such as Islamic dietary laws and Jewish dietary laws.

Culinary culture exchange is also an important factor for cuisine in many regions: Japan's first substantial and direct exposure to the West came with the arrival of European missionaries in the second half of the 16th century. At that time, the combination of Spanish and Portuguese game frying techniques with an East Asian method for cooking vegetables in oil led to the development of tempura, the "popular Japanese dish in which seafood and many different types of vegetables are coated with batter and deep fried".

History
Further information: List of historical cuisines
Cuisine dates back to the Antiquity. As food began to require more planning, there was an emergence of meals that situated around culture.

Evolution of cuisine

An example of nouvelle cuisine presentation. This dish consists of marinated crayfish on gazpacho asparagus and watercress.
Cuisines evolve continually, and new cuisines are created by innovation and cultural interaction. One recent example is fusion cuisine, which combines elements of various culinary traditions while not being categorized per any one cuisine style, and generally refers to the innovations in many contemporary restaurant cuisines since the 1970s. Nouvelle cuisine (New cuisine) is an approach to cooking and food presentation in French cuisine that was popularized in the 1960s by the food critics Henri Gault, who invented the phrase, and his colleagues André Gayot and Christian Millau in a new restaurant guide, the Gault-Millau, or Le Nouveau Guide.[citation needed] Molecular cuisine, is a modern style of cooking which takes advantage of many technical innovations from the scientific disciplines (molecular cooking). The term was coined in 1999 by the French INRA chemist Hervé This because he wanted to distinguish it from the name Molecular gastronomy (a scientific activity) that was introduced by him and the late Oxford physicist Nicholas Kurti in 1988. It is also named as multi sensory cooking, modernist cuisine, culinary physics, and experimental cuisine by some chefs. Besides, international trade brings new foodstuffs including ingredients to existing cuisines and leads to changes. The introduction of hot pepper to China from South America around the end of the 17th century, greatly influencing Sichuan cuisine, which combines the original taste (with use of Sichuan pepper) with the taste of newly introduced hot pepper and creates a unique mala (麻辣) flavor that's mouth-numbingly spicy and pungent.

Global cuisine
Main articles: Global cuisine and List of cuisines
A global cuisine is a cuisine that is practiced around the world, and can be categorized according to the common use of major foodstuffs, including grains, produce and cooking fats.

Regional cuisines
Regional cuisines can vary based on availability and usage of specific ingredients, local cooking traditions and practices, as well as overall cultural differences. Such factors can be more-or-less uniform across wide swaths of territory, or vary intensely within individual regions. For example, in Central and North South America, corn (maize), both fresh and dried, is a staple food, and is used in many different ways. In northern Europe, wheat, rye, and fats of animal origin predominate, while in southern Europe olive oil is ubiquitous and rice is more prevalent. In Italy, the cuisine of the north, featuring butter and rice, stands in contrast to that of the south, with its wheat pasta and olive oil. In some parts of China, rice is the staple, while in others this role is filled by noodles and bread. Throughout the Middle East and Mediterranean, common ingredients include lamb, olive oil, lemons, peppers, and rice. The vegetarianism practiced in much of India has made pulses (crops harvested solely for the dry seed) such as chickpeas and lentils as important as wheat or rice. From India to Indonesia, the extensive use of spices is characteristic; coconuts and seafood are also used throughout the region both as foodstuffs and as seasonings.

African cuisine
LocationAfricaGreen.svg
Main article: List of African cuisines
African cuisines use a combination of locally available fruits, cereals and vegetables, as well as milk and meat products. In some parts of the continent, the traditional diet features a preponderance of milk, curd and whey products. In much of tropical Africa, however, cow's milk is rare and cannot be produced locally (owing to various diseases that affect livestock). The continent's diverse demographic makeup is reflected in the many different eating and drinking habits, dishes, and preparation techniques of its manifold populations.

Typical Ethiopian and Eritrean cuisine: Injera (thin pancake-like bread) and several kinds of wat (stew)
Typical Ethiopian and Eritrean cuisine: Injera (thin pancake-like bread) and several kinds of wat (stew)

 
A Ramadan dinner in Tanzania
A Ramadan dinner in Tanzania

 
Yassa is a popular dish throughout West Africa prepared with chicken or fish. Chicken yassa is pictured.
Yassa is a popular dish throughout West Africa prepared with chicken or fish. Chicken yassa is pictured.

 
Spices at central market in Agadir, Morocco
Spices at central market in Agadir, Morocco

Asian cuisines
LocationAsia.svg
Main article: List of Asian cuisines
Due to Asia's vast size and extremely diverse geography and demographics, Asian cuisines are many and varied, and include East Asian cuisine, South Asian cuisine, Southeast Asian cuisine, Central Asian cuisine and West Asian cuisine. Ingredients common to East Asia and Southeast Asia (due to overseas Chinese influence) include rice, ginger, garlic, sesame seeds, chilies, dried onions, soy, and tofu, with stir frying, steaming, and deep frying being common cooking methods. While rice is common to most regional cuisines in Asia, different varieties are popular in the different regions: Basmati rice is popular in South Asia, Jasmine rice in Southeast Asia, and long-grain rice in China and short-grain rice in Japan and Korea. Curry is also a common ingredient found in South Asia, Southeast Asia, and East Asia (notably Japanese curry); however, they are not popular in West Asian and Central Asian cuisines. Those curry dishes with origins in South Asia usually have a yogurt base, with origins in Southeast Asia a coconut milk base, and in East Asia a stewed meat and vegetable base. South Asian cuisine and Southeast Asian cuisine are often characterized by their extensive use of spices and herbs native to the tropical regions of Asia.

Due to Guangdong's location on the southern coast of China, fresh live seafood is a specialty in Cantonese cuisine. Such markets selling seafood are found across East Asia.
Due to Guangdong's location on the southern coast of China, fresh live seafood is a specialty in Cantonese cuisine. Such markets selling seafood are found across East Asia.

 
Traditional North Indian vegetarian thali with various curries from India. Various curry dishes are found across South Asia.
Traditional North Indian vegetarian thali with various curries from India. Various curry dishes are found across South Asia.

 
A market stall at Thanin market in Chiang Mai, Thailand, selling ready-cooked food. Market stalls selling food are found across Southeast Asia.
A market stall at Thanin market in Chiang Mai, Thailand, selling ready-cooked food. Market stalls selling food are found across Southeast Asia.

 
A Tajik feast. A large feast is commonly associated with cultures of Central Asia.
A Tajik feast. A large feast is commonly associated with cultures of Central Asia.

 
Typical Assyrian cuisine; an example of a type of meal found in West Asia.
Typical Assyrian cuisine; an example of a type of meal found in West Asia.

European cuisine
LocationEuropeGreen.svg
Main article: List of European cuisines
European cuisine (alternatively, "Western cuisine") include the cuisines of Europe and other Western countries. European cuisine includes non-indigenous cuisines of North America, Australasia, Oceania, and Latin America as well. The term is used by East Asians to contrast with East Asian styles of cooking. When used in English, the term may refer more specifically to cuisine in (Continental) Europe; in this context, a synonym is Continental cuisine.

An English Sunday roast with roast beef, roast potatoes, vegetables and Yorkshire pudding
An English Sunday roast with roast beef, roast potatoes, vegetables and Yorkshire pudding

 
Traditional pizza from Napoli: originally Italian dish
Traditional pizza from Napoli: originally Italian dish

 
German sausages and cheese
German sausages and cheese

 
Beef Stroganoff, a Russian dish.
Beef Stroganoff, a Russian dish.

Oceanian cuisine
LocationOceaniaGreen.svg
Main article: Oceanic cuisine
Oceanian cuisines include Australian cuisine, New Zealand cuisine, and the cuisines from many other islands or island groups throughout Oceania. Australian cuisine consists of immigrant Anglo-Celtic derived cuisine, and Bushfood prepared and eaten by native Aboriginal Australian peoples, and various newer Asian influences. New Zealand cuisine also consists of European inspired dishes, such as Pavlova, and native Maori cuisine. Across Oceania, staples include the Kumura (Sweet potato) and Taro, which was/is a staple from Papua New Guinea to the South Pacific. On most islands in the south pacific, fish are widely consumed because of the proximity to the ocean.

Bush Tucker (bush foods) harvested at Alice Springs Desert Park in Australia
Bush Tucker (bush foods) harvested at Alice Springs Desert Park in Australia

 
A Hāngi being prepared, a New Zealand Māori method of cooking food for special occasions using hot rocks buried in a pit oven.
A Hāngi being prepared, a New Zealand Māori method of cooking food for special occasions using hot rocks buried in a pit oven.

 
Samoan umu, an oven of hot rocks above ground
Samoan umu, an oven of hot rocks above ground

Cuisines of the Americas
Americas (orthographic projection).svg
Main articles: List of cuisines of the Americas and Native American cuisine
The cuisines of the Americas are found across North and South America, and are based on the cuisines of the countries from which the immigrant people came, primarily Europe. However, the traditional European cuisine has been adapted by the addition of many local and native ingredients, and many techniques have been added to traditional foods as well. Native American cuisine is prepared by indigenous populations across the continent, and its influences can be seen on multi-ethnic Latin American cuisine. Many staple foods eaten across the continent, such as corn (maize), beans, and potatoes have native origins. The regional cuisines are North American cuisine, Mexican cuisine, Central American cuisine, South American cuisine, and Caribbean cuisine.

Food is any substance consumed by an organism for nutritional support. Food is usually of plant, animal, or fungal origin, and contains essential nutrients, such as carbohydrates, fats, proteins, vitamins, or minerals. The substance is ingested by an organism and assimilated by the organism's cells to provide energy, maintain life, or stimulate growth. Different species of animals have different feeding behaviours that satisfy the needs of their metabolisms that have evolved to fill a specific ecological niche within specific geographical contexts.

Omnivorous humans are highly adaptable and have adapted to obtain food in many different ecosystems. The majority of the food energy required is supplied by the industrial food industry, which produces food with intensive agriculture and distributes it through complex food processing and food distribution systems. This system of conventional agriculture relies heavily on fossil fuels, which means that the food and agricultural system is one of the major contributors to climate change, accountable for as much as 37% of total greenhouse gas emissions.

The food system has significant impacts on a wide range of other social and political issues including: sustainability, biological diversity, economics, population growth, water supply, and food security. Food safety and security are monitored by international agencies like the International Association for Food Protection, World Resources Institute, World Food Programme, Food and Agriculture Organization, and International Food Information Council.

Definition and classification
Food is any substance consumed to provide nutritional support and energy to an organism. It can be raw, processed or formulated and is consumed orally by animals for growth, health or pleasure. Food is mainly composed of water, lipids, proteins and carbohydrates. Minerals (e.g. salts) and organic substances (e.g. vitamins) can also be found in food. Plants, algae and some microorganisms use photosynthesis to make their own food molecules. Water is found in many foods and has been defined as a food by itself. Water and fiber have low energy densities, or calories, while fat is the most energy dense component. Some inorganic (non-food) elements are also essential for plant and animal functioning.

Human food can be classified in various ways, either by related content or by how the food is processed. The number and composition of food groups can vary. Most systems include four basic groups that describe their origin and relative nutritional function: Vegetables and Fruit, Cereals and Bread, Dairy, and Meat. Studies that look into diet quality group food into whole grains/cereals, refined grains/cereals, vegetables, fruits, nuts, legumes, eggs, dairy products, fish, red meat, processed meat, and sugar-sweetened beverages. The Food and Agriculture Organization and World Health Organization use a system with nineteen food classifications: cereals, roots, pulses and nuts, milk, eggs, fish and shellfish, meat, insects, vegetables, fruits, fats and oils, sweets and sugars, spices and condiments, beverages, foods for nutritional uses, food additives, composite dishes and savoury snacks.

Food sources

A typical aquatic food web
In a given ecosystem, food forms a web of interlocking chains with primary producers at the bottom and apex predators at the top. Other aspects of the web include detrovores (that eat detritis) and decomposers (that break down dead organisms). Primary producers include algae, plants, bacteria and protists that acquire their energy from sunlight. Primary consumers are the herbivores that consume the plants, and secondary consumers are the carnivores that consume those herbivores. Some organisms, including most mammals and birds, diet consists of both animals and plants, and they are considered omnivores. The chain ends with the apex predators, the animals that have no known predators in its ecosystem. Humans are considered apex predators.

Humans are omnivores, finding sustenance in vegetables, fruits, cooked meat, milk, eggs, mushrooms and seaweed. Cereal grain is a staple food that provides more food energy worldwide than any other type of crop. Corn (maize), wheat, and rice account for 87% of all grain production worldwide. Just over half of the world's crops are used to feed humans (55 percent), with 36 percent grown as animal feed and 9 percent for biofuels. Fungi and bacteria are also used in the preparation of fermented foods like bread, wine, cheese and yogurt.

Sunlight and soil
Photosynthesis is the ultimate source of energy and food for nearly all life on earth. It is the main food source for plants, algae and certain bacteria. Without this, all organisms which depend on these organisms further up the food chain would be unable to exist, from coral to lions. Energy from the sun is absorbed and used to transform water and carbon dioxide in the air or soil into oxygen and glucose. The oxygen is then released, and the glucose stored as an energy reserve.

Plants also absorb important nutrients and minerals from the air, water and soil. Carbon, oxygen and hydrogen are absorbed from the air or water and are the basic nutrients needed for plant survival. The three main nutrients absorbed from the soil for plant growth are nitrogen, phosphorus and potassium, with other important nutrients including calcium, sulfur, magnesium, iron boron, chlorine, manganese, zinc, copper molybdenum and nickel.

Plants

Foods from plant sources
Plants as a food source are divided into seeds, fruits, vegetables, legumes, grains and nuts. Where plants fall within these categories can vary, with botanically described fruits such as the tomato, squash, pepper and eggplant or seeds like peas commonly considered vegetables. Food is a fruit if the part eaten is derived from the reproductive tissue, so seeds, nuts and grains are technically fruit. From a culinary perspective, fruits are generally considered the remains of botanically described fruits after grains, nuts, seeds and fruits used as vegetables are removed. Grains can be defined as seeds that humans eat or harvest, with cereal grains (oats, wheat, rice, corn, barley, rye, sorghum and millet) belonging to the Poaceae (grass) family and pulses coming from the Fabaceae (legume) family. Whole grains are foods that contain all the elements of the original seed (bran, germ, and endosperm). Nuts are dry fruits, distinguishable by their woody shell.

Fleshy fruits (distinguishable from dry fruits like grain, seeds and nuts) can be further classified as stone fruits (cherries and peaches), pome fruits (apples, pears), berries (blackberry, strawberry), citrus (oranges, lemon), melons (watermelon, cantaloupe), Mediterranean fruits (grapes, fig), tropical fruits (banana, pineapple). Vegetables refer to any other part of the plant that can be eaten, including roots, stems, leaves, flowers, bark or the entire plant itself. These include root vegetables (potatoes and carrots), bulbs (onion family), flowers (cauliflower and broccoli), leaf vegetables (spinach and lettuce) and stem vegetables (celery and asparagus).

Plants have high carbohydrate, protein and lipid content, with carbohydrates mainly in the form of starch, fructose, glucose and other sugars. Most vitamins are found from plant sources, with exceptions of vitamin D and vitamin B12. Minerals are also plentiful, although the presence of phytates can prevent their release. Fruit can consist of up to 90% water, contain high levels of simple sugars that contribute to their sweet taste, and have a high vitamin C content. Compared to fleshy fruit (excepting Bananas) vegetables are high in starch, potassium, dietary fiber, folate and vitamins and low in fat and calories. Grains are more starch based and nuts have a high protein, fibre, vitamin E and B content. Seeds are a good source of food for animals because they are abundant and contain fibre and healthful fats, such as omega-3 fats.

Animals that only eat plants are called herbivores, with those that mostly just eat fruits known as frugivores, leaves, while shoot eaters are folivores (pandas) and wood eaters termed xylophages (termites). Frugivores include a diverse range of species from annelids to elephants, chimpanzees and many birds. About 182 fish consume seeds or fruit. Animals (domesticated and wild) use as many types of grasses that have adapted to different locations as their main source of nutrients.

Humans only eat about 200 out of the worlds 400 000 plant species, despite at least half of them being edible. Most human plant-based food comes from maize, rice, and wheat. Plants can be processed into breads, pasta, cereals, juices and jams or raw ingredients such as sugar, herbs, spices and oils can be extracted. Oilseeds are pressed to produce rich oils – ⁣sunflower, flaxseed, rapeseed (including canola oil) and sesame.

Many plants and animals have coevolved in such a way that the fruit is a good source of nutrition to the animal who then excretes the seeds some distance away, allowing greater dispersal. Even seed predation can be mutually beneficial, as some seeds can survive the digestion process. Insects are major eaters of seeds, with ants being the only real seed dispersers. Birds, although being major dispersers, only rarely eat seeds as a source of food and can be identified by their thick beak that is used to crack open the seed coat. Mammals eat a more diverse range of seeds, as they are able to crush harder and larger seeds with their teeth.

Animals

Various raw meats
Animals are used as food either directly or indirectly. This includes meat, eggs, shellfish and dairy products like milk and cheese. They are an important source of protein and are considered complete proteins for human consumption as they contain all the essential amino acids that the human body needs. One 4-ounce (110 g) steak, chicken breast or pork chop contains about 30 grams of protein. One large egg has 7 grams of protein. A 4-ounce (110 g) serving of cheese has about 15 grams of protein. And 1 cup of milk has about 8 grams of protein. Other nutrients found in animal products include calories, fat, essential vitamins (including B12) and minerals (including zinc, iron, calcium, magnesium).

Food products produced by animals include milk produced by mammary glands, which in many cultures is drunk or processed into dairy products (cheese, butter, etc.). Eggs laid by birds and other animals are eaten and bees produce honey, a reduced nectar from flowers that is used as a popular sweetener in many cultures. Some cultures consume blood, such as in blood sausage, as a thickener for sauces, or in a cured, salted form for times of food scarcity, and others use blood in stews such as jugged hare.

Taste
Main article: Taste
Animals, specifically humans, typically have five different types of tastes: sweet, sour, salty, bitter, and umami. The differing tastes are important for distinguishing between foods that are nutritionally beneficial and those which may contain harmful toxins. As animals have evolved, the tastes that provide the most energy are the most pleasant to eat while others are not enjoyable, although humans in particular can acquire a preference for some substances which are initially unenjoyable. Water, while important for survival, has no taste.

Sweetness is almost always caused by a type of simple sugar such as glucose or fructose, or disaccharides such as sucrose, a molecule combining glucose and fructose. Sourness is caused by acids, such as vinegar in alcoholic beverages. Sour foods include citrus, specifically lemons and limes. Sour is evolutionarily significant as it can signal a food that may have gone rancid due to bacteria. Saltiness is the taste of alkali metal ions such as sodium and potassium. It is found in almost every food in low to moderate proportions to enhance flavor. Bitter taste is a sensation considered unpleasant characterised by having a sharp, pungent taste. Unsweetened dark chocolate, caffeine, lemon rind, and some types of fruit are known to be bitter. Umami, commonly described as savory, is a marker of proteins and characteristic of broths and cooked meats. Foods that have a strong umami flavor include cheese, meat and mushrooms.


Catfish have millions of taste buds covering their entire body.
While most animals taste buds are located in their mouth, some insects taste receptors are located on their legs and some fish have taste buds along their entire body. Dogs, cats and birds have relatively few taste buds (chickens have about 30), adult humans have between 2000 and 4000, while catfish can have more than a million. Herbivores generally have more than carnivores as they need to tell which plants may be poisonous. Not all mammals share the same tastes: some rodents can taste starch, cats cannot taste sweetness, and several carnivores (including hyenas, dolphins, and sea lions) have lost the ability to sense up to four of the five taste modalities found in humans.

Digestion
Main article: Digestion
Food is broken into nutrient components through digestive process. Proper digestion consists of mechanical processes (chewing, peristalsis) and chemical processes (digestive enzymes and microorganisms). The digestive systems of herbivores and carnivores are very different as plant matter is harder to digest. Carnivores mouths are designed for tearing and biting compared to the grinding action found in herbivores. Herbivores however have comparatively longer digestive tracts and larger stomachs to aid in digesting the cellulose in plants.

Animals are multicellular, eukaryotic organisms in the biological kingdom Animalia. With few exceptions, animals consume organic material, breathe oxygen, are able to move, can reproduce sexually, and grow from a hollow sphere of cells, the blastula, during embryonic development. As of 2022, 2.16 million living animal species have been described—of which around 1.05 million are insects, over 85,000 are molluscs, and around 65,000 are vertebrates—but it has been estimated there are around 7.77 million animal species in total. Animals range in length from 8.5 micrometres (0.00033 in) to 33.6 metres (110 ft). They have complex interactions with each other and their environments, forming intricate food webs. The scientific study of animals is known as zoology.

Most living animal species are in Bilateria, a clade whose members have a bilaterally symmetric body plan. The Bilateria include the protostomes, containing animals such as nematodes, arthropods, flatworms, annelids and molluscs, and the deuterostomes, containing the echinoderms and the chordates, the latter including the vertebrates. Life forms interpreted as early animals were present in the Ediacaran biota of the late Precambrian. Many modern animal phyla became clearly established in the fossil record as marine species during the Cambrian explosion, which began around 539 million years ago. 6,331 groups of genes common to all living animals have been identified; these may have arisen from a single common ancestor that lived 650 million years ago.

Historically, Aristotle divided animals into those with blood and those without. Carl Linnaeus created the first hierarchical biological classification for animals in 1758 with his Systema Naturae, which Jean-Baptiste Lamarck expanded into 14 phyla by 1809. In 1874, Ernst Haeckel divided the animal kingdom into the multicellular Metazoa (now synonymous with Animalia) and the Protozoa, single-celled organisms no longer considered animals. In modern times, the biological classification of animals relies on advanced techniques, such as molecular phylogenetics, which are effective at demonstrating the evolutionary relationships between taxa.

Humans make use of many animal species, such as for food (including meat, milk, and eggs), for materials (such as leather and wool), as pets, and as working animals including for transport. Dogs have been used in hunting, as have birds of prey, while many terrestrial and aquatic animals were hunted for sports. Nonhuman animals have appeared in art from the earliest times and are featured in mythology and religion.

Etymology
The word "animal" comes from the Latin animalis, meaning 'having breath', 'having soul' or 'living being'. The biological definition includes all members of the kingdom Animalia. In colloquial usage, the term animal is often used to refer only to nonhuman animals. The term "metazoa" is derived from the Ancient Greek μετα (meta, meaning "later") and ζῷᾰ (zōia, plural of ζῷον zōion, meaning animal).

Characteristics

Animals are unique in having the ball of cells of the early embryo (1) develop into a hollow ball or blastula (2).
Animals have several characteristics that set them apart from other living things. Animals are eukaryotic and multicellular. Unlike plants and algae, which produce their own nutrients, animals are heterotrophic, feeding on organic material and digesting it internally. With very few exceptions, animals respire aerobically.[a] All animals are motile (able to spontaneously move their bodies) during at least part of their life cycle, but some animals, such as sponges, corals, mussels, and barnacles, later become sessile. The blastula is a stage in embryonic development that is unique to animals, allowing cells to be differentiated into specialised tissues and organs.

Structure
All animals are composed of cells, surrounded by a characteristic extracellular matrix composed of collagen and elastic glycoproteins. During development, the animal extracellular matrix forms a relatively flexible framework upon which cells can move about and be reorganised, making the formation of complex structures possible. This may be calcified, forming structures such as shells, bones, and spicules. In contrast, the cells of other multicellular organisms (primarily algae, plants, and fungi) are held in place by cell walls, and so develop by progressive growth. Animal cells uniquely possess the cell junctions called tight junctions, gap junctions, and desmosomes.

With few exceptions—in particular, the sponges and placozoans—animal bodies are differentiated into tissues. These include muscles, which enable locomotion, and nerve tissues, which transmit signals and coordinate the body. Typically, there is also an internal digestive chamber with either one opening (in Ctenophora, Cnidaria, and flatworms) or two openings (in most bilaterians).

Reproduction and development
See also: Sexual reproduction § Animals, and Asexual reproduction § Examples in animals

Sexual reproduction is nearly universal in animals, such as these dragonflies.
Nearly all animals make use of some form of sexual reproduction. They produce haploid gametes by meiosis; the smaller, motile gametes are spermatozoa and the larger, non-motile gametes are ova. These fuse to form zygotes, which develop via mitosis into a hollow sphere, called a blastula. In sponges, blastula larvae swim to a new location, attach to the seabed, and develop into a new sponge. In most other groups, the blastula undergoes more complicated rearrangement. It first invaginates to form a gastrula with a digestive chamber and two separate germ layers, an external ectoderm and an internal endoderm. In most cases, a third germ layer, the mesoderm, also develops between them. These germ layers then differentiate to form tissues and organs.

Repeated instances of mating with a close relative during sexual reproduction generally leads to inbreeding depression within a population due to the increased prevalence of harmful recessive traits. Animals have evolved numerous mechanisms for avoiding close inbreeding.

Some animals are capable of asexual reproduction, which often results in a genetic clone of the parent. This may take place through fragmentation; budding, such as in Hydra and other cnidarians; or parthenogenesis, where fertile eggs are produced without mating, such as in aphids.

Ecology

Predators, such as this ultramarine flycatcher (Ficedula superciliaris), feed on other animals.
Animals are categorised into ecological groups depending on how they obtain or consume organic material, including carnivores, herbivores, omnivores, detritivores, and parasites. Interactions between animals form complex food webs. In carnivorous or omnivorous species, predation is a consumer–resource interaction where a predator feeds on another organism (called its prey). Selective pressures imposed on one another lead to an evolutionary arms race between predator and prey, resulting in various anti-predator adaptations. Almost all multicellular predators are animals. Some consumers use multiple methods; for example, in parasitoid wasps, the larvae feed on the hosts' living tissues, killing them in the process, but the adults primarily consume nectar from flowers. Other animals may have very specific feeding behaviours, such as hawksbill sea turtles primarily eating sponges.


Hydrothermal vent mussels and shrimps
Most animals rely on the biomass and energy produced by plants through photosynthesis. Herbivores eat plant material directly, while carnivores, and other animals on higher trophic levels typically acquire it indirectly by eating other animals. Animals oxidize carbohydrates, lipids, proteins, and other biomolecules, which allows the animal to grow and to sustain biological processes such as locomotion. Animals living close to hydrothermal vents and cold seeps on the dark sea floor consume organic matter of archaea and bacteria produced in these locations through chemosynthesis (by oxidizing inorganic compounds, such as hydrogen sulfide).

Animals originally evolved in the sea. Lineages of arthropods colonised land around the same time as land plants, probably between 510 and 471 million years ago during the Late Cambrian or Early Ordovician. Vertebrates such as the lobe-finned fish Tiktaalik started to move on to land in the late Devonian, about 375 million years ago. Animals occupy virtually all of earth's habitats and microhabitats, including salt water, hydrothermal vents, fresh water, hot springs, swamps, forests, pastures, deserts, air, and the interiors of other animals, plants, fungi, and rocks. Animals are however not particularly heat tolerant; very few of them can survive at constant temperatures above 50 °C (122 °F). Only very few species of animals (mostly nematodes) inhabit the most extreme cold deserts of continental Antarctica.

Diversity
Size
Further information: Largest organisms and Smallest organisms

The blue whale is the largest animal that has ever lived.
The blue whale (Balaenoptera musculus) is the largest animal that has ever lived, weighing up to 190 tonnes and measuring up to 33.6 metres (110 ft) long. The largest extant terrestrial animal is the African bush elephant (Loxodonta africana), weighing up to 12.25 tonnes and measuring up to 10.67 metres (35.0 ft) long. The largest terrestrial animals that ever lived were titanosaur sauropod dinosaurs such as Argentinosaurus, which may have weighed as much as 73 tonnes, and Supersaurus which may have reached 39 meters. Several animals are microscopic; some Myxozoa (obligate parasites within the Cnidaria) never grow larger than 20 µm, and one of the smallest species (Myxobolus shekel) is no more than 8.5 µm when fully grown.

Numbers and habitats
The following table lists estimated numbers of described extant species for all the animal groups, along with their principal habitats (terrestrial, fresh water, and marine), and free-living or parasitic ways of life. Species estimates shown here are based on numbers described scientifically; much larger estimates have been calculated based on various means of prediction, and these can vary wildly. For instance, around 25,000–27,000 species of nematodes have been described, while published estimates of the total number of nematode species include 10,000–20,000; 500,000; 10 million; and 100 million. Using patterns within the taxonomic hierarchy, the total number of animal species—including those not yet described—was calculated to be about 7.77 million in 2011.[b]

Phylum	Example	Described species	Land	Sea	Freshwater	Free-living	Parasitic
Arthropoda	wasp	1,257,000	1,000,000
(insects)	>40,000
(Malac-
ostraca)	94,000	Yes	>45,000[c]
Mollusca	snail	85,000
107,000	35,000	60,000	5,000
12,000	Yes	>5,600
Chordata	green spotted frog facing right	>70,000	23,000	13,000	18,000
9,000	Yes	40
(catfish)
Platyhelminthes	Pseudoceros dimidiatus.jpg	29,500	Yes	Yes	1,300	Yes
3,000–6,500

>40,000
4,000–25,000

Nematoda	CelegansGoldsteinLabUNC.jpg	25,000	Yes (soil)	4,000	2,000	11,000	14,000
Annelida	Nerr0328.jpg	17,000	Yes (soil)	Yes	1,750	Yes	400
Cnidaria	Table coral	16,000		Yes	Yes (few)	Yes	>1,350
(Myxozoa)
Porifera	A colourful Sponge on the Fathom.jpg	10,800		Yes	200–300	Yes	Yes
Echinodermata	Starfish, Caswell Bay - geograph.org.uk - 409413.jpg	7,500		7,500		Yes	
Bryozoa	Bryozoan at Ponta do Ouro, Mozambique (6654415783).jpg	6,000		Yes	60–80	Yes	
Rotifera	20090730 020239 Rotifer.jpg	2,000		>400	2,000	Yes	
Nemertea	Némerte.jpg	1,350		Yes	Yes	Yes	
Tardigrada	Tardigrade (50594282802).jpg	1,335	Yes
(moist plants)	Yes	Yes	Yes	
Gastrotricha	Paradasys subterraneus.jpg	794		Yes	Yes	Yes	
Xenacoelomorpha	Proporus sp.png	430		Yes		Yes	
Nematomorpha	Nematomorpha Somiedo.JPG	354	Yes
(moist places)	Yes
(one genus)	Yes	Yes
(as adults)	Yes
(as juveniles)
Brachiopoda	Liospiriferina rostrata Noir.jpg	396
(30,000 extinct)		Yes		Yes	
Kinorhyncha	Cephalorhyncha flosculosa zoomed.jpg	196		Yes (mud)		Yes	
Ctenophora	Bathocyroe fosteri.jpg	187		Yes		Yes	
Onychophora	Unidentified velvet worm.jpg	187	Yes			Yes	
Chaetognatha	Chaetoblack.png	186		Yes		Yes	
Entoprocta	Barentsia laxa 1498966.png	172		Yes	Yes
Yes	
Hemichordata	Torq ventral acorn worm.tif	126		Yes		Yes	
Rhombozoa	Dicyema japonicum.png	107					Yes
Gnathostomulida	Gnathostomula paradoxa Sylt.tif	97		Yes (sand)		Yes	
Loricifera	Pliciloricus enigmatus.jpg	30		Yes (sand)		Yes	
Orthonectida	EB1911 Mesozoa - Rhopalura giardii.jpg	29					Yes
Priapulida	Halicryptus spinulosus 1.JPEG	20		Yes		Yes	
Phoronida	Phoronis ijimai 99523588.jpg	16		Yes		Yes	
Placozoa	Trichoplax adhaerens photograph.png	4		Yes		Yes	
Cycliophora	Feeding stage and attached Prometheus larva of Symbion pandora.jpg	2		Yes		Yes	
Micrognathozoa	Limnognathia maerski youtube.png	1		Yes (sand)		Yes	
Total number of described extant species as of 2013: 1,525,728
Evolutionary origin
Further information: Urmetazoan
Animals are found as long ago as the Ediacaran biota, towards the end of the Precambrian, and possibly somewhat earlier. It had long been doubted whether these life-forms included animals, but the discovery of the animal lipid cholesterol in fossils of Dickinsonia establishes their nature. Animals are thought to have originated under low-oxygen conditions, suggesting that they were capable of living entirely by anaerobic respiration, but as they became specialized for aerobic metabolism they became fully dependent on oxygen in their environments.

Many animal phyla first appear in the fossil record during the Cambrian explosion, starting about 539 million years ago, in beds such as the Burgess shale. Extant phyla in these rocks include molluscs, brachiopods, onychophorans, tardigrades, arthropods, echinoderms and hemichordates, along with numerous now-extinct forms such as the predatory Anomalocaris. The apparent suddenness of the event may however be an artefact of the fossil record, rather than showing that all these animals appeared simultaneously. That view is supported by the discovery of Auroralumina attenboroughii, the earliest known Ediacaran crown-group cnidarian (557–562 mya, some 20 million years before the Cambrian explosion) from Charnwood Forest, England. It is thought to be one of the earliest predators, catching small prey with its nematocysts as modern cnidarians do.

Some palaeontologists have suggested that animals appeared much earlier than the Cambrian explosion, possibly as early as 1 billion years ago. Early fossils that might represent animals appear for example in the 665-million-year-old rocks of the Trezona Formation of South Australia. These fossils are interpreted as most probably being early sponges. Trace fossils such as tracks and burrows found in the Tonian period (from 1 gya) may indicate the presence of triploblastic worm-like animals, roughly as large (about 5 mm wide) and complex as earthworms. However, similar tracks are produced today by the giant single-celled protist Gromia sphaerica, so the Tonian trace fossils may not indicate early animal evolution. Around the same time, the layered mats of microorganisms called stromatolites decreased in diversity, perhaps due to grazing by newly evolved animals. Objects such as sediment-filled tubes that resemble trace fossils of the burrows of wormlike animals have been found in 1.2 gya rocks in North America, in 1.5 gya rocks in Australia and North America, and in 1.7 gya rocks in Australia. Their interpretation as having an animal origin is disputed, as they might be water-escape or other structures.

The Francevillian biota contains the earliest Eukaryotes known (2.1 ga).
The Francevillian biota contains the earliest Eukaryotes known (2.1 ga).

 
Dickinsonia costata from the Ediacaran biota (c. 635–542 mya) is one of the earliest animal species known.
Dickinsonia costata from the Ediacaran biota (c. 635–542 mya) is one of the earliest animal species known.

 
Auroralumina attenboroughii, an Ediacaran predator (c. 560 mya)
Auroralumina attenboroughii, an Ediacaran predator (c. 560 mya)

 
Anomalocaris canadensis is one of the many animal species that emerged in the Cambrian explosion, starting some 539 mya, and found in the fossil beds of the Burgess shale.
Anomalocaris canadensis is one of the many animal species that emerged in the Cambrian explosion, starting some 539 mya, and found in the fossil beds of the Burgess shale.

Phylogeny
Further information: Lists of animals
Animals are monophyletic, meaning they are derived from a common ancestor. Animals are sister to the Choanoflagellata, with which they form the Choanozoa. The most basal animals, the Porifera, Ctenophora, Cnidaria, and Placozoa, have body plans that lack bilateral symmetry. Their relationships are still disputed; the sister group to all other animals could be the Porifera or the Ctenophora, both of which lack hox genes, important in body plan development.

These genes are found in the Placozoa and the higher animals, the Bilateria. 6,331 groups of genes common to all living animals have been identified; these may have arisen from a single common ancestor that lived 650 million years ago in the Precambrian. 25 of these are novel core gene groups, found only in animals; of those, 8 are for essential components of the Wnt and TGF-beta signalling pathways which may have enabled animals to become multicellular by providing a pattern for the body's system of axes (in three dimensions), and another 7 are for transcription factors including homeodomain proteins involved in the control of development.

The phylogenetic tree indicates approximately how many millions of years ago (mya) the lineages split.

Choanozoa	
Choanoflagellata Desmarella moniliformis.jpg

Animalia	
Parazoa	
Porifera Reef3859 - Flickr - NOAA Photo Library.jpg

Eumetazoa	
Ctenophora Comb jelly.jpg

ParaHoxozoa	
Placozoa Trichoplax adhaerens photograph.png

Cnidaria Cauliflour Jellyfish, Cephea cephea at Marsa Shouna, Red Sea, Egypt SCUBA.jpg

Bilateria	
Xenacoelomorpha Proporus sp.png

Nephrozoa	
Deuterostomia	
Chordata Common carp (white background).jpg

Ambulacraria Portugal 20140812-DSC01434 (21371237591).jpg

Protostomia	
Ecdysozoa	
Scalidophora Priapulus caudatus 20150625.jpg

Panarthropoda Long nosed weevil edit.jpg

Nematoida CelegansGoldsteinLabUNC 2.jpg

>529 mya
Spiralia	
Gnathifera	
Chaetognatha Chaetoblack 3.png

Gnathostomulida Gnathostomula paradoxa Sylt.tif

Micrognathozoa Limnognathia maerski youtube.png

Rotifera (inc. Acanthocephala) Bdelloid Rotifer (cropped).jpg

Platytrochozoa	
Rouphozoa	
Gastrotricha Paradasys subterraneus.jpg

Platyhelminthes Sorocelis reticulosa.jpg

Lophotrochozoa	
Annelida Polychaeta (no) 2.jpg

Mollusca Grapevinesnail 01.jpg

Nemertea Amphiporus angulatus.png

Lophophorata	
Bryozoa Bryozoan at Ponta do Ouro, Mozambique (6654415783).jpg

Brachiozoa	
Brachiopoda Liospiriferina rostrata Noir.jpg

Phoronida Phoronis ijimai 99523588.jpg

550 mya
580 mya
610 mya
650 mya
Triploblasts
680 mya
760 mya
950 mya

Non-bilateria

Non-bilaterians include sponges (centre) and corals (background).
Several animal phyla lack bilateral symmetry. Among these, the sponges (Porifera) probably diverged first, representing the oldest animal phylum. Sponges lack the complex organization found in most other animal phyla; their cells are differentiated, but in most cases not organised into distinct tissues. They typically feed by drawing in water through pores.

The Ctenophora (comb jellies) and Cnidaria (which includes jellyfish, sea anemones, and corals) are radially symmetric and have digestive chambers with a single opening, which serves as both mouth and anus. They are sometimes placed together in the group Coelenterata because of common traits, not because of close relationships. Animals in both phyla have distinct tissues, but these are not organised into organs. They are diploblastic, having only two main germ layers, ectoderm and endoderm. The tiny placozoans are similar, but they do not have a permanent digestive chamber.

Bilateria
Main articles: Bilateria and Symmetry (biology) § Bilateral symmetry

Idealised bilaterian body plan.[d] With an elongated body and a direction of movement the animal has head and tail ends. Sense organs and mouth form the basis of the head. Opposed circular and longitudinal muscles enable peristaltic motion.
The remaining animals, the great majority—comprising some 29 phyla and over a million species—form a clade, the Bilateria, which have a bilaterally symmetric body plan. The Bilateria are triploblastic, with three well-developed germ layers, and their tissues form distinct organs. The digestive chamber has two openings, a mouth and an anus, and there is an internal body cavity, a coelom or pseudocoelom. These animals have a head end (anterior) and a tail end (posterior), a back (dorsal) surface and a belly (ventral) surface, and a left and a right side.

Having a front end means that this part of the body encounters stimuli, such as food, favouring cephalisation, the development of a head with sense organs and a mouth. Many bilaterians have a combination of circular muscles that constrict the body, making it longer, and an opposing set of longitudinal muscles, that shorten the body; these enable soft-bodied animals with a hydrostatic skeleton to move by peristalsis. They also have a gut that extends through the basically cylindrical body from mouth to anus. Many bilaterian phyla have primary larvae which swim with cilia and have an apical organ containing sensory cells. However, over evolutionary time, descendant spaces have evolved which have lost one or more of each of these characteristics. For example, adult echinoderms are radially symmetric (unlike their larvae), while some parasitic worms have extremely simplified body structures.

Genetic studies have considerably changed zoologists' understanding of the relationships within the Bilateria. Most appear to belong to two major lineages, the protostomes and the deuterostomes. The basalmost bilaterians are the Xenacoelomorpha.

Protostomes and deuterostomes
Further information: Embryological origins of the mouth and anus
Main articles: Protostome and Deuterostome

The bilaterian gut develops in two ways. In many protostomes, the blastopore develops into the mouth, while in deuterostomes it becomes the anus.
Protostomes and deuterostomes differ in several ways. Early in development, deuterostome embryos undergo radial cleavage during cell division, while many protostomes (the Spiralia) undergo spiral cleavage. Animals from both groups possess a complete digestive tract, but in protostomes the first opening of the embryonic gut develops into the mouth, and the anus forms secondarily. In deuterostomes, the anus forms first while the mouth develops secondarily. Most protostomes have schizocoelous development, where cells simply fill in the interior of the gastrula to form the mesoderm. In deuterostomes, the mesoderm forms by enterocoelic pouching, through invagination of the endoderm.

The main deuterostome phyla are the Echinodermata and the Chordata. Echinoderms are exclusively marine and include starfish, sea urchins, and sea cucumbers. The chordates are dominated by the vertebrates (animals with backbones), which consist of fishes, amphibians, reptiles, birds, and mammals. The deuterostomes also include the Hemichordata (acorn worms).

Ecdysozoa
Main article: Ecdysozoa

Ecdysis: a dragonfly has emerged from its dry exuviae and is expanding its wings. Like other arthropods, its body is divided into segments.
The Ecdysozoa are protostomes, named after their shared trait of ecdysis, growth by moulting. They include the largest animal phylum, the Arthropoda, which contains insects, spiders, crabs, and their kin. All of these have a body divided into repeating segments, typically with paired appendages. Two smaller phyla, the Onychophora and Tardigrada, are close relatives of the arthropods and share these traits. The ecdysozoans also include the Nematoda or roundworms, perhaps the second largest animal phylum. Roundworms are typically microscopic, and occur in nearly every environment where there is water; some are important parasites. Smaller phyla related to them are the Nematomorpha or horsehair worms, and the Kinorhyncha, Priapulida, and Loricifera. These groups have a reduced coelom, called a pseudocoelom.

Spiralia
Main article: Spiralia

Spiral cleavage in a sea snail embryo
The Spiralia are a large group of protostomes that develop by spiral cleavage in the early embryo. The Spiralia's phylogeny has been disputed, but it contains a large clade, the superphylum Lophotrochozoa, and smaller groups of phyla such as the Rouphozoa which includes the gastrotrichs and the flatworms. All of these are grouped as the Platytrochozoa, which has a sister group, the Gnathifera, which includes the rotifers.

The Lophotrochozoa includes the molluscs, annelids, brachiopods, nemerteans, bryozoa and entoprocts. The molluscs, the second-largest animal phylum by number of described species, includes snails, clams, and squids, while the annelids are the segmented worms, such as earthworms, lugworms, and leeches. These two groups have long been considered close relatives because they share trochophore larvae.

History of classification
Further information: Taxonomy (biology), History of zoology (through 1859), and History of zoology since 1859

Jean-Baptiste de Lamarck led the creation of a modern classification of invertebrates, breaking up Linnaeus's "Vermes" into 9 phyla by 1809.
In the classical era, Aristotle divided animals,[e] based on his own observations, into those with blood (roughly, the vertebrates) and those without. The animals were then arranged on a scale from man (with blood, 2 legs, rational soul) down through the live-bearing tetrapods (with blood, 4 legs, sensitive soul) and other groups such as crustaceans (no blood, many legs, sensitive soul) down to spontaneously generating creatures like sponges (no blood, no legs, vegetable soul). Aristotle was uncertain whether sponges were animals, which in his system ought to have sensation, appetite, and locomotion, or plants, which did not: he knew that sponges could sense touch, and would contract if about to be pulled off their rocks, but that they were rooted like plants and never moved about.

In 1758, Carl Linnaeus created the first hierarchical classification in his Systema Naturae. In his original scheme, the animals were one of three kingdoms, divided into the classes of Vermes, Insecta, Pisces, Amphibia, Aves, and Mammalia. Since then the last four have all been subsumed into a single phylum, the Chordata, while his Insecta (which included the crustaceans and arachnids) and Vermes have been renamed or broken up. The process was begun in 1793 by Jean-Baptiste de Lamarck, who called the Vermes une espèce de chaos (a chaotic mess)[f] and split the group into three new phyla: worms, echinoderms, and polyps (which contained corals and jellyfish). By 1809, in his Philosophie Zoologique, Lamarck had created 9 phyla apart from vertebrates (where he still had 4 phyla: mammals, birds, reptiles, and fish) and molluscs, namely cirripedes, annelids, crustaceans, arachnids, insects, worms, radiates, polyps, and infusorians.

In his 1817 Le Règne Animal, Georges Cuvier used comparative anatomy to group the animals into four embranchements ("branches" with different body plans, roughly corresponding to phyla), namely vertebrates, molluscs, articulated animals (arthropods and annelids), and zoophytes (radiata) (echinoderms, cnidaria and other forms). This division into four was followed by the embryologist Karl Ernst von Baer in 1828, the zoologist Louis Agassiz in 1857, and the comparative anatomist Richard Owen in 1860.

In 1874, Ernst Haeckel divided the animal kingdom into two subkingdoms: Metazoa (multicellular animals, with five phyla: coelenterates, echinoderms, articulates, molluscs, and vertebrates) and Protozoa (single-celled animals), including a sixth animal phylum, sponges. The protozoa were later moved to the former kingdom Protista, leaving only the Metazoa as a synonym of Animalia.

In human culture
Practical uses
Main article: Animals in culture

Sides of beef in a slaughterhouse
The human population exploits a large number of other animal species for food, both of domesticated livestock species in animal husbandry and, mainly at sea, by hunting wild species. Marine fish of many species are caught commercially for food. A smaller number of species are farmed commercially. Humans and their livestock make up more than 90% of the biomass of all terrestrial vertebrates, and almost as much as all insects combined.

Invertebrates including cephalopods, crustaceans, and bivalve or gastropod molluscs are hunted or farmed for food. Chickens, cattle, sheep, pigs, and other animals are raised as livestock for meat across the world. Animal fibres such as wool are used to make textiles, while animal sinews have been used as lashings and bindings, and leather is widely used to make shoes and other items. Animals have been hunted and farmed for their fur to make items such as coats and hats. Dyestuffs including carmine (cochineal), shellac, and kermes have been made from the bodies of insects. Working animals including cattle and horses have been used for work and transport from the first days of agriculture.

Animals such as the fruit fly Drosophila melanogaster serve a major role in science as experimental models. Animals have been used to create vaccines since their discovery in the 18th century. Some medicines such as the cancer drug trabectedin are based on toxins or other molecules of animal origin.


A gun dog retrieving a duck during a hunt
People have used hunting dogs to help chase down and retrieve animals, and birds of prey to catch birds and mammals, while tethered cormorants have been used to catch fish. Poison dart frogs have been used to poison the tips of blowpipe darts. A wide variety of animals are kept as pets, from invertebrates such as tarantulas and octopuses, insects including praying mantises, reptiles such as snakes and chameleons, and birds including canaries, parakeets, and parrots all finding a place. However, the most kept pet species are mammals, namely dogs, cats, and rabbits. There is a tension between the role of animals as companions to humans, and their existence as individuals with rights of their own. A wide variety of terrestrial and aquatic animals are hunted for sport.

Symbolic uses

Artistic vision: Still Life with Lobster and Oysters by Alexander Coosemans, c. 1660
Animals have been the subjects of art from the earliest times, both historical, as in Ancient Egypt, and prehistoric, as in the cave paintings at Lascaux. Major animal paintings include Albrecht Dürer's 1515 The Rhinoceros, and George Stubbs's c. 1762 horse portrait Whistlejacket. Insects, birds and mammals play roles in literature and film, such as in giant bug movies.

Animals including insects and mammals feature in mythology and religion. In both Japan and Europe, a butterfly was seen as the personification of a person's soul, while the scarab beetle was sacred in ancient Egypt. Among the mammals, cattle, deer, horses, lions, bats, bears, and wolves are the subjects of myths and worship. The signs of the Western and Chinese zodiacs are based on animals.

A country is a distinct part of the world, such as a state, nation, or other political entity. It may be a sovereign state or make up one part of a larger state. For example, the country of Japan is an independent, sovereign state, while the country of Wales is a component of a multi-part sovereign state, the United Kingdom. A country may be a historically sovereign area (such as Korea), a currently sovereign territory with a unified government (such as Senegal), or a non-sovereign geographic region associated with certain distinct political, ethnic, or cultural characteristics (such as the Basque Country).

The definition and usage of the word "country" is flexible and has changed over time. The Economist wrote in 2010 that "any attempt to find a clear definition of a country soon runs into a thicket of exceptions and anomalies." Most sovereign states, but not all countries, are members of the United Nations.

The largest country by area is Russia, while the smallest is the microstate Vatican City. The most populous is China, while Vatican City is also the least populous.

Etymology
The word country comes from Old French contrée, which derives from Vulgar Latin (terra) contrata ("(land) lying opposite"; "(land) spread before"), derived from contra ("against, opposite"). It most likely entered the English language after the Franco-Norman invasion during the 11th century.[better source needed]

Definition of a country
In English
In English the word has increasingly become associated with political divisions, so that one sense, associated with the indefinite article – "a country" – is now frequently applied as a synonym for a state or a former sovereign state. It may also be used as a synonym for "nation". Taking as examples Canada, Sri Lanka, and Yugoslavia, cultural anthropologist Clifford Geertz wrote in 1997 that "it is clear that the relationships between 'country' and 'nation' are so different from one [place] to the next as to be impossible to fold into a dichotomous opposition as they are into a promiscuous fusion."

Areas much smaller than a political state may be referred to as countries, such as the West Country in England, "big sky country" (used in various contexts of the American West), "coal country" (used to describe coal-mining regions in several sovereign states) and many other terms.[better source needed] The word "country" is also used for the sense of native sovereign territory, such as the widespread use of Indian country in the United States. The term "country" in English may also be wielded to describe rural areas, or used in the form "countryside." Raymond Williams, a Welsh scholar, wrote in 1975:

'Country' and 'city' are very powerful words, and this is not surprising when we remember how much they seem to stand for in the experience of human communities. In English, 'country' is both a nation and a part of a 'land'; 'the country' can be the whole society or its rural area. In the long history of human settlements, this connection between the land from which directly or indirectly we all get our living and the achievements of human society has been deeply known.

The unclear definition of "country" in modern English was further commented upon by philosopher Simon Keller:

Often, a country is presumed to be identical with a collection of citizens. Sometimes, people say that a country is a project, or an idea, or an ideal. Occasionally, philosophers entertain more metaphysically ambitious pictures, suggesting that a country is an organic entity with its own independent life and character, or that a country is an autonomous agent, just like you or me. Such claims are rarely explained or defended, however, and it is not clear how they should be assessed. We attribute so many different kinds of properties to countries, speaking as though a country can feature wheat fields waving or be girt by sea, can have a founding date and be democratic and free, can be English speaking, culturally diverse, war torn or Islamic.

— New Waves In Political Philosophy, "Making Nonsense of Loyalty to Country", page 96
Melissa Lucashenko, an Aboriginal Australian writer, expressed the difficulty of defining "country" in a 2005 essay, "Unsettlement":
...What is this thing country? What does country mean? ... I spoke with others who said country meant Home, but who added the caveat that Home resided in people rather than places – a kind of portable Country... I tried to tease out some ways in which non-Indigenous people have understood country. I made categories: Country as Economy. Country as Geography. Country as Society. Country as Myth. Country as History. For all that I walked, slept, breathed and dreamed Country, the language still would not come.

In other languages
The equivalent terms in various Romance languages (e.g. the French pays) have not carried the process of being identified with sovereign political states as far as the English country. These terms are derived from the Roman term pagus, which continued to be used in the Middle Ages for small geographical areas similar to the size of English counties.[citation needed] In many European countries, the words are used for sub-divisions of the national territory, as in the German Bundesländer, as well as a less formal term for a sovereign state. France has very many "pays" that are officially recognized at some level and are either natural regions, like the Pays de Bray, or reflect old political or economic entities, like the Pays de la Loire.[citation needed]

A version of "country" can be found in modern French as contrée, derived from the Old French word cuntrée,[better source needed] that is used similarly to the word pays to define non-state regions, but can also be used to describe a political state in some particular cases. The modern Italian contrada is a word with its meaning varying locally, but usually meaning a ward or similar small division of a town, or a village or hamlet in the countryside.[citation needed]

Identification
Further information: National symbol
Symbols of a country may incorporate cultural, religious or political symbols of any nation that the country includes. Many categories of symbols can be seen in flags, coats of arms, or seals.

Name
See also: List of country-name etymologies
Map of Pacific Island countries identified by their two-letter ISO country codes
A number of non-sovereign entities nevertheless have country codes, such as PF (French Polynesia) and TK (Tokelau)
Most countries have a long name and a short name. The long name is typically used in formal contexts and often describes the country's form of government. The short name is the country's common name by which it is typically identified.[better source needed] The names of most countries are derived from a feature of the land, the name of a historical tribe or person, or a directional description.[better source needed] The International Organization for Standardization maintains a list of country codes as part of ISO 3166 to designate each country with a two-letter country code. The name of a country can hold cultural and diplomatic significance. Upper Volta changed its name to Burkina Faso to reflect the end of French colonization, and the name of North Macedonia was disputed for years due to a conflict with the similarly named Macedonia region in Greece.

Flags
Originally, flags representing a country would generally be the personal flag of its rulers; however, over time, the practice of using personal banners as flags of places was abandoned in favor of flags that had some significance to the nation, often its patron saint. Early examples of these were the maritime republics such as Genoa which could be said to have a national flag as early as the 12th century. However, these were still mostly used in the context of marine identification.[citation needed]

Although some flags date back earlier, widespread use of flags outside of military or naval context begins only with the rise of the idea of the nation state at the end of the 18th century and particularly are a product of the Age of Revolution. Revolutions such as those in France and America called for people to begin thinking of themselves as citizens as opposed to subjects under a king, and thus necessitated flags that represented the collective citizenry, not just the power and right of a ruling family. With nationalism becoming common across Europe in the 19th century, national flags came to represent most of the states of Europe. Flags also began fostering a sense of unity between different peoples, such as the Union Jack representing a union between England and Scotland, or began to represent unity between nations in a perceived shared struggle, for example, the Pan-Slavic colors or later Pan-Arab colors.

As Europeans colonized significant portions of the world, they exported ideas of nationhood and national symbols, including flags, with the adoption of a flag becoming seen as integral to the nation-building process. Political change, social reform, and revolutions combined with a growing sense of nationhood among ordinary people in the 19th and 20th centuries led to the birth of new nations and flags around the globe. With so many flags being created, interest in these designs began to develop and the study of flags, vexillology, at both professional and amateur levels, emerged. After World War II, Western vexillology went through a phase of rapid development, with many research facilities and publications being established.

National anthems
A national anthem is a patriotic musical composition symbolizing and evoking eulogies of the history and traditions of a country or nation. Though the custom of an officially adopted national anthem became popular only in the 19th century, some national anthems predate this period, often existing as patriotic songs long before designation as national anthem.[citation needed] Several countries remain without an official national anthem. In these cases, there are established de facto anthems played at sporting events or diplomatic receptions. These include the United Kingdom ("God Save the Queen") and Sweden (Du gamla, Du fria). Some sovereign states that are made up of multiple countries or constituencies have associated musical compositions for each of them (such as with the United Kingdom, Russia, and the former Soviet Union). These are sometimes referred to as national anthems even though they are not sovereign states (for example, "Hen Wlad Fy Nhadau" is used for Wales, part of the United Kingdom).[citation needed]

Other symbols
Coats of arms or national emblems
Seals or stamps
National mottos
National colors
Sovereignty and recognition
Main article: List of sovereign states
When referring to a specific polity, the term "country" may refer to a sovereign state, a constituent country, or a dependent territory. A sovereign state is a political entity that has supreme legitimate authority over a part of the world. There is no universal agreement on the number of "countries" in the world since several states have disputed sovereignty status, and a number of non-sovereign entities are commonly called countries.

By one application of the declarative theory of statehood and constitutive theory of statehood,[better source needed] there are 206 sovereign states; of which 193 are members of the UN, two have observer status at the United Nations General Assembly (UNGA) (the Holy See and Palestine), and 11 others are neither a member nor observer at the UNGA.[better source needed]

Some countries, such as Taiwan and the Sahrawi Republic, have disputed sovereignty status. Some sovereign states are unions of separate polities, each of which may also be considered a country in its own right, called constituent countries. The Danish Realm consists of Denmark proper, the Faroe Islands, and Greenland. The Kingdom of the Netherlands consists of the Netherlands proper, Aruba, Curaçao, and Sint Maarten.[note 1][better source needed] The United Kingdom consists of England, Scotland, Wales, and Northern Ireland.

Dependent territories are the territories of a sovereign state that are outside of its proper territory. These include the Realm of New Zealand, the dependencies of Norway, the British Overseas Territories and Crown Dependencies, the territories of the United States, the territories of Australia, the special administrative regions of China, the Danish Realm, Åland, Overseas France, and the Caribbean Netherlands. Most dependent territories have ISO country codes.[better source needed] In total there are 249 ISO country codes, including all 193 UN members and a number of other countries. Some dependent territories are treated as a separate "country of origin" in international trade, such as Hong Kong, Greenland, and Macau.[better source needed]

Patriotism
A positive emotional connection to a country a person belongs to is called patriotism. Patriotism is a sense of love for, devotion to, and sense of attachment to one's country. This attachment can be a combination of many different feelings, and language relating to one's homeland, including ethnic, cultural, political, or historical aspects. It encompasses a set of concepts closely related to nationalism, mostly civic nationalism and sometimes cultural nationalism.

Economy
Several organizations seek to identify trends to produce economy country classifications. Countries are often distinguished as developing countries or developed countries.[citation needed]

The United Nations Department of Economic and Social Affairs annually produces the World Economic Situation and Prospects Report classifies states as developed countries, economies in transition, or developing countries. The report classifies country development based on per capita gross national income (GNI). The UN identifies subgroups within broad categories based on geographical location or ad hoc criteria. The UN outlines the geographical regions for developing economies like Africa, East Asia, South Asia, Western Asia, Latin America, and the Caribbean. The 2019 report recognizes only developed countries in North America, Europe, Asia, and the Pacific. The majority of economies in transition and developing countries are found in Africa, Asia, Latin America, and the Caribbean.[citation needed]

The World Bank also classifies countries based on GNI per capita. The World Bank Atlas method classifies countries as low-income economies, lower-middle-income economies, upper-middle-income economies, or high-income economies. For the 2020 fiscal year, the World Bank defines low-income economies as countries with a GNI per capita of $1,025 or less in 2018; lower-middle-income economies as countries with a GNI per capita between $1,026 and $3,995; upper-middle-income economies as countries with a GNI per capita between $3,996 and $12,375; high-income economies as countries with a GNI per capita of $12,376 or more.

It also identifies regional trends. The World Bank defines its regions as East Asia and Pacific, Europe and Central Asia, Latin America and the Caribbean, Middle East and North Africa, North America, South Asia, and Sub-Saharan Africa. Lastly, the World Bank distinguishes countries based on its operational policies. The three categories include International Development Association (IDA) countries, International Bank for Reconstruction and Development (IBRD) countries, and Blend countries.[citation needed]

In its most general sense, the term "world" refers to the totality of entities, to the whole of reality or to everything that is. The nature of the world has been conceptualized differently in different fields. Some conceptions see the world as unique while others talk of a "plurality of worlds". Some treat the world as one simple object while others analyze the world as a complex made up of many parts. In scientific cosmology the world or universe is commonly defined as "[t]he totality of all space and time; all that is, has been, and will be". Theories of modality, on the other hand, talk of possible worlds as complete and consistent ways how things could have been. Phenomenology, starting from the horizon of co-given objects present in the periphery of every experience, defines the world as the biggest horizon or the "horizon of all horizons". In philosophy of mind, the world is commonly contrasted with the mind as that which is represented by the mind. Theology conceptualizes the world in relation to God, for example, as God's creation, as identical to God or as the two being interdependent. In religions, there is often a tendency to downgrade the material or sensory world in favor of a spiritual world to be sought through religious practice. A comprehensive representation of the world and our place in it, as is commonly found in religions, is known as a worldview. Cosmogony is the field that studies the origin or creation of the world while eschatology refers to the science or doctrine of the last things or of the end of the world.

In various contexts, the term "world" takes a more restricted meaning associated, for example, with the Earth and all life on it, with humanity as a whole or with an international or intercontinental scope. In this sense, world history refers to the history of humanity as a whole or world politics is the discipline of political science studying issues that transcend nations and continents. Other examples include terms such as "world religion", "world language", "world government", "world war", "world population", "world economy" or "world championship".

Etymology
The English word world comes from the Old English weorold. The Old English is a reflex of the Common Germanic *weraldiz, a compound of weraz 'man' and aldiz 'age', thus literally meaning roughly 'age of man'; this word also led to Old Frisian warld, Old Saxon werold, Old Dutch werolt, Old High German weralt, and Old Norse verǫld.

The corresponding word in Latin is mundus, literally 'clean, elegant', itself a loan translation of Greek cosmos 'orderly arrangement'. While the Germanic word thus reflects a mythological notion of a "domain of Man" (compare Midgard), presumably as opposed to the divine sphere on the one hand and the chthonic sphere of the underworld on the other, the Greco-Latin term expresses a notion of creation as an act of establishing order out of chaos.

Conceptions
Different fields often work with quite different conceptions of the essential features associated with the term "world". Some conceptions see the world as unique: there can be no more than one world. Others talk of a "plurality of worlds". Some see worlds as complex things composed of many substances as their parts while others hold that worlds are simple in the sense that there is only one substance: the world as a whole. Some characterize worlds in terms of objective spacetime while others define them relative to the horizon present in each experience. These different characterizations are not always exclusive: it may be possible to combine some without leading to a contradiction. Most of them agree that worlds are unified totalities.

Monism and pluralism
Monism is a thesis about oneness: that only one thing exists in a certain sense. The denial of monism is pluralism, the thesis that, in a certain sense, more than one thing exists. There are many forms of monism and pluralism, but in relation to the world as a whole, two are of special interest: existence monism/pluralism and priority monism/pluralism. Existence monism states that the world is the only concrete object there is. This means that all the concrete "objects" we encounter in our daily lives, including apples, cars and ourselves, are not truly objects in a strict sense. Instead, they are just dependent aspects of the world-object. Such a world-object is simple in the sense that it does not have any genuine parts. For this reason, it has also been referred to as "blobject" since it lacks an internal structure just like a blob. Priority monism allows that there are other concrete objects besides the world. But it holds that these objects do not have the most fundamental form of existence, that they somehow depend on the existence of the world. The corresponding forms of pluralism, on the other hand, state that the world is complex in the sense that it is made up of concrete, independent objects.

Scientific cosmology
Scientific cosmology can be defined as the science of the universe as a whole. In it, the terms "universe" and "cosmos" are usually used as synonyms for the term "world". One common definition of the world/universe found in this field is as "[t]he totality of all space and time; all that is, has been, and will be". Some definitions emphasize that there are two other aspects to the universe besides spacetime: forms of energy or matter, like stars and particles, and laws of nature. Different world-conceptions in this field differ both concerning their notion of spacetime and of the contents of spacetime. The theory of relativity plays a central role in modern cosmology and its conception of space and time. An important difference from its predecessors is that it conceives space and time not as distinct dimensions but as a single four-dimensional manifold called spacetime. This can be seen in special relativity in relation to the Minkowski metric, which includes both spatial and temporal components in its definition of distance. General relativity goes one step further by integrating the concept of mass into the concept of spacetime as its curvature. Quantum cosmology, on the other hand, uses a classical notion of spacetime and conceives the whole world as one big wave function expressing the probability of finding particles in a given location.

Theories of modality
The world-concept plays an important role in many modern theories of modality, usually in the form of possible worlds. A possible world is a complete and consistent way how things could have been. The actual world is a possible world since the way things are is a way things could have been. But there are many other ways things could have been besides how they actually are. For example, Hillary Clinton did not win the 2016 US election, but she could have won them. So there is a possible world in which she did. There is a vast number of possible worlds, one corresponding to each such difference, no matter how small or big, as long as no outright contradictions are introduced this way.

Possible worlds are often conceived as abstract objects, for example, in terms of non-obtaining states of affairs or as maximally consistent sets of propositions. On such a view, they can even be seen as belonging to the actual world. Another way to conceive possible worlds, made famous by David Lewis, is as concrete entities. On this conception, there is no important difference between the actual world and possible worlds: both are conceived as concrete, inclusive and spatiotemporally connected. The only difference is that the actual world is the world we live in, while other possible worlds are not inhabited by us but by our counterparts. Everything within a world is spatiotemporally connected to everything else but the different worlds do not share a common spacetime: They are spatiotemporally isolated from each other. This is what makes them separate worlds.

It has been suggested that, besides possible worlds, there are also impossible worlds. Possible worlds are ways things could have been, so impossible worlds are ways things could not have been. Such worlds involve a contradiction, like a world in which Hillary Clinton both won and lost the 2016 US election. Both possible and impossible worlds have in common the idea that they are totalities of their constituents.

Phenomenology
Within phenomenology, worlds are defined in terms of horizons of experiences. When we perceive an object, like a house, we do not just experience this object at the center of our attention but also various other objects surrounding it, given in the periphery. The term "horizon" refers to these co-given objects, which are usually experienced only in a vague, indeterminate manner. The perception of a house involves various horizons, corresponding to the neighborhood, the city, the country, the Earth, etc. In this context, the world is the biggest horizon or the "horizon of all horizons". It is common among phenomenologists to understand the world not just as a spatiotemporal collection of objects but as additionally incorporating various other relations between these objects. These relations include, for example, indication-relations that help us anticipate one object given the appearances of another object and means-end-relations or functional involvements relevant for practical concerns.

Philosophy of mind
In philosophy of mind, the term "world" is commonly used in contrast to the term "mind" as that which is represented by the mind. This is sometimes expressed by stating that there is a gap between mind and world and that this gap needs to be overcome for representation to be successful. One of the central problems in philosophy of mind is to explain how the mind is able to bridge this gap and to enter into genuine mind-world-relations, for example, in the form of perception, knowledge or action. This is necessary for the world to be able to rationally constrain the activity of the mind. According to a realist position, the world is something distinct and independent from the mind. Idealists, on the other hand, conceive of the world as partially or fully determined by the mind. Immanuel Kant's transcendental idealism, for example, posits that the spatiotemporal structure of the world is imposed by the mind on reality but lacks independent existence otherwise. A more radical idealist conception of the world can be found in Berkeley's subjective idealism, which holds that the world as a whole, including all everyday objects like tables, cats, trees and ourselves, "consists of nothing but minds and ideas".

Theology
Different theological positions hold different conceptions of the world based on its relation to God. Classical theism states that God is wholly distinct from the world. But the world depends for its existence on God, both because God created the world and because He maintains or conserves it. This is sometimes understood in analogy to how humans create and conserve ideas in their imagination, with the difference being that the divine mind is vastly more powerful. On such a view, God has absolute, ultimate reality in contrast to the lower ontological status ascribed to the world. God's involvement in the world is often understood along the lines of a personal, benevolent God who looks after and guides His creation. Deists agree with theists that God created the world but deny any subsequent, personal involvement in it. Pantheists, on the other hand, reject the separation between God and world. Instead, they claim that the two are identical. This means that there is nothing to the world that does not belong to God and that there is nothing to God beyond what is found in the world. Panentheism constitutes a middle ground between theism and pantheism. Against theism, It holds that God and the world are interrelated and depend on each other. Against pantheism, it holds that there is no outright identity between the two. Atheists, on the other hand, deny the existence of God and thereby of conceptions of the world based on its relation to God.

History of philosophy
In philosophy, the term world has several possible meanings. In some contexts, it refers to everything that makes up reality or the physical universe. In others, it can mean have a specific ontological sense (see world disclosure). While clarifying the concept of world has arguably always been among the basic tasks of Western philosophy, this theme appears to have been raised explicitly only at the start of the twentieth century and has been the subject of continuous debate. The question of what the world is has by no means been settled.

Parmenides
The traditional interpretation of Parmenides' work is that he argued that the everyday perception of reality of the physical world (as described in doxa) is mistaken, and that the reality of the world is 'One Being' (as described in aletheia): an unchanging, ungenerated, indestructible whole.

Plato
Plato is well known for his theory of forms, which posits the existence of two different worlds: the sensible world and the intelligible world. The sensible world is the world we live in, filled with changing physical things we can see, touch and interact with. The intelligible world, on the other hand, is the world of invisible, eternal, changeless forms like goodness, beauty, unity and sameness. Plato ascribes a lower ontological status to the sensible world, which only imitates the world of forms. This is due to the fact that physical things exist only to the extent that they participate in the forms that characterize them, while the forms themselves have an independent manner of existence. In this sense, the sensible world is a mere replication of the perfect exemplars found in the world of forms: it never lives up to the original. In the allegory of the cave, Plato compares the physical things we are familiar with to mere shadows of the real things. But not knowing the difference, the prisoners in the cave mistake the shadows for the real things.

Hegel
In Georg Wilhelm Friedrich Hegel's philosophy of history, the expression Weltgeschichte ist Weltgericht (World History is a tribunal that judges the World) is used to assert the view that History is what judges men, their actions and their opinions. Science is born from the desire to transform the World in relation to Man; its final end is technical application.

Schopenhauer
The World as Will and Representation is the central work of Arthur Schopenhauer. Schopenhauer saw the human will as our one window to the world behind the representation; the Kantian thing-in-itself. He believed, therefore, that we could gain knowledge about the thing-in-itself, something Kant said was impossible, since the rest of the relationship between representation and thing-in-itself could be understood by analogy to the relationship between human will and human body.

Wittgenstein
Two definitions that were both put forward in the 1920s, however, suggest the range of available opinion. "The world is everything that is the case," wrote Ludwig Wittgenstein in his influential Tractatus Logico-Philosophicus, first published in 1921. This definition would serve as the basis of logical positivism, with its assumption that there is exactly one world, consisting of the totality of facts, regardless of the interpretations that individual people may make of them.

Heidegger
Martin Heidegger, meanwhile, argued that "the surrounding world is different for each of us, and notwithstanding that we move about in a common world". The world, for Heidegger, was that into which we are always already "thrown" and with which we, as beings-in-the-world, must come to terms. His conception of "world disclosure" was most notably elaborated in his 1927 work Being and Time.

Eugen Fink
"World" is one of the key terms in Eugen Fink's philosophy. He thinks that there is a misguided tendency in western philosophy to understand the world as one enormously big thing containing all the small everyday things we are familiar with. He sees this view as a form of forgetfulness of the world and tries to oppose it by what he calls the "cosmological difference": the difference between the world and the inner-worldly things it contains. On his view, the world is the totality of the inner-worldly things that transcends them. It is itself groundless but it provides a ground for things. It therefore cannot be identified with a mere container. Instead, the world gives appearance to inner-worldly things, it provides them with a place, a beginning and an end. One difficulty in investigating the world is that we never encounter it since it is not just one more thing that appears to us. This is why Fink uses the notion of play or playing to elucidate the nature of the world. He sees play as a symbol of the world that is both part of it and that represents it. Play usually comes with a form of imaginary play-world involving various things relevant to the play. But just like the play is more than the imaginary realities appearing in it so the world is more than the actual things appearing in it.

Goodman
The concept of worlds plays a central role in Nelson Goodman's late philosophy. He argues that we need to posit different worlds in order to account for the fact that there are different incompatible truths found in reality. Two truths are incompatible if they ascribe incompatible properties to the same thing. This happens, for example, when we assert both that the earth moves and that the earth is at rest. These incompatible truths correspond to two different ways of describing the world: heliocentrism and geocentrism. Goodman terms such descriptions "world versions". He holds a correspondence theory of truth: a world version is true if it corresponds to a world. Incompatible true world versions correspond to different worlds. It is common for theories of modality to posit the existence of a plurality of possible worlds. But Goodman's theory is different since it posits a plurality not of possible but of actual worlds. Such a position is in danger of involving a contradiction: there cannot be a plurality of actual worlds if worlds are defined as maximally inclusive wholes. This danger may be avoided by interpreting Goodman's world-concept not as maximally inclusive wholes in the absolute sense but in relation to its corresponding world-version: a world contains all and only the entities that its world-version describes.

Religion

Wikiquote has quotations related to Worldliness.

Yggdrasil, a modern attempt to reconstruct the Norse world tree which connects the heavens, the world, and the underworld.
Mythological cosmologies often depict the world as centered on an axis mundi and delimited by a boundary such as a world ocean, a world serpent or similar. In some religions, worldliness (also called carnality) is that which relates to this world as opposed to other worlds or realms.

Buddhism
In Buddhism, the world means society, as distinct from the monastery. It refers to the material world, and to worldly gain such as wealth, reputation, jobs, and war. The spiritual world would be the path to enlightenment, and changes would be sought in what we could call the psychological realm.

Christianity
In Christianity, the term often connotes the concept of the fallen and corrupt world order of human society, in contrast to the World to Come. The world is frequently cited alongside the flesh and the Devil as a source of temptation that Christians should flee. Monks speak of striving to be "in this world, but not of this world" — as Jesus said — and the term "worldhood" has been distinguished from "monkhood", the former being the status of merchants, princes, and others who deal with "worldly" things.

This view is clearly expressed by king Alfred the Great of England (d. 899) in his famous Preface to the Cura Pastoralis:

"Therefore I command you to do as I believe you are willing to do, that you free yourself from worldly affairs (Old English: woruldðinga) as often as you can, so that wherever you can establish that wisdom that God gave you, you establish it. Consider what punishments befell us in this world when we neither loved wisdom at all ourselves, nor transmitted it to other men; we had the name alone that we were Christians, and very few had the practices".

Although Hebrew and Greek words meaning "world" are used in Scripture with the normal variety of senses, many examples of its use in this particular sense can be found in the teachings of Jesus according to the Gospel of John, e.g. 7:7, 8:23, 12:25, 14:17, 15:18-19, 17:6-25, 18:36. In contrast, a relatively newer concept is Catholic imagination.

Contemptus mundi is the name given to the belief that the world, in all its vanity, is nothing more than a futile attempt to hide from God by stifling our desire for the good and the holy. This view has been criticised as a "pastoral of fear" by modern historian Jean Delumeau.

During the Second Vatican Council, there was a novel attempt to develop a positive theological view of the World, which is illustrated by the pastoral optimism of the constitutions Gaudium et spes, Lumen gentium, Unitatis redintegratio and Dignitatis humanae.

Eastern Christianity
In Eastern Christian monasticism or asceticism, the world of mankind is driven by passions. Therefore, the passions of the World are simply called "the world". Each of these passions are a link to the world of mankind or order of human society. Each of these passions must be overcome in order for a person to receive salvation (Theosis). The process of Theosis is a personal relationship with God. This understanding is taught within the works of ascetics like Evagrius Ponticus, and the most seminal ascetic works read most widely by Eastern Christians, the Philokalia and The Ladder of Divine Ascent (the works of Evagrius and John Climacus are also contained within the Philokalia). At the highest level of world transcendence is hesychasm which culminates into the Vision of God.

Orbis Catholicus
Orbis Catholicus is a Latin phrase meaning Catholic world, per the expression Urbi et Orbi, and refers to that area of Christendom under papal supremacy. It is somewhat similar to the phrases secular world, Jewish world and Islamic world.

Islam
Main article: Dunya
In Islam, the term "dunya" is used for the world. Its meaning is derived from the root word "dana", a term for "near". It is mainly associated with the temporal, sensory world and earthly concerns, i.e. with this world in contrast to the spiritual world. Some religious teachings warn of our tendency to seek happiness in this world and advise a more ascetic lifestyle concerned with the afterlife. But other strands in Islam recommend a balanced approach.

Mandaeism
In Mandaean cosmology, the world or earthly realm is known as Tibil. It is separated from the World of Light (alma d-nhūra) above and the World of Darkness (alma d-hšuka) below by ayar (aether).

Hinduism
Hinduism constitutes a wide family of religious-philosophical views. These views present different perspectives on the nature and role of the world. Samkhya philosophy, for example, is a metaphysical dualism that understands reality as comprising two parts: purusha and prakriti. The term "purusha" stands for the individual conscious self that each of us possesses. Prakriti, on the other hand, is the one world inhabited by all these selves. Samkhya understands this world as a world of matter governed by the law of cause and effect. The term "matter" is understood in a very wide sense in this tradition including both physical and mental aspects. This is reflected in the doctrine of tattvas, according to which prakriti is made up of 23 different principles or elements of reality. These principles include both physical elements, like water or earth, and mental aspects, like intelligence or sense-impressions. The relation between purusha and prakriti is usually conceived as one of mere observation: purusha is the conscious self aware of the world of prakriti but does not causally interact with it.

A very different conception of the world is present in Advaita Vedanta, the monist school among the Vedanta schools. Unlike the realist position defended in Samkhya philosophy, Advaita Vedanta sees the world of multiplicity as an illusion, referred to as Maya. This illusion also includes our impression of existing as separate experiencing selfs called Jivas. Instead, Advaita Vedanta teaches that on the most fundamental level of reality, referred to as Brahman, there exists no plurality or difference. All there is is one all-encompassing self: Atman. Ignorance is seen as the source of this illusion, which results in bondage to the world of mere appearances. But liberation is possible in the course of overcoming this illusion by acquiring the knowledge of Brahman, according to Advaita Vedanta.

Related terms and problems
Worldviews
Main article: Worldview
A worldview is a comprehensive representation of the world and our place in it. As a representation, it is a subjective perspective of the world and thereby different from the world it represents. All higher animals need to represent their environment in some way in order to navigate it. But it has been argued that only humans possess a representation encompassing enough to merit the term "worldview". Philosophers of worldviews commonly hold that the understanding of any object depends on a worldview constituting the background on which this understanding can take place. This may affect not just our intellectual understanding of the object in question but the experience of it in general. It is therefore impossible to assess one's worldview from a neutral perspective since this assessment already presupposes the worldview as its background. Some hold that each worldview is based on a single hypothesis that promises to solve all the problems of our existence we may encounter. On this interpretation, the term is closely associated to the worldviews given by different religions. Worldviews offer orientation not just in theoretical matters but also in practical matters. For this reason, they usually include answers to the question of the meaning of life and other evaluative components about what matters and how we should act. A worldview can be unique to one individual but worldviews are usually shared by many people within a certain culture or religion.

Paradox of many worlds
The idea that there exist many different worlds is found in various fields. For example, Theories of modality talk about a plurality of possible worlds and the many-worlds interpretation of quantum mechanics carries this reference even in its name. Talk of different worlds is also common in everyday language, for example, with reference to the world of music, the world of business, the world of football, the world of experience or the Asian world. But at the same time, worlds are usually defined as all-inclusive totalities. This seems to contradict the very idea of a plurality of worlds since if a world is total and all-inclusive then it cannot have anything outside itself. Understood this way, a world can neither have other worlds besides itself or be part of something bigger. One way to resolve this paradox while holding onto the notion of a plurality of worlds is to restrict the sense in which worlds are totalities. On this view, worlds are not totalities in an absolute sense. This might be even understood in the sense that, strictly speaking, there are no worlds at all. Another approach understands worlds in a schematic sense: as context-dependent expressions that stand for the current domain of discourse. So in the expression "Around the World in Eighty Days", the term "world" refers to the earth while in the colonial expression "the New World" it refers to the landmass of North and South America.

Cosmogony
Main article: Cosmogony
Cosmogony is the field that studies the origin or creation of the world. This includes both scientific cosmogony and creation myths found in various religions. The dominant theory in scientific cosmogony is the Big Bang theory, according to which both space, time and matter have their origin in one initial singularity occurring about 13.8 billion years ago. This singularity was followed by an expansion that allowed the universe to sufficiently cool down for the formation of subatomic particles and later atoms. These initial elements formed giant clouds, which would then coalesce into stars and galaxies. Non-scientific creation myths are found in many cultures and are often enacted in rituals expressing their symbolic meaning. They can be categorized concerning their contents. Types often found include creation from nothing, from chaos or from a cosmic egg.

Eschatology
Main article: Eschatology
Eschatology refers to the science or doctrine of the last things or of the end of the world. It is traditionally associated with religion, specifically with the Abrahamic religions. In this form, it may include teachings both of the end of each individual human life and of the end of the world as a whole. But it has been applied to other fields as well, for example, in the form of physical Eschatology, which includes scientifically based speculations about the far future of the universe. According to some models, there will be a Big Crunch in which the whole universe collapses back into a singularity, possibly resulting in a second Big Bang afterward. But current astronomical evidence seems to suggest that our universe will continue to expand indefinitely.

World history
Main article: World history (field)
World history studies the world from a historical perspective. Unlike other approaches to history, it employs a global viewpoint. It deals less with individual nations and civilizations, which it usually approaches at a high level of abstraction. Instead, it concentrates on wider regions and zones of interaction, often interested in how people, goods and ideas move from one region to another. It includes comparisons of different societies and civilizations as well as considering wide-ranging developments with a long-term global impact like the process of industrialization. Contemporary world history is dominated by three main research paradigms determining the periodization into different epochs. One is based on productive relations between humans and nature. The two most important changes in history in this respect were the introduction of agriculture and husbandry concerning the production of food, which started around 10,000 to 8,000 BCE and is sometimes termed the Neolithic revolution, and the industrial revolution, which started around 1760 CE and involved the transition from manual to industrial manufacturing. Another paradigm, focusing on culture and religion instead, is based on Karl Jaspers' theories about the axial age, a time in which various new forms of religious and philosophical thoughts appeared in several separate parts of the world around the time between 800 and 200 BCE. A third periodization is based on the relations between civilizations and societies. According to this paradigm, history can be divided into three periods in relation to the dominant region in the world: Middle Eastern dominance before 500 BCE, Eurasian cultural balance until 1500 CE and Western dominance since 1500 CE. Big history employs an even wider framework than world history by putting human history into the context of the history of the universe as a whole. It starts with the Big Bang and traces the formation of galaxies, the solar system, the earth, its geological eras, the evolution of life and humans until the present day.

World politics
World politics, also referred to as global politics or international relations, is the discipline of political science studying issues of interest to the world that transcend nations and continents. It aims to explain complex patterns found in the social world that are often related to the pursuit of power, order and justice, usually in the context of globalization. It focuses not just on the relations between nation-states but also considers other transnational actors, like multinational corporations, terrorist groups, or non-governmental organizations. For example, it tries to explain events like 9/11, the 2003 war in Iraq or the financial crisis of 2007–2008.

Various theories have been proposed in order to deal with the complexity involved in formulating such explanations. These theories are sometimes divided into realism, liberalism and constructivism. Realists see nation-states as the main actors in world politics. They constitute an anarchical international system without any overarching power to control their behavior. They are seen as sovereign agents that, determined by human nature, act according to their national self-interest. Military force may play an important role in the ensuing struggle for power between states, but diplomacy and cooperation are also key mechanisms for nations to achieve their goals. Liberalists acknowledge the importance of states but they also emphasize the role of transnational actors, like the United Nations or the World Trade Organization. They see humans as perfectible and stress the role of democracy in this process. The emergent order in world politics, on this perspective, is more complex than a mere balance of power since more different agents and interests are involved in its production. Constructivism ascribes more importance to the agency of individual humans than realism and liberalism. It understands the social world as a construction of the people living in it. This leads to an emphasis on the possibility of change. If the international system is an anarchy of nation-states, as the realists hold, then this is only so because we made it this way and may well change since this is not prefigured by human nature, according to the constructivists.

Science is a systematic endeavor that builds and organizes knowledge in the form of testable explanations and predictions about the universe.

The earliest written records of identifiable predecessors to modern science come from Ancient Egypt and Mesopotamia from around 3000 to 1200 BCE. Their contributions to mathematics, astronomy, and medicine entered and shaped the Greek natural philosophy of classical antiquity, whereby formal attempts were made to provide explanations of events in the physical world based on natural causes.: 12  After the fall of the Western Roman Empire, knowledge of Greek conceptions of the world deteriorated in Western Europe during the early centuries (400 to 1000 CE) of the Middle Ages, but was preserved in the Muslim world during the Islamic Golden Age and later by the efforts of Byzantine Greek scholars who brought Greek manuscripts from the dying Byzantine Empire to Western Europe in the Renaissance.

The recovery and assimilation of Greek works and Islamic inquiries into Western Europe from the 10th to 13th century revived "natural philosophy", which was later transformed by the Scientific Revolution that began in the 16th century as new ideas and discoveries departed from previous Greek conceptions and traditions. The scientific method soon played a greater role in knowledge creation and it was not until the 19th century that many of the institutional and professional features of science began to take shape, along with the changing of "natural philosophy" to "natural science".

Modern science is typically divided into three major branches: natural sciences (e.g., biology, chemistry, and physics), which study the physical world; the social sciences (e.g., economics, psychology, and sociology), which study individuals and societies; and the formal sciences (e.g., logic, mathematics, and theoretical computer science), which study formal systems, governed by axioms and rules. There is disagreement whether the formal sciences are science disciplines, because they do not rely on empirical evidence. Applied sciences are disciplines that use scientific knowledge for practical purposes, such as in engineering and medicine.

New knowledge in science is advanced by research from scientists who are motivated by curiosity about the world and a desire to solve problems. Contemporary scientific research is highly collaborative and is usually done by teams in academic and research institutions, government agencies, and companies. The practical impact of their work has led to the emergence of science policies that seek to influence the scientific enterprise by prioritizing the ethical and moral development of commercial products, armaments, health care, public infrastructure, and environmental protection.

The word science has been used in Middle English since the 14th century in the sense of "the state of knowing". The word was borrowed from the Anglo-Norman language as the suffix -cience, which was borrowed from the Latin word scientia, meaning "knowledge, awareness, understanding". It is a noun derivative of the Latin sciens meaning "knowing", and undisputedly derived from the Latin sciō, the present participle scīre, meaning "to know".

There are many hypotheses for science's ultimate word origin. According to Michiel de Vaan, Dutch linguist and Indo-Europeanist, sciō may have its origin in the Proto-Italic language as *skije- or *skijo- meaning "to know", which may originate from Proto-Indo-European language as *skh1-ie, *skh1-io, meaning "to incise". The Lexikon der indogermanischen Verben proposed sciō is a back-formation of nescīre, meaning "to not know, be unfamiliar with", which may derive from Proto-Indo-European *sekH- in Latin secāre, or *skh2-, from *sḱʰeh2(i)- meaning "to cut".

In the past, science was a synonym for "knowledge" or "study", in keeping with its Latin origin. A person who conducted scientific research was called a "natural philosopher" or "man of science". In 1834, William Whewell introduced the term scientist in a review of Mary Somerville's book On the Connexion of the Physical Sciences, crediting it to "some ingenious gentleman" (possibly himself).

Early history
Main article: History of science in early cultures
Clay tablet with markings, three columns for numbers and one for ordinals
The Plimpton 322 tablet by the Babylonians records Pythagorean triples, written in about 1800 BCE.
Science has no single origin. Rather, systematic methods emerged gradually over the course of tens of thousands of years, taking different forms around the world, and few details are known about the very earliest developments. Women likely played a central role in prehistoric science, as did religious rituals. Some scholars use the term "protoscience" to label activities in the past that resemble modern science in some but not all features; however, this label has also been criticized as denigrating or too suggestive of presentism, thinking about those activities only in relation to modern categories.

Direct evidence for scientific processes becomes clearer with the advent of writing systems in early civilizations like Ancient Egypt and Mesopotamia, creating the earliest written records in the history of science in around 3000 to 1200 BCE.: 12–15  Although the words and concepts of "science" and "nature" were not part of the conceptual landscape at the time, the ancient Egyptians and Mesopotamians made contributions that would later find a place in Greek and medieval science: mathematics, astronomy, and medicine.: 12  From the 3rd millennium BCE, the ancient Egyptians developed a decimal numbering system, solved practical problems using geometry, and developed a calendar. Their healing therapies involved drug treatments and the supernatural, such as prayers, incantations, and rituals.: 9 

The ancient Mesopotamians used knowledge about the properties of various natural chemicals for manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing. They studied animal physiology, anatomy, behavior, and astrology for divinatory purposes. The Mesopotamians had an intense interest in medicine and the earliest medical prescriptions appeared in Sumerian during the Third Dynasty of Ur. They seem to study scientific subjects which have practical or religious applications and have little interest of satisfying curiosity.

Classical antiquity
Main article: History of science in classical antiquity
Framed mosaic of philosophers gathering around and conversing
Plato's Academy mosaic, made between 100 BCE to 79 AD, shows many Greek philosophers and scholars.
In classical antiquity, there is no real ancient analog of a modern scientist. Instead, well-educated, usually upper-class, and almost universally male individuals performed various investigations into nature whenever they could afford the time. Before the invention or discovery of the concept of phusis or nature by the pre-Socratic philosophers, the same words tend to be used to describe the natural "way" in which a plant grows, and the "way" in which, for example, one tribe worships a particular god. For this reason, it is claimed that these men were the first philosophers in the strict sense and the first to clearly distinguish "nature" and "convention".

The early Greek philosophers of the Milesian school, which was founded by Thales of Miletus and later continued by his successors Anaximander and Anaximenes, were the first to attempt to explain natural phenomena without relying on the supernatural. The Pythagoreans developed a complex number philosophy: 467–68  and contributed significantly to the development of mathematical science.: 465  The theory of atoms was developed by the Greek philosopher Leucippus and his student Democritus. Later, Epicurus would develop a full natural cosmology based on atomism, and would adopt a "canon" (ruler, standard) which established physical criteria or standards of scientific truth. The Greek doctor Hippocrates established the tradition of systematic medical science and is known as "The Father of Medicine".

A turning point in the history of early philosophical science was Socrates' example of applying philosophy to the study of human matters, including human nature, the nature of political communities, and human knowledge itself. The Socratic method as documented by Plato's dialogues is a dialectic method of hypothesis elimination: better hypotheses are found by steadily identifying and eliminating those that lead to contradictions. The Socratic method searches for general commonly-held truths that shape beliefs and scrutinizes them for consistency. Socrates criticized the older type of study of physics as too purely speculative and lacking in self-criticism.

Aristotle in the 4th century BCE created a systematic program of teleological philosophy. In the 3rd century BCE, Greek astronomer Aristarchus of Samos was the first to propose a heliocentric model of the universe, with the Sun at the center and all the planets orbiting it. Aristarchus's model was widely rejected because it was believed to violate the laws of physics, while Ptolemy's Almagest, which contains a geocentric description of the Solar System, was accepted through the early Renaissance instead. The inventor and mathematician Archimedes of Syracuse made major contributions to the beginnings of calculus. Pliny the Elder was a Roman writer and polymath, who wrote the seminal encyclopedia Natural History.

Positional notation for representing numbers likely emerged between the 3rd and 5th centuries CE along Indian trade routes. This numeral system made efficient arithmetic operations more accessible and would eventually become standard for mathematics worldwide.

Middle Ages
Main article: History of science § Middle Ages
Picture of a peacock on very old paper
The first page of Vienna Dioscurides depicts a peacock, made in the 6th century.
Due to the collapse of the Western Roman Empire, the 5th century saw an intellectual decline and knowledge of Greek conceptions of the world deteriorated in Western Europe.: 194  During the period, Latin encyclopedists such as Isidore of Seville preserved the majority of general ancient knowledge. In contrast, because the Byzantine Empire resisted attacks from invaders, they were able to preserve and improve prior learning.: 159  John Philoponus, a Byzantine scholar in the 500s, started to question Aristotle's teaching of physics, introducing the theory of impetus.: 307, 311, 363, 402  His criticism served as an inspiration to medieval scholars and Galileo Galilei, who extensively cited his works ten centuries later.: 307–308 

During late antiquity and the early Middle Ages, natural phenomena were mainly examined via the Aristotelian approach. The approach includes Aristotle's four causes: material, formal, moving, and final cause. Many Greek classical texts were preserved by the Byzantine empire and Arabic translations were done by groups such as the Nestorians and the Monophysites. Under the Caliphate, these Arabic translations were later improved and developed by Arabic scientists. By the 6th and 7th centuries, the neighboring Sassanid Empire established the medical Academy of Gondeshapur, which is considered by Greek, Syriac, and Persian physicians as the most important medical center of the ancient world.

The House of Wisdom was established in Abbasid-era Baghdad, Iraq, where the Islamic study of Aristotelianism flourished until the Mongol invasions in the 13th century. Ibn al-Haytham, better known as Alhazen, began experimenting as a means to gain knowledge and disproved Ptolemy's theory of vision: Book I, [6.54]. p. 372  Avicenna's compilation of the Canon of Medicine, a medical encyclopedia, is considered to be one of the most important publications in medicine and was used until the 18th century.

By the eleventh century, most of Europe had become Christian,: 204  and in 1088, the University of Bologna emerged as the first university in Europe. As such, demand for Latin translation of ancient and scientific texts grew,: 204  a major contributor to the Renaissance of the 12th century. Renaissance scholasticism in western Europe flourished, with experiments done by observing, describing, and classifying subjects in nature. In the 13rd century, medical teachers and students at Bologna began opening human bodies, leading to the first anatomy textbook based on human dissection by Mondino de Luzzi.

Renaissance
Main articles: Scientific Revolution and Science in the Renaissance
Drawing of planets' orbit around the Sun
Drawing of the heliocentric model as proposed by the Copernicus's De revolutionibus orbium coelestium
New developments in optics played a role in the inception of the Renaissance, both by challenging long-held metaphysical ideas on perception, as well as by contributing to the improvement and development of technology such as the camera obscura and the telescope. At the start of the Renaissance, Roger Bacon, Vitello, and John Peckham each built up a scholastic ontology upon a causal chain beginning with sensation, perception, and finally apperception of the individual and universal forms of Aristotle.: Book I  A model of vision later known as perspectivism was exploited and studied by the artists of the Renaissance. This theory uses only three of Aristotle's four causes: formal, material, and final.

In the sixteenth century, Nicolaus Copernicus formulated a heliocentric model of the Solar System, stating that the planets revolve around the Sun, instead of the geocentric model where the planets and the Sun revolve around the Earth. This was based on a theorem that the orbital periods of the planets are longer as their orbs are farther from the center of motion, which he found not to agree with Ptolemy's model.

Johannes Kepler and others challenged the notion that the only function of the eye is perception, and shifted the main focus in optics from the eye to the propagation of light. Kepler is best known, however, for improving Copernicus' heliocentric model through the discovery of Kepler's laws of planetary motion. Kepler did not reject Aristotelian metaphysics and described his work as a search for the Harmony of the Spheres. Galileo had made significant contributions to astronomy, physics and engineering. However, he became persecuted after Pope Urban VIII sentenced him for writing about the heliocentric model.

The printing press was widely used to publish scholarly arguments, including some that disagreed widely with contemporary ideas of nature. Francis Bacon and René Descartes published philosophical arguments in favor of a new type of non-Aristotelian science. Bacon emphasized the importance of experiment over contemplation, questioned the Aristotelian concepts of formal and final cause, promoted the idea that science should study the laws of nature and the improvement of all human life. Descartes emphasized individual thought and argued that mathematics rather than geometry should be used to study nature.

Age of Enlightenment
Main article: Science in the Age of Enlightenment
see caption
Title page of the 1687 first edition of Philosophiæ Naturalis Principia Mathematica by Isaac Newton
At the start of the Age of Enlightenment, Isaac Newton formed the foundation of classical mechanics by his Philosophiæ Naturalis Principia Mathematica, greatly influencing future physicists. Gottfried Wilhelm Leibniz incorporated terms from Aristotelian physics, now used in a new non-teleological way. This implied a shift in the view of objects: objects were now considered as having no innate goals. Leibniz assumed that different types of things all work according to the same general laws of nature, with no special formal or final causes.

During this time, the declared purpose and value of science became producing wealth and inventions that would improve human lives, in the materialistic sense of having more food, clothing, and other things. In Bacon's words, "the real and legitimate goal of sciences is the endowment of human life with new inventions and riches", and he discouraged scientists from pursuing intangible philosophical or spiritual ideas, which he believed contributed little to human happiness beyond "the fume of subtle, sublime or pleasing [speculation]".

Science during the Enlightenment was dominated by scientific societies and academies, which had largely replaced universities as centers of scientific research and development. Societies and academies were the backbones of the maturation of the scientific profession. Another important development was the popularization of science among an increasingly literate population. Enlightenment philosophers chose a short history of scientific predecessors – Galileo, Boyle, and Newton principally – as the guides to every physical and social field of the day.

The 18th century saw significant advancements in the practice of medicine and physics; the development of biological taxonomy by Carl Linnaeus; a new understanding of magnetism and electricity; and the maturation of chemistry as a discipline. Ideas on human nature, society, and economics evolved during the Enlightenment. Hume and other Scottish Enlightenment thinkers developed A Treatise of Human Nature, which was expressed historically in works by authors including James Burnett, Adam Ferguson, John Millar and William Robertson, all of whom merged a scientific study of how humans behaved in ancient and primitive cultures with a strong awareness of the determining forces of modernity. Modern sociology largely originated from this movement. In 1776, Adam Smith published The Wealth of Nations, which is often considered the first work on modern economics.

19th century
Main article: 19th century in science
Sketch of a map with captions
The first diagram of an evolutionary tree made by Charles Darwin in 1837
During the nineteenth century, many distinguishing characteristics of contemporary modern science began to take shape. These included the transformation of the life and physical sciences, frequent use of precision instruments, emergence of terms such as "biologist", "physicist", "scientist", increased professionalization of those studying nature, scientists gained cultural authority over many dimensions of society, industrialization of numerous countries, thriving of popular science writings and emergence of science journals. During the late 19th century, psychology emerged as a separate discipline from philosophy when Wilhelm Wundt founded the first laboratory for psychological research in 1879.

During the mid-19th century, Charles Darwin and Alfred Russel Wallace independently proposed the theory of evolution by natural selection in 1858, which explained how different plants and animals originated and evolved. Their theory was set out in detail in Darwin's book On the Origin of Species, published in 1859. Separately, Gregor Mendel presented his paper, "Experiments on Plant Hybridization" in 1865, which outlined the principles of biological inheritance, serving as the basis for modern genetics.

Early in the 19th century, John Dalton suggested the modern atomic theory, based on Democritus's original idea of indivisible particles called atoms. The laws of conservation of energy, conservation of momentum and conservation of mass suggested a highly stable universe where there could be little loss of resources. However, with the advent of the steam engine and the industrial revolution there was an increased understanding that not all forms of energy have the same energy qualities, the ease of conversion to useful work or to another form of energy. This realization led to the development of the laws of thermodynamics, in which the free energy of the universe is seen as constantly declining: the entropy of a closed universe increases over time.[a]

The electromagnetic theory was established in the 19th century by the works of Hans Christian Ørsted, André-Marie Ampère, Michael Faraday, James Clerk Maxwell, Oliver Heaviside, and Heinrich Hertz. The new theory raised questions that could not easily be answered using Newton's framework. The discovery of X-rays inspired the discovery of radioactivity by Henri Becquerel and Marie Curie in 1896, Marie Curie then became the first person to win two Nobel prizes. In the next year came the discovery of the first subatomic particle, the electron.

20th century
Main article: 20th century in science
Graph showing lower ozone concentration at the South Pole
First global view of the ozone hole in 1983, using a space telescope
In the first half of the century, the development of antibiotics and artificial fertilizers improved human living standards globally. Harmful environmental issues such as ozone depletion, ocean acidification, eutrophication and climate change came to the public's attention and caused the onset of environmental studies.

During this period, scientific experimentation became increasingly larger in scale and funding. The extensive technological innovation stimulated by World War I, World War II, and the Cold War led to competitions between global powers, such as the Space Race and nuclear arms race. Substantial international collaborations were also made, despite armed conflicts.

In the late 20th century, active recruitment of women and elimination of sex discrimination greatly increased the number of women scientists, but large gender disparities remained in some fields. The discovery of the cosmic microwave background in 1964 led to a rejection of the steady-state model of the universe in favor of the Big Bang theory of Georges Lemaître.

The century saw fundamental changes within science disciplines. Evolution became a unified theory in the early 20th-century when the modern synthesis reconciled Darwinian evolution with classical genetics. Albert Einstein's theory of relativity and the development of quantum mechanics complement classical mechanics to describe physics in extreme length, time and gravity. Widespread use of integrated circuits in the last quarter of the 20th century combined with communications satellites led to a revolution in information technology and the rise of the global internet and mobile computing, including smartphones. The need for mass systematization of long, intertwined causal chains and large amounts of data led to the rise of the fields of systems theory and computer-assisted scientific modeling.

21st century
Main article: 21st century § Science and technology
Fuzzy donut-shaped blob on a black background
Radio light image of M87* black hole, made by the earth-spanning Event Horizon Telescope array in 2019
The Human Genome Project was completed in 2003 by identifying and mapping all of the genes of the human genome. The first induced pluripotent human stem cells were made in 2006, allowing adult cells to be transformed into stem cells and turn to any cell type found in the body. With the affirmation of the Higgs boson discovery in 2013, the last particle predicted by the Standard Model of particle physics was found. In 2015, gravitational waves, predicted by general relativity a century before, were first observed. In 2019, the international collaboration Event Horizon Telescope presented the first direct image of a black hole's accretion disk.

Branches
Main article: Branches of science
Modern science is commonly divided into three major branches: natural science, social science, and formal science. Each of these branches comprises various specialized yet overlapping scientific disciplines that often possess their own nomenclature and expertise. Both natural and social sciences are empirical sciences, as their knowledge is based on empirical observations and is capable of being tested for its validity by other researchers working under the same conditions.

Natural science
Natural science is the study of the physical world. It can be divided into two main branches: life science and physical science. These two branches may be further divided into more specialized disciplines. For example, physical science can be subdivided into physics, chemistry, astronomy, and earth science. Modern natural science is the successor to the natural philosophy that began in Ancient Greece. Galileo, Descartes, Bacon, and Newton debated the benefits of using approaches which were more mathematical and more experimental in a methodical way. Still, philosophical perspectives, conjectures, and presuppositions, often overlooked, remain necessary in natural science. Systematic data collection, including discovery science, succeeded natural history, which emerged in the 16th century by describing and classifying plants, animals, minerals, and so on. Today, "natural history" suggests observational descriptions aimed at popular audiences.

Social science
Two curve crossing over at a point, forming a X shape
Supply and demand curve in economics, crossing over at the optimal equilibrium
Social science is the study of human behavior and functioning of societies. It has many disciplines that include, but are not limited to anthropology, economics, history, human geography, political science, psychology, and sociology. In the social sciences, there are many competing theoretical perspectives, many of which are extended through competing research programs such as the functionalists, conflict theorists, and interactionists in sociology. Due to the limitations of conducting controlled experiments involving large groups of individuals or complex situations, social scientists may adopt other research methods such as the historical method, case studies, and cross-cultural studies. Moreover, if quantitative information is available, social scientists may rely on statistical approaches to better understand social relationships and processes.

Formal science
Formal science is an area of study that generates knowledge using formal systems. A formal system is an abstract structure used for inferring theorems from axioms according to a set of rules. It includes mathematics, systems theory, and theoretical computer science. The formal sciences share similarities with the other two branches by relying on objective, careful, and systematic study of an area of knowledge. They are, however, different from the empirical sciences as they rely exclusively on deductive reasoning, without the need for empirical evidence, to verify their abstract concepts. The formal sciences are therefore a priori disciplines and because of this, there is disagreement on whether they constitute a science. Nevertheless, the formal sciences play an important role in the empirical sciences. Calculus, for example, was initially invented to understand motion in physics. Natural and social sciences that rely heavily on mathematical applications include mathematical physics, chemistry, biology, finance, and economics.

Applied science
see caption
A steam turbine with the case opened. Such turbines produce most of the electricity used today.
Applied science is the use of the scientific method and knowledge to attain practical goals and includes a broad range of disciplines such as engineering and medicine. Engineering is the use of scientific principles to invent, design and build machines, structures and technologies. Science may contribute to the development of new technologies. Medicine is the practice of caring for patients by maintaining and restoring health through the prevention, diagnosis, and treatment of injury or disease. The applied sciences are often contrasted with the basic sciences, which are focused on advancing scientific theories and laws that explain and predict events in the natural world.

Computational science applies computing power to simulate real-world situations, enabling a better understanding of scientific problems than formal mathematics alone can achieve. The use of machine learning and artificial intelligence is becoming a central feature of computational contributions to science for example in agent-based computational economics, random forests, topic modeling and various forms of prediction. However, machines alone rarely advance knowledge as they require human guidance and capacity to reason; and they can introduce bias against certain social groups or sometimes underperform against humans.

Interdisciplinary science
Interdisciplinary science involves the combination of two or more disciplines into one, such as bioinformatics, a combination of biology and computer science or cognitive sciences. The concept has existed since the ancient Greek and it became popular again in the 20th century.

Scientific research
Scientific research can be labeled as either basic or applied research. Basic research is the search for knowledge and applied research is the search for solutions to practical problems using this knowledge. Most understanding comes from basic research, though sometimes applied research targets specific practical problems. This leads to technological advances that were not previously imaginable.

Scientific method
6 steps of the scientific method in a loop
A diagram variant of scientific method represented as an ongoing process
Scientific research involves using the scientific method, which seeks to objectively explain the events of nature in a reproducible way. Scientists usually take for granted a set of basic assumptions that are needed to justify the scientific method: there is an objective reality shared by all rational observers; this objective reality is governed by natural laws; these laws were discovered by means of systematic observation and experimentation. Mathematics is essential in the formation of hypotheses, theories, and laws, because it is used extensively in quantitative modeling, observing, and collecting measurements. Statistics is used to summarize and analyze data, which allows scientists to assess the reliability of experimental results.

In the scientific method, an explanatory thought experiment or hypothesis is put forward as an explanation using parsimony principles and is expected to seek consilience – fitting with other accepted facts related to an observation or scientific question. This tentative explanation is used to make falsifiable predictions, which are typically posted before being tested by experimentation. Disproof of a prediction is evidence of progress.: 4–5  Experimentation is especially important in science to help establish causal relationships to avoid the correlation fallacy, though in some sciences such as astronomy or geology, a predicted observation might be more appropriate.

When a hypothesis proves unsatisfactory, it is modified or discarded. If the hypothesis survived testing, it may become adopted into the framework of a scientific theory, a logically reasoned, self-consistent model or framework for describing the behavior of certain natural events. A theory typically describes the behavior of much broader sets of observations than a hypothesis; commonly, a large number of hypotheses can be logically bound together by a single theory. Thus a theory is a hypothesis explaining various other hypotheses. In that vein, theories are formulated according to most of the same scientific principles as hypotheses. Scientists may generate a model, an attempt to describe or depict an observation in terms of a logical, physical or mathematical representation and to generate new hypotheses that can be tested by experimentation.

While performing experiments to test hypotheses, scientists may have a preference for one outcome over another. Eliminating the bias can be achieved by transparency, careful experimental design, and a thorough peer review process of the experimental results and conclusions. After the results of an experiment are announced or published, it is normal practice for independent researchers to double-check how the research was performed, and to follow up by performing similar experiments to determine how dependable the results might be. Taken in its entirety, the scientific method allows for highly creative problem solving while minimizing the effects of subjective and confirmation bias. Intersubjective verifiability, the ability to reach a consensus and reproduce results, is fundamental to the creation of all scientific knowledge.

Scientific literature
Main articles: Scientific literature and Lists of important publications in science
Decorated "NATURE" as title, with scientific text below
Cover of the first issue of Nature, November 4, 1869
Scientific research is published in a range of literature. Scientific journals communicate and document the results of research carried out in universities and various other research institutions, serving as an archival record of science. The first scientific journals, Journal des sçavans followed by Philosophical Transactions, began publication in 1665. Since that time the total number of active periodicals has steadily increased. In 1981, one estimate for the number of scientific and technical journals in publication was 11,500.

Most scientific journals cover a single scientific field and publish the research within that field; the research is normally expressed in the form of a scientific paper. Science has become so pervasive in modern societies that it is considered necessary to communicate the achievements, news, and ambitions of scientists to a wider population.

Challenges
The replication crisis is an ongoing methodological crisis that affects parts of the social and life sciences. In subsequent investigations, the results of many scientific studies are proven to be unrepeatable. The crisis has long-standing roots; the phrase was coined in the early 2010s as part of a growing awareness of the problem. The replication crisis represents an important body of research in metascience, which aims to improve the quality of all scientific research while reducing waste.

An area of study or speculation that masquerades as science in an attempt to claim a legitimacy that it would not otherwise be able to achieve is sometimes referred to as pseudoscience, fringe science, or junk science. Physicist Richard Feynman coined the term "cargo cult science" for cases in which researchers believe and at a glance looks like they are doing science, but lack the honesty allowing their results to be rigorously evaluated. Various types of commercial advertising, ranging from hype to fraud, may fall into these categories. Science has been described as "the most important tool" for separating valid claims from invalid ones.

There can also be an element of political or ideological bias on all sides of scientific debates. Sometimes, research may be characterized as "bad science," research that may be well-intended but is incorrect, obsolete, incomplete, or over-simplified expositions of scientific ideas. The term "scientific misconduct" refers to situations such as where researchers have intentionally misrepresented their published data or have purposely given credit for a discovery to the wrong person.

Philosophy of science

Depiction of epicycles, where a planet orbit is going around in a bigger orbit
For Kuhn, the addition of epicycles in Ptolemaic astronomy was "normal science" within a paradigm, whereas the Copernican revolution was a paradigm shift.
There are different schools of thought in the philosophy of science. The most popular position is empiricism, which holds that knowledge is created by a process involving observation; scientific theories generalize observations. Empiricism generally encompasses inductivism, a position that explains how general theories can be made from the finite amount of empirical evidence available. Many versions of empiricism exist, with the predominant ones being Bayesianism and the hypothetico-deductive method.

Empiricism has stood in contrast to rationalism, the position originally associated with Descartes, which holds that knowledge is created by the human intellect, not by observation. Critical rationalism is a contrasting 20th-century approach to science, first defined by Austrian-British philosopher Karl Popper. Popper rejected the way that empiricism describes the connection between theory and observation. He claimed that theories are not generated by observation, but that observation is made in the light of theories: that the only way theory A can be affected by observation is after theory A were to conflict with observation, but theory B were to survive the observation. Popper proposed replacing verifiability with falsifiability as the landmark of scientific theories, replacing induction with falsification as the empirical method. Popper further claimed that there is actually only one universal method, not specific to science: the negative method of criticism, trial and error, covering all products of the human mind, including science, mathematics, philosophy, and art.

Another approach, instrumentalism, emphasizes the utility of theories as instruments for explaining and predicting phenomena. It views scientific theories as black boxes with only their input (initial conditions) and output (predictions) being relevant. Consequences, theoretical entities, and logical structure are claimed to be something that should be ignored. Close to instrumentalism is constructive empiricism, according to which the main criterion for the success of a scientific theory is whether what it says about observable entities is true.

Thomas Kuhn argued that the process of observation and evaluation takes place within a paradigm, a logically consistent "portrait" of the world that is consistent with observations made from its framing. He characterized normal science as the process of observation and "puzzle solving" which takes place within a paradigm, whereas revolutionary science occurs when one paradigm overtakes another in a paradigm shift. Each paradigm has its own distinct questions, aims, and interpretations. The choice between paradigms involves setting two or more "portraits" against the world and deciding which likeness is most promising. A paradigm shift occurs when a significant number of observational anomalies arise in the old paradigm and a new paradigm makes sense of them. That is, the choice of a new paradigm is based on observations, even though those observations are made against the background of the old paradigm. For Kuhn, acceptance or rejection of a paradigm is a social process as much as a logical process. Kuhn's position, however, is not one of relativism.

Finally, another approach often cited in debates of scientific skepticism against controversial movements like "creation science" is methodological naturalism. Naturalists maintain that a difference should be made between natural and supernatural, and science should be restricted to natural explanations. Methodological naturalism maintains that science requires strict adherence to empirical study and independent verification.

Scientific community
The scientific community is a network of interacting scientists who conducts scientific research. The community consists of smaller groups working in scientific fields. By having peer review, through discussion and debate within journals and conferences, scientists maintain the quality of research methodology and objectivity when interpreting results.

Scientists
Portrait of a middle-aged woman
Marie Curie was the first person to be awarded two Nobel Prizes: Physics in 1903 and Chemistry in 1911.
Scientists are individuals who conduct scientific research to advance knowledge in an area of interest. In modern times, many professional scientists are trained in an academic setting and upon completion, attain an academic degree, with the highest degree being a doctorate such as a Doctor of Philosophy or PhD. Many scientists pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit organizations.

Scientists exhibit a strong curiosity about reality and a desire to apply scientific knowledge for the benefit of health, nations, the environment, or industries. Other motivations include recognition by their peers and prestige. In modern times, many scientists have advanced degrees in an area of science and pursue careers in various sectors of the economy such as academia, industry, government, and nonprofit environments.

Science has historically been a male-dominated field, with notable exceptions. Women in science faced considerable discrimination in science, much as they did in other areas of male-dominated societies. For example, women were frequently being passed over for job opportunities and denied credit for their work. The achievements of women in science have been attributed to the defiance of their traditional role as laborers within the domestic sphere. Lifestyle choice plays a major role in female engagement in science; female graduate students' interest in careers in research declines dramatically throughout graduate school, whereas that of their male colleagues remains unchanged.

Learned societies

Picture of scientists in 200th anniversary of the Prussian Academy of Sciences, 1900
Learned societies for the communication and promotion of scientific thought and experimentation have existed since the Renaissance. Many scientists belong to a learned society that promotes their respective scientific discipline, profession, or group of related disciplines. Membership may either be open to all, require possession of scientific credentials, or conferred by election. Most scientific societies are non-profit organizations, and many are professional associations. Their activities typically include holding regular conferences for the presentation and discussion of new research results and publishing or sponsoring academic journals in their discipline. Some societies act as professional bodies, regulating the activities of their members in the public interest or the collective interest of the membership.[citation needed]

The professionalization of science, begun in the 19th century, was partly enabled by the creation of national distinguished academies of sciences such as the Italian Accademia dei Lincei in 1603, the British Royal Society in 1660, the French Academy of Sciences in 1666, the American National Academy of Sciences in 1863, the German Kaiser Wilhelm Society in 1911, and the Chinese Academy of Sciences in 1949. International scientific organizations, such as the International Science Council, are devoted to international cooperation for science advancement.

Awards
Science awards are usually given to individuals or organizations that have made significant contributions to a discipline. They are often given by prestigious institutions, thus it is considered a great honor for a scientist receiving them. Since the early Renaissance, scientists are often awarded medals, money, and titles. The Nobel Prize, a widely regarded prestigious award, is awarded annually to those who have achieved scientific advances in the fields of medicine, physics, and chemistry.

Society
"Science and society" redirects here. Not to be confused with Science & Society or Sociology of scientific knowledge.
Funding and policies
see caption
Budget of NASA as percentage of United States federal budget, peaking at 4.4% in 1966 and slowly declining since
Scientific research is often funded through a competitive process in which potential research projects are evaluated and only the most promising receive funding. Such processes, which are run by government, corporations, or foundations, allocate scarce funds. Total research funding in most developed countries is between 1.5% and 3% of GDP. In the OECD, around two-thirds of research and development in scientific and technical fields is carried out by industry, and 20% and 10% respectively by universities and government. The government funding proportion in certain fields is higher, and it dominates research in social science and humanities. In the lesser-developed nations, government provides the bulk of the funds for their basic scientific research.

Many governments have dedicated agencies to support scientific research, such as the National Science Foundation in the United States, the National Scientific and Technical Research Council in Argentina, Commonwealth Scientific and Industrial Research Organization in Australia, National Centre for Scientific Research in France, the Max Planck Society in Germany, and National Research Council in Spain. In commercial research and development, all but the most research-oriented corporations focus more heavily on near-term commercialization possibilities rather than research driven by curiosity.

Science policy is concerned with policies that affect the conduct of the scientific enterprise, including research funding, often in pursuance of other national policy goals such as technological innovation to promote commercial product development, weapons development, health care, and environmental monitoring. Science policy sometimes refers to the act of applying scientific knowledge and consensus to the development of public policies. In accordance with public policy being concerned about the well-being of its citizens, science policy's goal is to consider how science and technology can best serve the public. Public policy can directly affect the funding of capital equipment and intellectual infrastructure for industrial research by providing tax incentives to those organizations that fund research.

Education and awareness
Main articles: Public awareness of science and Science journalism

Dinosaur exhibit in the Houston Museum of Natural Science
Science education for the general public is embedded in the school curriculum, and is supplemented by online pedagogical content (for example, YouTube and Khan Academy), museums, and science magazines and blogs. Scientific literacy is chiefly concerned with an understanding of the scientific method, units and methods of measurement, empiricism, a basic understanding of statistics (correlations, qualitative versus quantitative observations, aggregate statistics), as well as a basic understanding of core scientific fields, such as physics, chemistry, biology, ecology, geology and computation. As a student advances into higher stages of formal education, the curriculum becomes more in depth. Traditional subjects usually included in the curriculum are natural and formal sciences, although recent movements include social anbiase\[\d\]d applied science as well.

The mass media face pressures that can prevent them from accurately depicting competing scientific claims in terms of their credibility within the scientific community as a whole. Determining how much weight to give different sides in a scientific debate may require considerable expertise regarding the matter. Few journalists have real scientific knowledge, and even beat reporters who are knowledgeable about certain scientific issues may be ignorant about other scientific issues that they are suddenly asked to cover.

Science magazines such as New Scientist, Science & Vie, and Scientific American cater to the needs of a much wider readership and provide a non-technical summary of popular areas of research, including notable discoveries and advances in certain fields of research. Science fiction genre, primarily speculative fiction, can transmit the ideas and methods of science to the general public. Recent efforts to intensify or develop links between science and non-scientific disciplines, such as literature or poetry, include the Creative Writing Science resource developed through the Royal Literary Fund.

Anti-science 
Main article: Antiscience
While the scientific method is broadly accepted in the scientific community, some fractions of society reject certain scientific positions or are skeptical about science. Examples are the common notion that COVID-19 is not a major health threat to the US (held by 39% of Americans in August 2021) or the belief that climate change is not a major threat to the US (also held by 40% of Americans, in late 2019 and early 2020). Psychologists have pointed to four factors driving rejection of scientific results:

Scientific authorities are sometimes seen as inexpert, untrustworthy, or biased.
Some marginalized social groups hold anti-science attitudes, in part because these groups have often been exploited in unethical experiments.
Messages from scientists may contradict deeply-held existing beliefs or morals.
The delivery of a scientific message may not be appropriately targeted to a recipient's learning style.
Anti-science attitudes seem to be often caused by fear of rejection in social groups. For instance, climate change is perceived as a threat by only 22% of Americans on the right side of the political spectrum, but by 85% on the left. That is, if someone on the left would not consider climate change as a threat, this person may face contempt and be rejected in that social group. In fact, people may rather deny a scientifically accepted fact than lose or jeopardize their social status.

Politics
Result in bar graph of two questions ("Is global warming occurring?" and "Are oil/gas companies responsible?"), showing large discrepancies between American Democrats and Republicans
Public opinion on global warming in the United States by political party
Attitudes towards science are often determined by political opinions and goals. Government, business and advocacy groups have been known to use legal and economic pressure to influence scientific researchers. Many factors can act as facets of the politicization of science such as anti-intellectualism, perceived threats to religious beliefs, and fear for business interests. Politicization of science is usually accomplished when scientific information is presented in a way that emphasizes the uncertainty associated with the scientific evidence. Tactics such as shifting conversation, failing to acknowledge facts, and capitalizing on doubt of scientific consensus have been used to gain more attention for views that have been undermined by scientific evidence. Examples of issues that have involved the politicization of science include the global warming controversy, health effects of pesticides, and health effects of tobacco.